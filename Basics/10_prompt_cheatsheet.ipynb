{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a544a6d",
   "metadata": {},
   "source": [
    "# Prompt & Context Engineering — Cheat Sheet (with examples)\n",
    "\n",
    "## Goals\n",
    "\n",
    "* **Be reliable:** same input → same style/format.\n",
    "* **Be grounded:** answer only from provided context; refuse when missing.\n",
    "* **Be controllable:** tone, length, structure, language.\n",
    "* **Be efficient:** fit token budget, minimize latency/cost.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Principles\n",
    "\n",
    "* **Instruction hierarchy:** system > developer > user > data/context > examples.\n",
    "* **Single source of truth:** always state scope + allowed sources.\n",
    "* **Determinism first:** start with low temperature (0–0.3); raise only if needed.\n",
    "* **Tight feedback loop:** iterate with a small eval set and keep a changelog.\n",
    "* **Guardrails beat band-aids:** require “I don’t know” behavior explicitly.\n",
    "\n",
    "---\n",
    "\n",
    "## Prompt Skeletons (drop-in)\n",
    "\n",
    "### 1) RAG Answerer (safe, concise)\n",
    "\n",
    "```\n",
    "ROLE: You are an assistant that answers ONLY using the provided context.\n",
    "\n",
    "CONTEXT:\n",
    "{{context}}\n",
    "\n",
    "TASK:\n",
    "Answer the QUESTION strictly using the CONTEXT. If the answer is not present, reply exactly: \"I don’t know.\"\n",
    "\n",
    "QUESTION:\n",
    "{{question}}\n",
    "\n",
    "CONSTRAINTS:\n",
    "- Be concise (≤ 120 words).\n",
    "- Cite snippet IDs from CONTEXT if available (e.g., [D3], [P2]).\n",
    "- No speculation or external facts.\n",
    "```\n",
    "\n",
    "### 2) Persona + Style\n",
    "\n",
    "```\n",
    "ROLE: You are {{persona}}. Tone: {{tone}}. Audience: {{audience}}.\n",
    "\n",
    "TASK:\n",
    "Respond to the user while preserving the persona and tone.\n",
    "\n",
    "HARD RULES:\n",
    "- Stay in scope: {{scope}}.\n",
    "- If out of scope, say: \"Sorry, I can only discuss {{scope}}.\"\n",
    "- Keep responses under {{max_words}} words unless asked otherwise.\n",
    "```\n",
    "\n",
    "### 3) Format-Constrained (JSON)\n",
    "\n",
    "```\n",
    "ROLE: Output MUST be valid JSON. No extra text.\n",
    "\n",
    "SCHEMA:\n",
    "{\"answer\": string, \"confidence\": \"high|medium|low\", \"citations\": [string]}\n",
    "\n",
    "CONTEXT:\n",
    "{{context}}\n",
    "\n",
    "QUESTION:\n",
    "{{question}}\n",
    "\n",
    "RULES:\n",
    "- If unsure, answer \"\" and set \"confidence\": \"low\".\n",
    "- Do not include keys not in the schema.\n",
    "```\n",
    "\n",
    "### 4) Structured Reasoning (silent CoT)\n",
    "\n",
    "```\n",
    "ROLE: Solve carefully using internal reasoning, but only output the final answer.\n",
    "\n",
    "INTERNAL STEPS (do not reveal): analyze → plan → verify.\n",
    "\n",
    "QUESTION:\n",
    "{{question}}\n",
    "\n",
    "FINAL OUTPUT (no steps, no notes):\n",
    "```\n",
    "\n",
    "### 5) Multi-turn Memory Prompt\n",
    "\n",
    "```\n",
    "ROLE: Continue the conversation using the last N turns for context.\n",
    "\n",
    "CHAT HISTORY (most recent last):\n",
    "{{history}}\n",
    "\n",
    "NEW USER MESSAGE:\n",
    "{{message}}\n",
    "\n",
    "RULES:\n",
    "- Prefer recent history when conflicting.\n",
    "- Summarize long history if needed before answering.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Prompt Patterns (when to use & mini-examples)\n",
    "\n",
    "* **Zero-shot:** quickest baseline.\n",
    "  “Summarize this in 3 bullets.”\n",
    "\n",
    "* **Few-shot:** stabilize style/format.\n",
    "  Provide 2–3 input→output pairs before the task.\n",
    "\n",
    "* **Self-ask / self-query:** let the model generate subquestions before answering (implicit, no tools).\n",
    "  “Before answering, list the sub-questions you must resolve (silently). Then answer.”\n",
    "\n",
    "* **Refusal mode:**\n",
    "  “If the question is outside {{scope}}, reply: ‘Sorry, I can only discuss {{scope}}.’”\n",
    "\n",
    "* **Critic / Improve loop:**\n",
    "  First pass: draft. Second pass: “Critique the draft against these criteria: … Now produce the improved final.”\n",
    "\n",
    "* **Style-transfer:**\n",
    "  “Rewrite the answer to match Tone=‘friendly, direct’, Sentences ≤ 2 lines.”\n",
    "\n",
    "* **Self-consistency (sampling n):** run n>1 samples at T\\~0.7 and pick majority/aggregated (in code orchestration).\n",
    "\n",
    "---\n",
    "\n",
    "## Context Engineering (RAG) Toolkit\n",
    "\n",
    "### Chunking & Metadata\n",
    "\n",
    "* **Chunk size:** 300–800 tokens (test 512 vs 1024).\n",
    "* **Overlap:** 10–20% to preserve coherence.\n",
    "* **Metadata:** title, section, date, source\\_id, tags; store for filters & citations.\n",
    "\n",
    "### Retrieval Strategies\n",
    "\n",
    "* **Pure dense (embeddings):** cosine similarity on k=3–5.\n",
    "* **Hybrid:** BM25 (keyword) + dense; merge scores.\n",
    "* **Re-ranking:** retrieve k=20 dense → re-rank top 5 with a cross-encoder (optional).\n",
    "* **Multi-vector / passage + summary:** store both raw chunks and their summaries.\n",
    "\n",
    "### Context Packing\n",
    "\n",
    "* **Stuffing:** paste top-k chunks. Simple, can overflow.\n",
    "* **Refine:** start with answer from best chunk, refine with next chunks.\n",
    "* **Map-Reduce:** summarize each chunk → combine summaries → answer.\n",
    "* **Selective fields:** include only snippet, title, date, and a 1-line key point to save tokens.\n",
    "\n",
    "### Anti-Hallucination Prompts\n",
    "\n",
    "Add explicitly:\n",
    "\n",
    "* “If information is missing or uncertain, reply exactly: ‘I don’t know.’”\n",
    "* “Never infer dates/metrics not present in CONTEXT.”\n",
    "* “Prefer quoting snippets with \\[source\\_id].”\n",
    "\n",
    "### Recency/Validity Hints\n",
    "\n",
    "* Include `last_updated` in context header.\n",
    "* Prompt: “Prefer the most recent snippet when conflicting (by last\\_updated).”\n",
    "\n",
    "---\n",
    "\n",
    "## Guardrails & Safety\n",
    "\n",
    "* **Scope limiter:** define the domain you can talk about.\n",
    "* **Banned behaviors:** e.g., “No medical/financial advice.”\n",
    "* **Refusal template:** predictable sentence for out-of-scope.\n",
    "* **Toxicity filter (pre/post):** screen inputs/outputs if needed (in code).\n",
    "* **Regex/JSON schema validation:** reject malformed outputs; re-prompt with error.\n",
    "\n",
    "---\n",
    "\n",
    "## Parameter Tuning (defaults to start)\n",
    "\n",
    "* **temperature:** 0.2 (↑ for creativity; ↓ for precision).\n",
    "* **top\\_p:** 1.0 (rarely needed if temperature tuned).\n",
    "* **max\\_tokens:** budget-aware (e.g., ≤ 300 for concise replies).\n",
    "* **frequency/presence penalties:** small positive values to reduce repetition.\n",
    "\n",
    "---\n",
    "\n",
    "## Debugging Checklist\n",
    "\n",
    "1. **Bad grounding?** Increase k, try hybrid retrieval, add reranker.\n",
    "2. **Hallucinations?** Strengthen refusal text; add “no external facts”; reduce temperature.\n",
    "3. **Off-style?** Add few-shot examples; tighten persona/tone rules.\n",
    "4. **Too long?** Add hard length cap and “omit extras.”\n",
    "5. **Invalid JSON?** Provide schema + example + tool-enforced validation with a retry loop.\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation & Iteration\n",
    "\n",
    "### Mini Eval Set (keep it small but sharp)\n",
    "\n",
    "* 10 in-scope direct Qs (answerable).\n",
    "* 5 out-of-scope Qs (should refuse).\n",
    "* 5 ambiguous/underspecified Qs (should ask clarifying or say “don’t know”).\n",
    "* 5 adversarial (similar names, tricky dates).\n",
    "\n",
    "### Metrics\n",
    "\n",
    "* **Grounded accuracy:** correct & supported by context.\n",
    "* **Refusal accuracy:** % of OOS correctly refused.\n",
    "* **Format adherence:** valid JSON / style compliance.\n",
    "* **Conciseness/readability:** manual rubric 1–5.\n",
    "* **Latency & token usage.**\n",
    "\n",
    "### Workflow\n",
    "\n",
    "* Freeze a **Prompt vX**; run eval; log deltas.\n",
    "* Change **one variable at a time** (k, chunk size, prompt copy, temperature).\n",
    "* Keep a **prompt changelog** with rationales.\n",
    "\n",
    "---\n",
    "\n",
    "## Tips & Tricks (battle-tested)\n",
    "\n",
    "* **Name the sections** in your prompt (ROLE, CONTEXT, TASK, RULES) → improves compliance.\n",
    "* **Use exact strings** for refusals (“I don’t know.”) to simplify evals.\n",
    "* **Give a target length** (words, bullets, or tokens), not “be concise”.\n",
    "* **Pre-pend a TL;DR** summary to packed context when documents are long.\n",
    "* **Order context by score + recency**; label each snippet `[S1]…` for citing.\n",
    "* **Few-shot exemplars**: keep them **short** and structurally similar to desired outputs.\n",
    "* **Deterministic JSON:** forbid extra keys; provide 1 valid example.\n",
    "* **Hidden thoughts:** ask for careful internal reasoning but **only output final answer** (avoid printing chain-of-thought).\n",
    "* **Version everything:** prompt text, k, chunking, reranker on/off.\n",
    "\n",
    "---\n",
    "\n",
    "## Ready-to-Use Mini Libraries (copy/paste)\n",
    "\n",
    "### Short Answer (strict)\n",
    "\n",
    "```\n",
    "ROLE: Domain-bound assistant. Only use CONTEXT.\n",
    "\n",
    "CONTEXT:\n",
    "{{context}}\n",
    "\n",
    "QUESTION:\n",
    "{{question}}\n",
    "\n",
    "REPLY STYLE:\n",
    "- ≤ 5 sentences.\n",
    "- Quote source IDs like [S#] when relevant.\n",
    "- If not in CONTEXT: \"I don’t know.\"\n",
    "```\n",
    "\n",
    "### Clarifying Questions First\n",
    "\n",
    "```\n",
    "If the QUESTION is ambiguous or missing key details, ask up to 2 clarifying questions before answering. \n",
    "If sufficient, answer normally; else say: \"I don’t know.\"\n",
    "```\n",
    "\n",
    "### Summarizer (map-reduce compatible)\n",
    "\n",
    "```\n",
    "You will receive multiple snippets. For each snippet, produce a 1–2 sentence summary with its [S#].\n",
    "Then combine into a coherent, non-redundant final summary, preserving source IDs.\n",
    "```\n",
    "\n",
    "### JSON Extractor\n",
    "\n",
    "```\n",
    "ROLE: Extract fields from CONTEXT. Output valid JSON only.\n",
    "\n",
    "SCHEMA:\n",
    "{\"name\":\"\",\"role\":\"\",\"dates\":[],\"skills\":[]}\n",
    "\n",
    "RULES:\n",
    "- If a field is missing, use empty string/array.\n",
    "- Do not invent values.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Example: Putting It Together (RAG Q\\&A)\n",
    "\n",
    "```\n",
    "ROLE: You answer questions strictly from Harshit’s portfolio data.\n",
    "\n",
    "CONTEXT (ranked, newest first):\n",
    "[S1|2025-03-18] VGG-16 fine-tuned; best accuracy 64% …\n",
    "[S2|2025-03-10] Using FER2013 dataset …\n",
    "[S3|2024-11-26] Digit recognition project completed …\n",
    "\n",
    "QUESTION:\n",
    "What dataset did Harshit use for the emotion model?\n",
    "\n",
    "RULES:\n",
    "- Prefer newest when conflicting.\n",
    "- Cite source IDs.\n",
    "- If unknown: \"I don’t know.\"\n",
    "- ≤ 60 words.\n",
    "\n",
    "EXPECTED OUTPUT STYLE:\n",
    "\"Harshit used the FER2013 dataset for the emotion classification project. [S2]\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Ladder (quick plan)\n",
    "\n",
    "1. **Single-turn prompts**: zero → few-shot → persona → JSON.\n",
    "2. **Context packing**: k=3 stuffing → refine → map-reduce → hybrid.\n",
    "3. **Guardrails**: scope limiter + refusal tests.\n",
    "4. **Eval & versioning**: lock a v1; iterate with tiny, visible changes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f8762",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
