{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-11T07:39:34.540334Z",
     "iopub.status.busy": "2025-08-11T07:39:34.540093Z",
     "iopub.status.idle": "2025-08-11T07:39:40.599317Z",
     "shell.execute_reply": "2025-08-11T07:39:40.598623Z",
     "shell.execute_reply.started": "2025-08-11T07:39:34.540300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, langchain-core, langchain-huggingface\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.33.1\n",
      "    Uninstalling huggingface-hub-0.33.1:\n",
      "      Successfully uninstalled huggingface-hub-0.33.1\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.66\n",
      "    Uninstalling langchain-core-0.3.66:\n",
      "      Successfully uninstalled langchain-core-0.3.66\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.34.4 langchain-core-0.3.74 langchain-huggingface-0.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers langchain langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer on summarized text\n",
    "This is not anything really useful or properly functional, I just wanted to try the langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-08-11T07:40:45.001143Z",
     "iopub.status.busy": "2025-08-11T07:40:45.000551Z",
     "iopub.status.idle": "2025-08-11T07:41:08.873638Z",
     "shell.execute_reply": "2025-08-11T07:41:08.873096Z",
     "shell.execute_reply.started": "2025-08-11T07:40:45.001108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 07:40:54.118406: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754898054.273128      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754898054.317246      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from transformers.utils.logging import set_verbosity_error    # for suppressing errors and warnings\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:41:08.875326Z",
     "iopub.status.busy": "2025-08-11T07:41:08.874746Z",
     "iopub.status.idle": "2025-08-11T07:41:08.891416Z",
     "shell.execute_reply": "2025-08-11T07:41:08.890410Z",
     "shell.execute_reply.started": "2025-08-11T07:41:08.875298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7d00b41d774dbb9ca1266f956de772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:46:36.062928Z",
     "iopub.status.busy": "2025-08-11T07:46:36.062643Z",
     "iopub.status.idle": "2025-08-11T07:46:37.420880Z",
     "shell.execute_reply": "2025-08-11T07:46:37.420312Z",
     "shell.execute_reply.started": "2025-08-11T07:46:36.062906Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "summarization_pipe = pipeline(\n",
    "    task= 'summarization', \n",
    "    model= 'facebook/bart-large-cnn', \n",
    "    device= 0\n",
    ")\n",
    "summarizer = HuggingFacePipeline(pipeline= summarization_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:47:15.175266Z",
     "iopub.status.busy": "2025-08-11T07:47:15.174955Z",
     "iopub.status.idle": "2025-08-11T07:47:23.399880Z",
     "shell.execute_reply": "2025-08-11T07:47:23.398936Z",
     "shell.execute_reply.started": "2025-08-11T07:47:15.175246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2562e15c942c4354a94ae9491b1d215a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e4aa82bc384797857c5b413a0ff9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54815dd2933e4e5bae3690d49564ac76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190a86eab6a341fb8ac075c59a7525ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10614d86c6044158961f3ceb80460c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6f2e143d0742369f93c75c58e36622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1c88a80f954c22bfebd5053fb88e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "refinement_pipe = pipeline(\n",
    "    task= 'summarization', \n",
    "    model= 'facebook/bart-large', \n",
    "    device= 0\n",
    ")\n",
    "refiner = HuggingFacePipeline(pipeline= refinement_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:48:25.338186Z",
     "iopub.status.busy": "2025-08-11T07:48:25.337799Z",
     "iopub.status.idle": "2025-08-11T07:48:29.263354Z",
     "shell.execute_reply": "2025-08-11T07:48:29.262733Z",
     "shell.execute_reply.started": "2025-08-11T07:48:25.338163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f73fabac5949db8d2d2d6af8b5800b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebeace0ec61c4940bcef939690d6faf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f37253c24434e6c80f518c74192f17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded5b1727b0544e9b066a32a3c8d3aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad36b06e4d34e74af3df432b1fa14cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e66ac2c56f43659da10df8dd7a4737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\n",
    "    task= 'question-answering',\n",
    "    model= 'deepset/roberta-base-squad2',\n",
    "    device= 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:56:18.960943Z",
     "iopub.status.busy": "2025-08-11T07:56:18.960263Z",
     "iopub.status.idle": "2025-08-11T07:56:18.964249Z",
     "shell.execute_reply": "2025-08-11T07:56:18.963574Z",
     "shell.execute_reply.started": "2025-08-11T07:56:18.960921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summary_prompt = PromptTemplate.from_template('Summarize the following text in {word_limit} words: /n/n {text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:56:19.598299Z",
     "iopub.status.busy": "2025-08-11T07:56:19.598067Z",
     "iopub.status.idle": "2025-08-11T07:56:19.602098Z",
     "shell.execute_reply": "2025-08-11T07:56:19.601404Z",
     "shell.execute_reply.started": "2025-08-11T07:56:19.598281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summarization_chain = summary_prompt | summarizer | refiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T08:01:58.269456Z",
     "iopub.status.busy": "2025-08-11T08:01:58.269174Z",
     "iopub.status.idle": "2025-08-11T08:02:09.912266Z",
     "shell.execute_reply": "2025-08-11T08:02:09.911635Z",
     "shell.execute_reply.started": "2025-08-11T08:01:58.269437Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text to summarize:\n",
      " Artificial Intelligence (AI) has rapidly evolved from a niche research field into a transformative force reshaping industries, economies, and everyday life, powered by breakthroughs in machine learning, natural language processing, and computer vision, and fueled by unprecedented amounts of data and computational resources; from simple rule-based systems that could only perform narrowly defined tasks, AI has advanced to deep neural networks and large language models capable of understanding human language, generating creative content, detecting patterns in complex datasets, and even making autonomous decisions, enabling applications in healthcare where AI algorithms can diagnose diseases from medical images faster and sometimes more accurately than human doctors, in transportation where self-driving cars analyze real-time sensor inputs to navigate roads with minimal human intervention, in finance where predictive models assess market trends and manage risk, in education where adaptive learning platforms tailor content to individual student needs, and in entertainment where recommendation systems personalize experiences and generative AI tools create music, art, and scripts, all while industries race to leverage these capabilities for productivity gains and competitive advantage; yet the same powerful features that make AI so valuable also raise serious challenges, including bias in decision-making when models are trained on unrepresentative or prejudiced data, privacy concerns as vast quantities of personal information are collected and analyzed, ethical dilemmas over autonomous weapons and surveillance systems, job displacement as automation replaces certain human roles, and the existential debate over whether advanced AI might one day surpass human intelligence in ways that could be difficult to control, leading researchers and policymakers to advocate for robust governance frameworks, transparency in AI decision-making, and alignment techniques to ensure AI systems remain beneficial; meanwhile, the field continues to push boundaries with research into explainable AI to make model reasoning more transparent, reinforcement learning to enable agents to learn from trial and error in complex environments, multimodal AI systems that process and integrate information from text, images, audio, and video, and federated learning to allow AI models to be trained collaboratively without centralizing sensitive data, while quantum computing on the horizon promises to exponentially increase AI’s computational capabilities, potentially unlocking new levels of performance for optimization, cryptography, and scientific discovery; as AI becomes more embedded in human society, the conversation has shifted from whether AI will change the world to how it will do so, and whether humanity will guide its development with foresight, responsibility, and inclusivity, or be swept along by its momentum, making the next decade a critical period in determining whether AI will serve as a tool for human flourishing or a source of disruption that outpaces our ability to adapt.\n",
      "\n",
      "Enter the length of summary (short/medium/long):  long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 63. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Generated Summary:**\n",
      "Artificial Intelligence (AI) has rapidly evolved from a niche research field into a transformative force reshaping industries, economies, and everyday life. The next decade will be a critical period in determining whether AI will serve as a tool for human flourishing or a source of disruption that outpaces our ability to adapt.\n"
     ]
    }
   ],
   "source": [
    "# taking user input\n",
    "text_to_summarize = input('\\nEnter text to summarize:\\n')\n",
    "length = input('\\nEnter the length of summary (short/medium/long): ')\n",
    "\n",
    "# maping the length to get word_limit\n",
    "length_map = {\n",
    "    'short': 100,\n",
    "    'medium': 150,\n",
    "    'long': 300\n",
    "}\n",
    "word_limit = length_map.get(length.lower(), 150)\n",
    "\n",
    "# summarization\n",
    "summary = summarization_chain.invoke({\n",
    "    'word_limit': word_limit,\n",
    "    'text': text_to_summarize\n",
    "})\n",
    "print(f'\\n**Generated Summary:**\\n{summary}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T08:07:59.864724Z",
     "iopub.status.busy": "2025-08-11T08:07:59.864455Z",
     "iopub.status.idle": "2025-08-11T08:09:55.040481Z",
     "shell.execute_reply": "2025-08-11T08:09:55.039530Z",
     "shell.execute_reply.started": "2025-08-11T08:07:59.864705Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about the summary (or type `/q` to stop):\n",
      " What is Artificial Intelligence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Answer**:\n",
      "a transformative force reshaping industries, economies, and everyday life\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about the summary (or type `/q` to stop):\n",
      " What exponentially increases the computation capabilities of AI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Answer**:\n",
      "Artificial Intelligence (AI) has rapidly evolved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about the summary (or type `/q` to stop):\n",
      " how is it helpful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Answer**:\n",
      "a tool for human flourishing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about the summary (or type `/q` to stop):\n",
      " predictive models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Answer**:\n",
      "disruption that outpaces our ability to adapt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about the summary (or type `/q` to stop):\n",
      " /q\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # ask question from user\n",
    "    question = input('\\nAsk a question about the summary (or type `/q` to stop):\\n')\n",
    "\n",
    "    # cheking the quit condition\n",
    "    if question.lower() == '/q':\n",
    "        break\n",
    "\n",
    "    # inference\n",
    "    qa_result = qa_pipeline(\n",
    "        question= question,\n",
    "        context= summary\n",
    "    )\n",
    "\n",
    "    print(f'\\n**Answer**:\\n{qa_result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
