{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-05T15:02:35.331400Z",
     "iopub.status.busy": "2025-08-05T15:02:35.331034Z",
     "iopub.status.idle": "2025-08-05T15:03:01.416099Z",
     "shell.execute_reply": "2025-08-05T15:03:01.415371Z",
     "shell.execute_reply.started": "2025-08-05T15:02:35.331373Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 15:02:46.198065: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754406166.390463      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754406166.450423      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:01.418197Z",
     "iopub.status.busy": "2025-08-05T15:03:01.417599Z",
     "iopub.status.idle": "2025-08-05T15:03:01.423618Z",
     "shell.execute_reply": "2025-08-05T15:03:01.422907Z",
     "shell.execute_reply.started": "2025-08-05T15:03:01.418156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text = '''Moreover, if you want to fully understand how the machine learning algorithms work\n",
    "(not just how to use them), then you should have at least a basic understanding of\n",
    "a few math concepts, especially linear algebra. Specifically, you should know what\n",
    "vectors and matrices are, and how to perform some simple operations like adding\n",
    "vectors, or transposing and multiplying matrices. If you need a quick introduction to\n",
    "linear algebra (it’s really not rocket science!), I provide a tutorial at https://homl.info/\n",
    "tutorials. You will also find a tutorial on differential calculus, which may be helpful to\n",
    "understand how neural networks are trained, but it’s not entirely essential to grasp the\n",
    "important concepts. This book also uses other mathematical concepts occasionally,\n",
    "such as exponentials and logarithms, a bit of probability theory, and some basic\n",
    "statistics concepts, but nothing too advanced. If you need help on any of these,\n",
    "please check out https://khanacademy.org, which offers many excellent and free math\n",
    "courses online.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:01.424667Z",
     "iopub.status.busy": "2025-08-05T15:03:01.424400Z",
     "iopub.status.idle": "2025-08-05T15:03:19.465340Z",
     "shell.execute_reply": "2025-08-05T15:03:19.464549Z",
     "shell.execute_reply.started": "2025-08-05T15:03:01.424642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8592308fd64da2b00949ae210bfe02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3391a271a1d418c847f982d96e2edec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988161fabfc943a2a4d5bb8a2509dd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b98ff8ea8046ee8e41ccf25404a5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122ce5b97e704a8fa6f8d44674e24b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c1596c42de4c46b0bc3fbbddefa7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = pipeline(task= 'summarization', model= 'facebook/bart-large-cnn')\n",
    "response = model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:19.466462Z",
     "iopub.status.busy": "2025-08-05T15:03:19.466179Z",
     "iopub.status.idle": "2025-08-05T15:03:19.471815Z",
     "shell.execute_reply": "2025-08-05T15:03:19.471136Z",
     "shell.execute_reply.started": "2025-08-05T15:03:19.466438Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'If you want to fully understand how the machine learning algorithms work, then you should have at least a basic understanding of a few math concepts. This book also uses other mathematical concepts occasionally, such as exponentials and logarithms, a bit of probability theory, and some basicstatistics concepts. If you need help on any of these,please check out https://khanacademy.org, which offers many excellent and free math courses online.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:19.473432Z",
     "iopub.status.busy": "2025-08-05T15:03:19.473199Z",
     "iopub.status.idle": "2025-08-05T15:03:23.124812Z",
     "shell.execute_reply": "2025-08-05T15:03:23.123908Z",
     "shell.execute_reply.started": "2025-08-05T15:03:19.473406Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afa49e7649e4faaba618a204492e1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fcfd100feb41f895d4538fd29a90d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae225ad94b74d30b11006f85a92f9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f969f486f69b4ad6ac0e96200f9c6627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998795986175537}, {'label': 'NEGATIVE', 'score': 0.9990548491477966}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n",
    "response = classifier([\"I'm a very happy person.\", \"That is a terrible place.\"])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:23.127076Z",
     "iopub.status.busy": "2025-08-05T15:03:23.126801Z",
     "iopub.status.idle": "2025-08-05T15:03:27.854072Z",
     "shell.execute_reply": "2025-08-05T15:03:27.853268Z",
     "shell.execute_reply.started": "2025-08-05T15:03:23.127049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49a7e01222e412ab5eb5d9ce46be7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f73ac58a6a48f2a2516b434b5bf610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ba8960534a40a1a45a46126e0b981a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd7454680604fd7aaa41b75e8a85708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a25113122c34d6eb6068cf9fb6cf124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadfc4bd46d64fd8a3c17c04b30c117d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5b5c58e9ed444fa882ac86c620c17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model= 'distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:27.855199Z",
     "iopub.status.busy": "2025-08-05T15:03:27.854927Z",
     "iopub.status.idle": "2025-08-05T15:03:31.555915Z",
     "shell.execute_reply": "2025-08-05T15:03:31.555012Z",
     "shell.execute_reply.started": "2025-08-05T15:03:27.855172Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to use the concepts of a language to understand and to learn from the data and the context of the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be able to understand and understand the language to be'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\n",
    "    'In this course, we will teach you how to',\n",
    "    max_length= 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:31.556993Z",
     "iopub.status.busy": "2025-08-05T15:03:31.556712Z",
     "iopub.status.idle": "2025-08-05T15:03:40.995516Z",
     "shell.execute_reply": "2025-08-05T15:03:40.994735Z",
     "shell.execute_reply.started": "2025-08-05T15:03:31.556968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb877a7c35c847a786f81194ce74343e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36f36bcdfbe497d9c1e6a93ab3f5fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f7e22ca521499a8c7fb089d82305c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05bc8afdb044839be41721566c4add3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2256b59c3a4b24960f2fdc9d4e9da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54314c8bb4b2468e8254a5c51eeb5f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This course is about hugging face.',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.6356667876243591, 0.2551318407058716, 0.10920137912034988]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline('zero-shot-classification')\n",
    "res = classifier(\n",
    "    \"This course is about hugging face.\",\n",
    "    candidate_labels= ['education', 'politics', 'business']\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer & Model\n",
    "These are some generalized classes, which are simple helper classes that automatically figure out the right model/tokenizer to load just from a model name or path.\n",
    "\n",
    "**Common AutoClasses**:\n",
    "| Auto Class                           | What it does                                 |\n",
    "| ------------------------------------ | -------------------------------------------- |\n",
    "| `AutoTokenizer`                      | Loads the correct tokenizer for your model   |\n",
    "| `AutoModel`                          | Loads the base model (no task-specific head) |\n",
    "| `AutoModelForSequenceClassification` | For classification tasks                     |\n",
    "| `AutoModelForTokenClassification`    | For NER or similar tasks                     |\n",
    "| `AutoModelForQuestionAnswering`      | For Q\\&A tasks                               |\n",
    "| `AutoModelForCausalLM`               | For text generation (GPT-style models)       |\n",
    "| `AutoModelForMaskedLM`               | For fill-in-the-blank tasks (BERT-style)     |\n",
    "| `AutoProcessor`                      | For multi-modal models (images + text, etc.) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:40.996535Z",
     "iopub.status.busy": "2025-08-05T15:03:40.996308Z",
     "iopub.status.idle": "2025-08-05T15:03:41.000429Z",
     "shell.execute_reply": "2025-08-05T15:03:40.999743Z",
     "shell.execute_reply.started": "2025-08-05T15:03:40.996517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:41.001692Z",
     "iopub.status.busy": "2025-08-05T15:03:41.001398Z",
     "iopub.status.idle": "2025-08-05T15:03:47.842118Z",
     "shell.execute_reply": "2025-08-05T15:03:47.841302Z",
     "shell.execute_reply.started": "2025-08-05T15:03:41.001669Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d878740a22f44d88add77e917c68c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/902 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517f756d2f3149a99add58075277827c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530fb0f546fe485bb17a16c290f6e116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebc36ee2bd14fad9faf75566fc7bf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c63586f88e430f904e54be51f3fad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971e7f7626244108a73f76a93b7a92af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'tabularisai/multilingual-sentiment-analysis'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:47.843226Z",
     "iopub.status.busy": "2025-08-05T15:03:47.842952Z",
     "iopub.status.idle": "2025-08-05T15:03:48.027057Z",
     "shell.execute_reply": "2025-08-05T15:03:48.026297Z",
     "shell.execute_reply.started": "2025-08-05T15:03:47.843197Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline('sentiment-analysis', model= model, tokenizer= tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:48.028069Z",
     "iopub.status.busy": "2025-08-05T15:03:48.027825Z",
     "iopub.status.idle": "2025-08-05T15:03:56.373201Z",
     "shell.execute_reply": "2025-08-05T15:03:56.372075Z",
     "shell.execute_reply.started": "2025-08-05T15:03:48.028047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Positive', 'score': 0.49253690242767334}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(\"The food at that restaurant is really good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:56.374579Z",
     "iopub.status.busy": "2025-08-05T15:03:56.374252Z",
     "iopub.status.idle": "2025-08-05T15:03:56.825308Z",
     "shell.execute_reply": "2025-08-05T15:03:56.824452Z",
     "shell.execute_reply.started": "2025-08-05T15:03:56.374550Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response = {'input_ids': [101, 32935, 169, 29608, 59106, 17175, 10124, 16205, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "tokens = ['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n",
      "ids = [32935, 169, 29608, 59106, 17175, 10124, 16205]\n",
      "decoded_string = 'Using a Transformer network is simple'\n"
     ]
    }
   ],
   "source": [
    "sequence = 'Using a Transformer network is simple'\n",
    "\n",
    "response = tokenizer(sequence)\n",
    "print(f'{response = }')\n",
    "\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(f'{tokens = }')\n",
    "\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f'{ids = }')\n",
    "\n",
    "decoded_string = tokenizer.decode(ids)\n",
    "print(f'{decoded_string = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:56.828478Z",
     "iopub.status.busy": "2025-08-05T15:03:56.827625Z",
     "iopub.status.idle": "2025-08-05T15:03:58.336982Z",
     "shell.execute_reply": "2025-08-05T15:03:58.336197Z",
     "shell.execute_reply.started": "2025-08-05T15:03:56.828449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_directory = r'/kaggle/working/saved'\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "1. Prepare dataset\n",
    "2. load pretrained Tokenizer, call it with dataset -> encoding\n",
    "3. build dataset with encodings\n",
    "4. load pretrained model\n",
    "5. a) load trainer and train int\n",
    "   b) native tensorflow training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:03:58.337971Z",
     "iopub.status.busy": "2025-08-05T15:03:58.337725Z",
     "iopub.status.idle": "2025-08-05T15:03:59.604407Z",
     "shell.execute_reply": "2025-08-05T15:03:59.603631Z",
     "shell.execute_reply.started": "2025-08-05T15:03:58.337947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T15:12:02.521813Z",
     "iopub.status.busy": "2025-08-05T15:12:02.521474Z",
     "iopub.status.idle": "2025-08-05T15:12:02.552380Z",
     "shell.execute_reply": "2025-08-05T15:12:02.551612Z",
     "shell.execute_reply.started": "2025-08-05T15:12:02.521789Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= 'trained_model',\n",
    "    eval_strategy= 'epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we can fine tune:\n",
    "\n",
    "```python\n",
    "trainer = Trainer(\n",
    "    model= model,\n",
    "    args= training_args,\n",
    "    train_dataset= dataset[\"train\"],\n",
    "    eval_dataset= dataset[\"test\"],\n",
    "    compute_metrics= compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
