{
  "topic": "Artificial Intelligence in Climate Modeling",
  "source": "both",
  "wikipedia_docs": "Index: 1\nTitle: Generative artificial intelligence\nSource: https://en.wikipedia.org/wiki/Generative_artificial_intelligence\nContent: Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, DeepSeek, and Baidu. \nGenerative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\n\n\n== History ==\n\n\n=== Early history ===\nThe first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\n\n\n=== Generative neural networks (2014–2019) ===\n\nSince its inception, the field of machine learning has used both discriminative models and generative models to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress, and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\nIn 2017, the Transformer network enabled advancements in generative models compared to older long short-term memory (LSTM) models, leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018. This was followed in 2019 by GPT-2, which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.\nThe new generative models introduced during this period allowed for large neural networks to be trained using unsupervised learning or semi-supervised learning, rather than the supervised learning typical of discriminative models. Unsupervised learning removed the need for humans to manually label data, allowing for larger networks to be trained.\n\n\n=== Generative AI boom (2020–) ===\n\nIn March 2020, the release of 15.ai, a free web application created by an anonymous MIT researcher that could generate convincing character voices using minimal training data, marked one of the earliest popular use cases of generative AI. The platform is credited as the first mainstream service to popularize AI voice cloning (audio deepfakes) in memes and content creation, influencing subsequent developments in voice AI technology.\nIn 2021, the emergence of DALL-E, a transformer-based pixel generative model, marked an advance in AI-generated imagery. This was followed by the releases of Midjourney and Stable Diffusion in 2022, which further democratized access to high-quality artificial intelligence art creation from natural language prompts. These systems demonstrated unprecedented capabilities in generating photorealistic images, artwork, and designs based on text descriptions, leading to widespread adoption among artists, designers, and the general public.\nIn late 2022, the public release of ChatGPT revolutionized the accessibility and application of generative AI for general-purpose text-based tasks. The system's ability to engage in natural conversations, generate creative content, assist with coding, and perform various analytical tasks captured global attention and sparked widespread discussion about AI's potential impact on work, education, and creativity.\nIn March 2023, GPT-4's release represented another jump in generative AI capabilities. A team from Microsoft Research controversially argued that it \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.\" However, this assessment was contested by other scholars who maintained that generative AI remained \"still far from reaching the benchmark of 'general human intelligence'\" as of 2023. Later in 2023, Meta released ImageBind, an AI model combining multiple modalities including text, images, video, thermal data, 3D data, audio, and motion, paving the way for more immersive generative AI applications.\nIn December 2023, Google unveiled Gemini, a multimodal AI model available in four versions: Ultra, Pro, Flash, and Nano. The company integrated Gemini Pro into its Bard chatbot and announced plans for \"Bard Advanced\" powered by the larger Gemini Ultra model. In February 2024, Google unified Bard and Duet AI under the Gemini brand, launching a mobile app on Android and integrating the service into the Google app on iOS.\nIn March 2024, Anthropic released the Claude 3 family of large language models, including Claude 3 Haiku, Sonnet, and Opus. The models demonstrated significant improvements in capabilities across various benchmarks, with Claude 3 Opus notably outperforming leading models from OpenAI and Google. In June 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated improved performance compared to the larger Claude 3 Opus, particularly in areas such as coding, multistep workflows, and image analysis.\n\nAsia–Pacific countries are significantly more optimistic than Western societies about generative AI and show higher adoption rates. Despite expressing concerns about privacy and the pace of change, in a 2024 survey, 68% of Asia-Pacific respondents believed that AI was having a positive impact on the world, compared to 57% globally. According to a survey by SAS and Coleman Parkes Research, China in particular has emerged as a global leader in generative AI adoption, with 83% of Chinese respondents using the technology, exceeding both the global average of 54% and the U.S. rate of 65%. This leadership is further evidenced by China's intellectual property developments in the field, with a UN report revealing that Chinese entities filed over 38,000 generative AI patents from 2014 to 2023, substantially surpassing the United States in patent applications. A 2024 survey on the Chinese social app Soul reported that 18% of respondents born after 2000 used generative AI \"almost every day\", and that over 60% of respondents like or love AI-generated content, while less than 3% dislike or hate it.\n\n\n== Applications ==\nNotable types of generative AI models include generative pre-trained transformers (GPTs), generative adversarial networks (GANs), and variational autoencoders (VAEs). Generative AI systems are multimodal if they can process multiple types of inputs or generate multiple types of outputs. For example, GPT-4o can both process and generate text, images and audio.\nGenerative AI has made its appearance in a wide variety of industries, radically changing the dynamics of content creation, analysis, and delivery. In healthcare, for instance, generative AI accelerates drug discovery by creating molecular structures with target characteristics and generates radiology images for training diagnostic models. This ability not only enables faster and cheaper development but also enhances medical decision-making. In finance, generative AI services help create datasets and automate reports using natural language. It automates content creation, produces synthetic financial data, and tailors customer communications. It also powers chatbots and virtual agents. Collectively, these technologies enhance efficiency, reduce operational costs, and support data-driven decision-making in financial institutions. The media industry makes use of generative AI for numerous creative activities such as music composition, scriptwriting, video editing, and digital art. The educational sector is impacted as well, since the tools make learning personalized through creating quizzes, study aids, and essay composition. Both the teachers and the learners benefit from AI-based platforms that suit various learning patterns. In the educational field, in Colombia, student use of Meta's generative AI programs resulted in a decline in scores.\n\n\n=== Text and software code ===\n\nGenerative AI systems trained on words or word tokens include GPT-3, GPT-4, GPT-4o, LaMDA, LLaMA, BLOOM, Gemini, Claude and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks. Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\nIn addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs. Examples include OpenAI Codex, Tabnine, GitHub Copilot, Microsoft Copilot, and VS Code fork Cursor.\nSome AI assistants help candidates cheat during online coding interviews by providing code, improvements, and explanations. Their clandestine interfaces minimize the need for eye movements that would expose cheating to the interviewer.\n\n\n=== Images ===\n\nProducing high-quality visual art is a prominent application of generative AI. Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, FLUX.1, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer. Datasets include LAION-5B and others (see List of datasets in com\n\n---\n\nIndex: 2\nTitle: Artificial general intelligence\nSource: https://en.wikipedia.org/wiki/Artificial_general_intelligence\nContent: Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\nSome researchers argue that state‑of‑the‑art large language models (LLMs) already exhibit signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. Beyond AGI, artificial superintelligence (ASI) would outperform the best human abilities across every domain by a wide margin.\nUnlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are achieved.\nCreating AGI is a primary goal of AI research and of companies such as OpenAI, Google, and Meta. A 2020 survey identified 72 active AGI research and development projects across 37 countries.\nThe timeline for achieving human‑level intelligence AI remains deeply contested. Recent surveys of AI researchers give median forecasts ranging from the late 2020s to mid‑century, while still recording significant numbers who expect arrival much sooner—or never at all. There is debate on the exact definition of AGI and regarding whether modern LLMs such as GPT-4 are early forms of emerging AGI. AGI is a common topic in science fiction and futures studies.\nContention exists over whether AGI represents an existential risk. Many AI experts have stated that mitigating the risk of human extinction posed by AGI should be a global priority. Others find the development of AGI to be in too remote a stage to present such a risk.\n\n\n== Terminology ==\nAGI is also known as strong AI, full AI, human-level AI, human-level intelligent AI, or general intelligent action.\nSome academic sources reserve the term \"strong AI\" for computer programs that will experience sentience or consciousness. In contrast, weak AI (or narrow AI) is able to solve one specific problem but lacks general cognitive abilities. Some academic sources use \"weak AI\" to refer more broadly to any programs that neither experience consciousness nor have a mind in the same sense as humans.\nRelated concepts include artificial superintelligence and transformative AI. An artificial superintelligence (ASI) is a hypothetical type of AGI that is much more generally intelligent than humans, while the notion of transformative AI relates to AI having a large impact on society, for example, similar to the agricultural or industrial revolution.\nA framework for classifying AGI by performance and autonomy was proposed in 2023 by Google DeepMind researchers. They define five performance levels of AGI: emerging, competent, expert, virtuoso, and superhuman. For example, a competent AGI is defined as an AI that outperforms 50% of skilled adults in a wide range of non-physical tasks, and a superhuman AGI (i.e. an artificial superintelligence) is similarly defined but with a threshold of 100%. They consider large language models like ChatGPT or LLaMA 2 to be instances of emerging AGI (comparable to unskilled humans). Regarding the autonomy of AGI and associated risks, they define five levels: tool (fully in human control), consultant, collaborator, expert, and agent (fully autonomous).\n\n\n== Characteristics ==\n\nVarious popular definitions of intelligence have been proposed. One of the leading proposals is the Turing test. However, there are other well-known definitions, and some researchers disagree with the more popular approaches.\n\n\n=== Intelligence traits ===\nResearchers generally hold that a system is required to do all of the following to be regarded as an AGI:\n\nreason, use strategy, solve puzzles, and make judgments under uncertainty\nrepresent knowledge, including common sense knowledge\nplan\nlearn\ncommunicate in natural language\nif necessary, integrate these skills in completion of any given goal\nMany interdisciplinary approaches (e.g. cognitive science, computational intelligence, and decision making) consider additional traits such as imagination (the ability to form novel mental images and concepts) and autonomy.\nComputer-based systems that exhibit many of these capabilities exist (e.g. see computational creativity, automated reasoning, decision support system, robot, evolutionary computation, intelligent agent). There is debate about whether modern AI systems possess them to an adequate degree.\n\n\n=== Physical traits ===\nOther capabilities are considered desirable in intelligent systems, as they may affect intelligence or aid in its expression. These include:\n\nthe ability to sense (e.g. see, hear, etc.), and\nthe ability to act (e.g. move and manipulate objects, change location to explore, etc.)\nThis includes the ability to detect and respond to hazard.\nAlthough the ability to sense (e.g. see, hear, etc.) and the ability to act (e.g. move and manipulate objects, change location to explore, etc.) can be desirable for some intelligent systems, these physical capabilities are not strictly required for an entity to qualify as AGI—particularly under the thesis that large language models (LLMs) may already be or become AGI. Even from a less optimistic perspective on LLMs, there is no firm requirement for an AGI to have a human-like form; being a silicon-based computational system is sufficient, provided it can process input (language) from the external world in place of human senses. This interpretation aligns with the understanding that AGI has never been proscribed a particular physical embodiment and thus does not demand a capacity for locomotion or traditional \"eyes and ears\". It can be regarded as sufficient for an intelligent computer to interact with other systems, to invoke or regulate them, to achieve specific goals, including altering a physical environment, as the fictional HAL 9000 in the motion picture 2001: A Space Odyssey was both programmed and tasked to.\n\n\n=== Tests for human-level AGI ===\nSeveral tests meant to confirm human-level AGI have been considered, including:\n\nThe Turing Test (Turing)\nProposed by Alan Turing in his 1950 paper \"Computing Machinery and Intelligence\", this test involves a human judge engaging in natural language conversations with both a human and a machine designed to generate human-like responses. The machine passes the test if it can convince the judge it is human a significant fraction of the time. Turing proposed this as a practical measure of machine intelligence, focusing on the ability to produce human-like responses rather than on the internal workings of the machine.\nTuring described the test as follows:\nThe idea of the test is that the machine has to try and pretend to be a man, by answering questions put to it, and it will only pass if the pretence is reasonably convincing. A considerable portion of a jury, who should not be expert about machines, must be taken in by the pretence.\nIn 2014, a chatbot named Eugene Goostman, designed to imitate a 13-year-old Ukrainian boy, reportedly passed a Turing Test event by convincing 33% of judges that it was human. However, this claim was met with significant skepticism from the AI research community, who questioned the test's implementation and its relevance to AGI.\nIn 2023, it was claimed that \"AI is closer to ever\" to passing the Turing test, though the article's authors reinforced that imitation (as \"large language models\" ever closer to passing the test are built upon) is not synonymous with \"intelligence\". Further, as AI intelligence and human intelligence may differ, \"passing the Turing test is good evidence a system is intelligent, failing it is not good evidence a system is not intelligent.\"\nA 2024 study suggested that GPT-4 was identified as human 54% of the time in a randomized, controlled version of the Turing Test—surpassing older chatbots like ELIZA while still falling behind actual humans (67%).\nA 2025 pre‑registered, three‑party Turing‑test study by Cameron R. Jones and Benjamin K. Bergen showed that GPT-4.5 was judged to be the human in 73% of five‑minute text conversations—surpassing the 67% humanness rate of real confederates and meeting the researchers’ criterion for having passed the test.\nThe Robot College Student Test (Goertzel)\nA machine enrolls in a university, taking and passing the same classes that humans would, and obtaining a degree. LLMs can now pass university degree-level exams without even attending the classes.\nThe Employment Test (Nilsson)\nA machine performs an economically important job at least as well as humans in the same job. AIs are now replacing humans in many roles as varied as fast food and marketing.\nThe Ikea test (Marcus)\nAlso known as the Flat Pack Furniture Test. An AI views the parts and instructions of an Ikea flat-pack product, then controls a robot to assemble the furniture correctly.\nThe Coffee Test (Wozniak)\nA machine is required to enter an average American home and figure out how to make coffee: find the coffee machine, find the coffee, add water, find a mug, and brew the coffee by pushing the proper buttons. Robots developed by Figure AI and other robotics companies can perform tasks like this.\nThe Modern Turing Test (Suleyman)\nAn AI model is given $100,000 and has to obtain $1 million.\n\n\n=== AI-complete problems ===\n\nA problem is informally called \"AI-complete\" or \"AI-hard\" if it is believed that in order to solve it, one would need to implement AGI, because the solution is beyond the capabilities of a purpose-specific algorithm.\nThere are many problems that have been conjectured to require general intelligence to solve as well as humans. Examples include computer vision, natural language understanding, and dealing with unexpected circumstances while solving any real-world problem. Even a specific task like translation requires a machine to read and write in both languages, follow the author's argument (reason), understand the context (knowledge), and faithfully reproduce the author's original intent (social intelligence). All of these problems need to be solved simultaneously in order to reach human-level machine performance.\nHowever, many of these tasks can now be performed by modern large language models. According to Stanford University's 2024 AI index, AI has reached human-level performance on many benchmarks for reading comprehension and visual reasoning.\n\n\n== History ==\n\n\n=== Classical AI ===\n\nModern AI research began in the mid-1950s. The first generation of AI researchers were convinced that artificial general intelligence was possible and that it would exist in just a few decades. AI pioneer Herbert A. Simon wrote in 1965: \"machines will be capable, within twenty years, of doing any work a man can do.\"\nTheir predictions were the inspiration for Stanley Kubrick and Arthur C. Clarke's fictional character HAL 9000, who embodied what AI researchers believed they could create by the year 2001. AI pioneer Marvin Minsky was a consultant on the project of making HAL 9000 as realistic as possible according to the consensus predictions of the time. He said in 1967, \"Within a generation... the problem of creating 'artificial intelligence' will substantially be solved\".\nSeveral classical AI projects, such as Doug Lenat's Cyc project (that began in 1984), and Allen Newell's Soar project, were directed at AGI.\nHowever, in the early 1970s, it became obvious that researchers had grossly underestimated the difficulty of the project. Funding agencies became skeptical of AGI and put researchers under increasing pressure to produce useful \"applied AI\". In the early 1980s, Japan's Fifth Generation Computer Project revived interest in AGI, setting out a ten-year timeline that included AGI goals like \"carry on a casual conversat\n\n---\n\nIndex: 3\nTitle: Applications of artificial intelligence\nSource: https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence\nContent: Artificial intelligence is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. Artificial intelligence (AI) has been used in applications throughout industry and academia. Within the field of Artificial Intelligence, there are multiple subfields. The subfield of Machine learning has been used for various scientific and commercial purposes including language translation, image recognition, decision-making, credit scoring, and e-commerce. In recent years, there have been massive advancements in the field of Generative Artificial Intelligence, which uses generative models to produce text, images, videos or other forms of data. This article describes applications of AI in different sectors. \n\n\n== Agriculture ==\n\nIn agriculture, AI has been proposed as a way for farmers to identify areas that need irrigation, fertilization, or pesticide treatments to increase yields, thereby improving efficiency. AI has been used to attempt to classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and optimize irrigation.\n\n\n== Architecture and design ==\nAI in architecture has created a way for architects to create things beyond human understanding. AI implementation of machine learning text-to-render technologies, like DALL-E and stable Diffusion, gives power to visualization complex.\nAI allows designers to demonstrate their creativity and even invent new ideas while designing. In future, AI will not replace architects; instead, it will improve the speed of translating ideas sketching.\n\n\n== Business ==\n\n\n=== Content extraction ===\nAn optical character reader is used in the extraction of data in business documents like invoices and receipts. It can also be used in business contract documents e.g. employment agreements to extract critical data like employment terms, delivery terms, termination clauses, etc.\n\n\n== Computer science ==\n\n\n=== Programming assistance ===\n\n\n==== AI-powered code assisting tools ====\nAI can be used for real-time code completion, chat, and automated test generation. These tools are typically integrated with editors and IDEs as plugins. They differ in functionality, quality, speed, and approach to privacy. Code suggestions could be incorrect, and should be carefully reviewed by software developers before accepted. GitHub Copilot is one example. It was developed by GitHub and OpenAI and is able to autocomplete code in multiple programming languages.\n\n\n==== Neural network design ====\nAI can be used to create other AIs. For example, around November 2017, Google's AutoML project to evolve new neural net topologies created NASNet, a system optimized for ImageNet and POCO F1. NASNet's performance exceeded all previously published performance on ImageNet.\n\n\n==== Quantum computing ====\n\nMachine learning has been used for noise-cancelling in quantum technology, including quantum sensors. Moreover, there is substantial research and development of using quantum computers with machine learning algorithms. For example, there is a prototype, photonic, quantum memristive device for neuromorphic (quantum-)computers (NC)/artificial neural networks and NC-using quantum materials with some variety of potential neuromorphic computing-related applications, and quantum machine learning is a field with some variety of applications under development. AI could be used for quantum simulators which may have the application of solving physics and chemistry problems as well as for quantum annealers for training of neural networks for AI applications. There may also be some usefulness in chemistry, e.g. for drug discovery, and in materials science, e.g. for materials optimization/discovery (with possible relevance to quantum materials manufacturing).\n\n\n=== Historical contributions ===\nAI researchers have created many tools to solve the most difficult problems in computer science. Many of their inventions have been adopted by mainstream computer science and are no longer considered AI. All of the following were originally developed in AI laboratories:\n\nTime sharing\nInteractive interpreters\nGraphical user interfaces and the computer mouse\nRapid application development environments\nThe linked list data structure\nAutomatic storage management\nSymbolic programming\nFunctional programming\nDynamic programming\nObject-oriented programming\nOptical character recognition\nConstraint satisfaction\n\n\n== Customer service ==\n\n\n=== Human resources ===\n\nAnother application of AI is in human resources. AI can screen resumes and rank candidates based on their qualifications, predict candidate success in given roles, and automate repetitive communication tasks via chatbots.\n\n\n=== Job search ===\nAI has simplified the recruiting/job search process for both recruiters and job seekers. According to Raj Mukherjee from Indeed, 65% of job searchers search again within 91 days after hire. An AI-powered engine streamlines the complexity of job hunting by assessing information on job skills, salaries, and user tendencies, matching job seekers to the most relevant positions. Machine intelligence calculates appropriate wages and highlights resume information for recruiters using NLP, which extracts relevant words and phrases from text. Another application is an AI resume builder that compiles a CV in 5 minutes. Chatbots assist website visitors and refine workflows.\n\n\n=== Online and telephone customer service ===\n\nAI underlies avatars (automated online assistants) on web pages. It can reduce operation and training costs. Pypestream automated customer service for its mobile application to streamline communication with customers.\nA Google app analyzes language and converts speech into text. The platform can identify angry customers through their language and respond appropriately. Amazon uses a chatbot for customer service that can perform tasks like checking the status of an order, cancelling orders, offering refunds and connecting the customer with a human representative. Generative AI (GenAI), such as ChatGPT, is increasingly used in business to automate tasks and enhance decision-making.\n\n\n=== Hospitality ===\nIn the hospitality industry, AI is used to reduce repetitive tasks, analyze trends, interact with guests, and predict customer needs. AI hotel services come in the form of a chatbot, application, virtual voice assistant and service robots.\n\n\n== Education ==\n\nAI elevates teaching, focusing on significant issues like the knowledge nexus and educational equality. The evolution of AI in education and technology should be used to improve human capabilities in relationships where they do not replace humans. UNESCO recognizes the future of AI in education as an instrument to reach Sustainable Development Goal 4, called \"Inclusive and Equitable Quality Education.\"\nThe World Economic Forum also stresses AI's contribution to students' overall improvement and transforming teaching into a more enjoyable process.\n\n\n=== Personalized learning ===\nAI driven tutoring systems (such as Khan Academy, Duolingo and Carnegie Learning) are the forefoot of delivering personalized education.\nThese platforms leverage AI algorithms to analyze individual learning patterns, strengths, and weaknesses, enabling the customization of content and Algorithm to suit each student's pace and style of learning.\n\n\n=== Administrative efficiency ===\nIn educational institutions, AI is increasingly used to automate routine tasks like attendance tracking, grading and marking, which allows educators to devote more time to interactive teaching and direct student engagement.\nFurthermore, AI tools are employed to monitor student progress, analyze learning behaviors, and predict academic challenges, facilitating timely and proactive interventions for students who may be at risk of falling behind.\n\n\n=== Ethical and privacy concerns ===\nDespite the benefits, the integration of AI in education raises significant ethical and privacy concerns, particularly regarding the handling of sensitive student data.\nIt is imperative that AI systems in education are designed and operated with a strong emphasis on transparency, security, and respect for privacy to maintain trust and uphold the integrity of educational practices.\nMuch of the regulation will be influenced by the AI Act, the world's first comprehensive AI law.\n\n\n== Energy and environment ==\n\n\n=== Energy system ===\nPower electronics converters are used in renewable energy, energy storage, electric vehicles and high-voltage direct current transmission. These converters are failure-prone, which can interrupt service and require costly maintenance or catastrophic consequences in mission critical applications. AI can guide the design process for reliable power electronics converters, by calculating exact design parameters that ensure the required lifetime.\nThe U.S. Department of Energy wrote in an April 2024 report that AI may have applications in modeling power grids, reviewing federal permits with large language models, predicting levels of renewable energy production, and improving the planning process for electrical vehicle charging networks. Other studies have suggested that machine learning can be used for energy consumption prediction and scheduling, e.g. to help with renewable energy intermittency management (see also: smart grid and climate change mitigation in the power grid).\n\n\n=== Environmental monitoring ===\n\nAutonomous ships that monitor the ocean, AI-driven satellite data analysis, passive acoustics or remote sensing and other applications of environmental monitoring make use of machine learning.\nFor example, \"Global Plastic Watch\" is an AI-based satellite monitoring-platform for analysis/tracking of plastic waste sites to help prevention of plastic pollution – primarily ocean pollution – by helping identify who and where mismanages plastic waste, dumping it into oceans.\n\n\n=== Early-warning systems ===\nMachine learning can be used to spot early-warning signs of disasters and environmental issues, possibly including natural pandemics, earthquakes, landslides, heavy rainfall, long-term water supply vulnerability, tipping-points of ecosystem collapse, cyanobacterial bloom outbreaks, and droughts.\n\n\n=== Economic and social challenges ===\n\nAI for Good is a platform launched in 2017 by the International Telecommunication Union (ITU) agency of the United Nations (UN). The goal of the platform is to use AI to help achieve the UN's Sustainable Development Goals.\nThe University of Southern California launched the Center for Artificial Intelligence in Society, with the goal of using AI to address problems such as homelessness. Stanford researchers use AI to analyze satellite images to identify high poverty areas.\n\n\n== Entertainment and media ==\n\n\n=== Media ===\n\nAI applications analyze media content such as movies, TV programs, advertisement videos or user-generated content. The solutions often involve computer vision.\nTypical scenarios include the analysis of images using object recognition or face recognition techniques, or the analysis of video for scene recognizing scenes, objects or faces. AI-based media analysis can facilitate media search, the creation of descriptive keywords for content, content policy monitoring (such as verifying the suitability of content for a particular TV viewing time), speech to text for archival or other purposes, and the detection of logos, products or celebrity faces for ad placement.\n\nMotion interpolation\nPixel-art scaling algorithms\nImage scaling\nImage restoration\nPhoto colorization\nFilm restoration and video upscaling\nPhoto tagging\nAutomated species identification (such as identifying plants, fungi and animals with an app)\nText-to-image models such as DALL-E, Midjourney and Stable Diffusion\nImage to video\nText to video such as Make-A-Video from Meta, Imagen video and Phenaki from Google\nText to music with AI models such as MusicLM\nText to sp\n\n---\n",
  "arxiv_docs": "Index: 1\nTitle: ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning\nPublished: 2023-11-07\nAuthors: Julia Kaltenborn, Charlotte E. E. Lange, Venkatesh Ramesh, Philippe Brouillard, Yaniv Gurwicz, Chandni Nagda, Jakob Runge, Peer Nowack, David Rolnick\nSource: Arxiv research paper\nContent: ClimateSet: A Large-Scale\nClimate Model Dataset for Machine Learning\nJulia Kaltenborn∗\nMila Quebec AI Institute\n& McGill University\nCharlotte Emilie Elektra Lange\nMila Quebec AI Institute\n& University of Osnabrück\nVenkatesh Ramesh\nMila Quebec AI Institute\n& University of Montreal\nPhilippe Brouillard\nMila Quebec AI Institute\n& University of Montreal\nYaniv Gurwicz\nIntel Labs\nChandni Nagda\nUniversity of Illinois at\nUrbana-Champaign\nJakob Runge\nGerman Aerospace Center\n& Technische Universität Berlin\nPeer Nowack\nKarlsruhe Institute\nof Technology\nDavid Rolnick\nMila Quebec AI Institute\n& McGill University\nAbstract\nClimate models have been key for assessing the impact of climate change and\nsimulating future climate scenarios. The machine learning (ML) community has\ntaken an increased interest in supporting climate scientists’ efforts on various tasks\nsuch as climate model emulation, downscaling, and prediction tasks. Many of those\ntasks have been addressed on datasets created with single climate models. However,\nboth the climate science and ML communities have suggested that to address those\ntasks at scale, we need large, consistent, and ML-ready climate model datasets.\nHere, we introduce ClimateSet, a dataset containing the inputs and outputs of\n36 climate models from the Input4MIPs and CMIP6 archives. In addition, we\nprovide a modular dataset pipeline for retrieving and preprocessing additional\nclimate models and scenarios. We showcase the potential of our dataset by using\nit as a benchmark for ML-based climate model emulation. We gain new insights\nabout the performance and generalization capabilities of the different ML models\nby analyzing their performance across different climate models. Furthermore, the\ndataset can be used to train an ML emulator on several climate models instead\nof just one. Such a “super emulator” can quickly project new climate change\nscenarios, complementing existing scenarios already provided to policymakers. We\nbelieve ClimateSet will create the basis needed for the ML community to tackle\nclimate-related tasks at scale.\n1\nIntroduction\nClimate change poses a significant and increasing threat to humans and the environment. Understand-\ning and projecting future climate scenarios is essential to mitigating and adapting to climate change.\nThose future climate scenarios - the “Shared Socioeconomic Pathways” (SSP) 2 are determined by\nclimate forcer emissions and depend on socioeconomic decisions made by humanity. Here, the term\n“climate forcers” refers to greenhouse gases (GHG), aerosols, and aerosol precursors, among others.\n∗Address correspondence to julia.kaltenborn[at]mail.mcgill.ca\n2For readers who are new to climate modeling terminology, we recommend the glossary by IPCC (2022),\nalso available on https://www.ipcc.ch/sr15/chapter/glossary/.\n37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks.\narXiv:2311.03721v1  [cs.LG]  7 Nov 2023\nTo navigate citizens’ future in a changing climate, policymakers rely heavily on future simulations\nof our climate, summarized in reports for the Intergovernmental Panel on Climate Change (IPCC),\ne.g. Arias et al. (2021)). Those simulations are traditionally created by climate models, which are col-\nlected in the Coupled Model Intercomparison Project (CMIP; currently in Phase 6). Climate models\nare based on physical parameters that describe the climate and Earth system; these models simulate\nthe climate under different forcing scenarios, e.g. varying greenhouse gas emissions. However, even\non top high-performance computing (HPC) clusters, typical climate model simulations take months\nto run (Balaji et al., 2017).\nThe machine learning (ML) community has taken increased interest in supporting the climate science\ncommunity in their efforts to scale and accelerate climate-related modeling tasks. These tasks include\nclimate emulation/projection, downscaling, and general prediction tasks. Climate-related tasks also\npose interesting ML challenges due to the high dimensionality of the data, relatively low sample size,\nand inherent distribution shifts within the data. When approaching those climate-related tasks, ML\nmodels have typically leveraged one climate model (Watson-Parris et al., 2022; Cachay et al., 2021;\nMansfield et al., 2020; Krasnopolsky et al., 2013; Castruccio et al., 2014; Holden and Edwards, 2010;\nBeusch et al., 2020), and only rarely several climate models (Nguyen et al., 2023; Yu et al., 2022).\nThis runs counter to the standard practice in ML of leveraging massive datasets. This discrepancy\nmay be due to the difficulty in retrieving, preprocessing, and handling climate data correctly without\nsignificant domain knowledge. Indeed the ML community has experienced difficulties in retrieving\ndata of several climate models Nguyen et al. (2023) and making them consistent Busecke and\nAbernathey (2020). Those data challenges might limit the community’s ability to contribute to\nclimate-related modeling tasks.\nWhile the need for a consistent, easy-to-retrieve, and large climate model dataset to train ML models\nis currently unmet, it has been addressed in parts. For example, these desired datasets can be found\nfor weather (WeatherBench by Rasp et al. (2020)) and satellite data (EarthNet2021 by Requena-\nMesa et al. (2021)) rather than climate data. The access to large-scale weather data enabled the\ndevelopment of large ML weather forecasting models (Lam et al., 2022; Bi et al., 2022; Pathak\net al., 2022; Gao et al., 2022). Additionally, ClimaX (Nguyen et al., 2023) – the first climate and\nweather-related large-scale model – relies primarily on weather data. However, we cannot solely use\nweather data capturing “the past”, to address climate change related questions concerning “the future”.\nExtrapolation into such a future is difficult for ML models, especially under strong distribution shifts\nin space and time. Thus, large-scale and consistent ML datasets are needed not only for weather,\nbut also for climate. Efforts have been made to provide such data: xmip (Busecke and Abernathey,\n2020) provides the tools to create more consistent climate model data, however, it does not address\nall inconsistencies and e.g. cannot align the different temporal and spatial resolutions among climate\ndata. ClimateBench (Watson-Parris et al., 2022) provides a consistent, ML-ready dataset for climate\nemulation. A drawback to this dataset is that it provides only one climate model. Therefore, it does\nnot capture the multi-model uncertainty that is essential for informing policy making, and is limited\nin the amount of training data it can provide to ML tasks. The need expressed by both the ML\nand climate science communities (Dueben et al., 2022; Runge et al., 2019; Mansfield et al., 2020;\nWatson-Parris, 2021; Chantry et al., 2021) for a consistent, large, and ML-ready dataset has not yet\nbeen addressed jointly for climate data.\nHere, we introduce ClimateSet – a consistent, multi-climate-model dataset. We showcase the value of\nthe dataset for the task of climate emulation; however, the dataset can also be used for a wide variety\nof other tasks.\nOur main contributions are:\n• We introduce the ClimateSet data pipeline, which can be used to retrieve and preprocess\nclimate model data from CMIP6 (climate model outputs) and Input4MIPs (climate model\ninputs) for climate-related ML tasks.\n• We use this pipeline to build a core ClimateSet dataset with outputs of 36 climate models;\nand inputs for the emission fields of 4 different Shared Socioeconomic Pathway (SSP)\nscenarios and historical data.\n• We use ClimateSet to compare state-of-the-art ML methods across different climate models\non a climate model emulation task. We emulate temperature and precipitation responses to\nclimate forcers, obtaining results that are both qualitatively different and more reliable than\nwas possible in previous work.\n2\nInput4MIPs\nHistoric & future \nemissions for \ndifferent shared \nsocio-economic \npathways (SSP) \nof humanity\nClimate \nProjection\nExtreme Weather \nPrediction\nDownscaling\nA) Data Basis\nLarge Climate\nModels\nCMIP6\nOutputs of \nnumerical climate \nmodels (ESMs) \nfor SSPs: Climate \nvariables showing \ndifferent futures \nEarth System Models\nB) Core \nClimateSet\nC) Extension \nPipeline\nD) Use Cases\nESMs\nScenarios\nEnsemble members\nVariables\nSpatial resolution (km)\nTemporal resolution\n36\n5\n1\n2\nmon\n250\nCMIP6\nForcing Agents\nScenarios\nHeight levels\nSpatial resolution (km)\nTemporal resolution\n4\n5\n1\nmon\n250\nInput4MIPs\nDownloader\nXMIP\nRaw \nResolution\nClimateSet\nPreprocessor\nForcing Agents\nScenarios\nHeight levels\nSpatial resolution (km)\nTemporal resolution\nInput4MIPs\nESMs\nScenarios\nEnsemble members\nVariables\nSpatial resolution (km)\nTemporal resolution\nCMIP6\nExtended \nClimateSet\nE) Tools\nDownloader\nPreprocessor\nClouds / Servers\n+\n+\nFigure 1: ClimateSet. A) ClimateSet builds on the Input4MIPs and CMIP6 datasets made available\nthrough multiple climate modeling teams on the Earth System Grid Federation (ESGF) servers. B)\nClimateSet consists of a preprocessed, ML-ready core dataset that includes inputs and outputs for 5\nscenarios, 4 climate forcing agents, 2 climatic variables (temperature and precipitation), for a set of\n36 climate models. It is currently made publicly available through the Digital Research Alliance of\nCanada. C) The core dataset can be extended to include different variables, height levels, ensemble\nmembers, scenarios and any other information made available from climate models on the CMIP6\nserver of ESGF. The downloader and preprocessing pipelines are available on our GitHub repository.\nD) Potential use cases for ClimateSet range from climate projection, climate data downscaling,\nextreme weather prediction in different warming scenarios, to large ML climate models. E) The main\ntools provided through ClimateSet are the downloader and the preprocessor to make the climate model\ndata consistent with each other. For further information visit https://climateset.github.io.\n(The 3D Earth System Model visualization was created by Boris Sakschewski, used with permission).\n2\nClimateSet\nThe core dataset of ClimateSet consists of 36 climate models and their corresponding greenhouse\ngases, aerosols and aerosol precursor emission inputs for five different scenarios. The core dataset can\nbe extended with the pipeline we provide. For an overview of ClimateSet refer to Fig. 1. The dataset\nand the pipeline are both publicly available on https://climateset.github.io. ClimateSet\nserves two main purposes: (1) Providing the amount of training data needed for large-scale ML\nmodels; and (2) capturing the projection uncertainty across climate models that is key for climate\npolicy making. Both purposes can only be fulfilled by a dataset containing several climate models.\nThe following describes the core dataset, how the data was collected, its usage and limitations.\n2.1\nDatasets\n2.1.1\nCMIP6\nCMIP6. The backbone of the ClimateSet data pipeline is the Coupled Model Intercomparison Project\nPhase 6 (CMIP6), an archive uniting climate model outputs from numerous sources (Eyring et al.,\n2016). CMIP6 is used to inform the IPCC Assessment Reports and represents the largest available\narchive of comparable climate datasets (Petrie et al., 2021; Balaji et al., 2018) with 3.7 million\ndatasets and an expected total size of 20-80 PB. The core-data of ClimateSet are specifically climate\nmodel outputs of ScenarioMIP (O’Neill et al., 2016). ScenarioMIP contains projections of future\n3\nFigure 2: Forcing agent trajectories. Greenhouse gas (CO2, CH4), aerosol (BC), and aerosol precursor\n(SO2) emission trajectories from 2015 – 2100 for different Shared Socio-economic pathways (SSPs).\nclimate change scenarios from 58 climate models3. Each of those climate models provides a physical\nsimulation of how climate changes as a result of a forcing trajectory (SSP scenario) in the decades\nto come. The climate model receives future GHG and aerosol emission fields as input (see Sectio\n\n---\n\nIndex: 2\nTitle: Generating High-Resolution Regional Precipitation Using Conditional Diffusion Model\nPublished: 2023-12-12\nAuthors: Naufal Shidqi, Chaeyoon Jeong, Sungwon Park, Elke Zeller, Arjun Babu Nellikkattil, Karandeep Singh\nSource: Arxiv research paper\nContent: Generating High-Resolution Regional Precipitation Using Conditional\nDiffusion Model\nNaufal Shidqi1,2, Chaeyoon Jeong1,2, Sungwon Park1,2, Elke Zeller3,4, Arjun Babu Nellikkattil3,4\nand Karandeep Singh2\n1 School of Computing, KAIST, Daejeon, Republic of Korea, {naufal.shidqi, lily9991, psw0416}@kaist.ac.kr\n2 Data Science Group, IBS, Daejeon, Republic of Korea, {ksingh}@ibs.re.kr\n3 Department of Climate System, PNU, Busan, Republic of Korea, {arjunbabun, elkezeller}@pusan.ac.kr\n4 Center for Climate Physics, IBS, Busan, Republic of Korea\nAbstract\nClimate downscaling is a crucial technique\nwithin climate research, serving to project low-\nresolution (LR) climate data to higher resolu-\ntions (HR). Previous research has demonstrated\nthe effectiveness of deep learning for downscal-\ning tasks. However, most deep learning mod-\nels for climate downscaling may not perform\noptimally for high scaling factors (i.e., 4x, 8x)\ndue to their limited ability to capture the intri-\ncate details required for generating HR climate\ndata. Furthermore, climate data behaves differ-\nently from image data, necessitating a nuanced\napproach when employing deep generative mod-\nels. In response to these challenges, this paper\npresents a deep generative model for downscal-\ning climate data, specifically precipitation on a\nregional scale. We employ a denoising diffu-\nsion probabilistic model (DDPM) conditioned\non multiple LR climate variables. The proposed\nmodel is evaluated using precipitation data from\nthe Community Earth System Model (CESM)\nv1.2.2 simulation. Our results demonstrate sig-\nnificant improvements over existing baselines,\nunderscoring the effectiveness of the conditional\ndiffusion model in downscaling climate data.\nKeywords— Applied Deep Learning, Climate Sci-\nence, Climate Downscaling, Generative Model, Dif-\nfusion Model\nI.\nINTRODUCTION\nThe Earth’s climate is undergoing rapid changes, and\nits impact on the planet is becoming increasingly evident.\nThe buildup of greenhouse gases in the atmosphere, mainly\nfrom human activities like burning fossil fuels, and defor-\nestation, is causing climate change. It has significant and\nFig. 1. Overview of forward diffusion process by adding Gaus-\nsian noise to a single climate variable (total precipitation,\nPRECT) of HR data (q, left to right) and reverse diffusion pro-\ncess by gradually denoising the noisy data (pθ, right to left) con-\nditioned on XLR.\nfar-reaching effects on Earth. For instance, increased heat-\nwave frequency and intensity, extreme weather, and altered\nprecipitation patterns brought about by rising global tem-\nperatures harm agriculture and ecosystems. Therefore, it is\ncrucial to get a better understanding of the climate system.\nClimate researchers achieve this by employing both global\nand local climate models, which utilize fundamental equa-\ntions to simulate the climate system at both regional and\nglobal scales. Despite the significance of high-resolution\nsimulations in benefiting climate prediction and analysis\n[4], there are practical constraints related to computational\nrequirements and the associated costs. While global cli-\nmate models are readily available online through vari-\nous agencies, local climate models take more resources.\n“Downscaling” (a term that refers to projecting global cli-\nmate data, down onto regional scales) is a cost-effective\nmethod of approximating high-resolution data.\nClimate modelers often use one of two existing ap-\nproaches: dynamical downscaling and statistical down-\nscaling. Dynamical downscaling involves utilizing high-\nresolution (HR) regional climate models to simulate the\nintricate interactions between various elements, includ-\ning the atmosphere, land, oceans, and other climate vari-\nables. In essence, this is running a climate model on a re-\ngional scale with a high resolution. This method offers a\nmore comprehensive representation of local climate condi-\ntions but necessitates substantial computational resources\n[11]. On the other hand, statistical downscaling leverages\nclimate data to identify statistical relationships between\n1\narXiv:2312.07112v1  [cs.LG]  12 Dec 2023\nHR climate models and observed local climate conditions.\nConventional statistical techniques often struggle to cap-\nture the intricate relationships between global and local cli-\nmate patterns and the interactions among climate variables.\nStatistical downscaling can be viewed as a form of super-\nresolution (SR) task, analogous to those encountered in\ncomputer vision research. Similar to how SR tasks enhance\nthe resolution of low-resolution images, statistical down-\nscaling enhances the resolution of coarse climate data.\nPrior research has established the promise of deep learn-\ning in the context of downscaling climate models. One\nwork has employed a deep SR convolutional neural net-\nwork to facilitate the downscaling of climate variables\n[13]. Other investigations have explored alternative deep\nlearning techniques, including LSTM and various deep\nneural network-based methods, aiming to generate local-\nized climate data by incorporating climate-physics charac-\nteristics into their models [2, 8]. However, it’s worth not-\ning that these models predominantly rely on regression ap-\nproaches [10], which may exhibit limitations in handling\nhigher scale factors, i.e., 4x and 8x, and could result in\nhigh-frequency information loss due to over-smoothing, a\nconsequence of their objective functions. On the contrary,\nthe GAN-based method [1] has emerged as an alternative\nsolution for climate data downscaling. Nevertheless, it’s\nessential to acknowledge that the training of GANs can\nbe complex, requiring efforts to achieve convergence and\nthe inclusion of additional discriminator models. Further-\nmore, the success of super-resolution deep learning models\nin computer vision does not always seamlessly transfer to\nthe domain of climate data and warrants careful consider-\nation.\nTo address the limitations of previous approaches men-\ntioned above, this paper presents a denoising diffusion\nprobabilistic model (DDPM) for downscaling climate data.\nThe model is conditioned on multiple low-resolution (LR)\nclimate variables to extract the intrinsic relationships be-\ntween the input variables (LR) and the target variable (HR).\nMoreover, we experiment with how the number of climate\nvariables used in the model affects the performance, high-\nlighting the need for a careful approach when employ-\ning deep learning in climate downscaling. We evaluate our\nmodel by downscaling total precipitation (PRECT) from\nthe Community Earth System Model (CESM) v1.2.2 into\nhigh 4x and 8x scale factors. The results show substan-\ntial improvements in the performance compared to existing\nbaselines, indicating the effectiveness of the conditional\ndiffusion model in downscaling climate data. These find-\nings pave the way for future research endeavors involving\nthe use of diffusion models for the downscaling of climate\ndata from a wide range of climate model simulations.\nII.\nCONDITIONAL DIFFUSION MODEL\nOur objective is to produce high-resolution (HR) re-\ngional climate data from low-resolution (LR) global cli-\nFig. 2. Overall architecture of the denoising model εθ based on\nU-Net [9] used in DDPM [3], conditioned on three LR climate\nvariables XLR (TS, PRECT, and dPHIS). The model predicts only\nthe noise injected (εpred ) on a single target climate variable\n(PRECT) at timestep t.\nmate data, a process referred to as “climate downscaling”.\nMore specifically, given LR global-scale climate data rep-\nresented as XLR ∈RC×H\n′×W\n′\nand HR regional-scale cli-\nmate data denoted as XHR ∈RC×H×W originating from an\nunknown conditional distribution p(XHR|XLR), we adapt\ndenoising diffusion probabilistic model (DDPM) [3] for\ngenerating the downscaled climate data XHR in an itera-\ntive improvement procedure. The model initiates the gen-\neration of the downscaled output XHR\n0\nthrough a reverse\ndiffusion process in T steps, starting from a noisy data\nXHR\nT\n∼N (0,I), to intermediate data distribution XHR\nt\nand\nprogressing iteratively until reaching XHR\n0\nwhere t takes on\nvalues from T −1 to 1. The learnable reverse diffusion pro-\ncess is conditioned on XLR, denoted as p(XHR\nt−1|XHR\nt\n,XLR)\nwhere XHR\n0\n∼p(XHR|XLR), as illustrated in Figure 1. The\nintermediate data distributions at each diffusion step XHR\nt\nare obtained from a forward diffusion process which is de-\ntermined beforehand by adding fixed Gaussian noise itera-\ntively using Markov chain, denoted as q(XHR\nt\n|XHR\nt−1) which\ncan be expressed as:\nq(XHR\nt\n|XHR\nt−1) = N (XHR\nt\n|\np\n1−βtXHR\nt−1,βtI)\n(1)\nwhere βt is a pre-defined noise variance scheduling hyper-\nparameter. On the other hand, the learnable reverse Gaus-\nsian diffusion process, which is also Markov chain, can be\nmathematically defined as:\npθ(XHR\nt−1|XHR\nt\n,XLR) = N (XHR\nt−1|µθ(XLR,XHR\nt\n,t),σ2\nt I)\n(2)\nA.\nDenoising Model Training and Inference\nWe follow DDPM [3] framework as our denoising\nmodel with U-Net [9] architecture as the neural network\nbackbone as shown in Figure 2. The overall algorithm for\ntraining the model and model inference is described in Al-\ngorithm 1 and Algorithm 2 respectively.\nThe denoising model objective is to estimate the initial\nnoise ε ∼N (0,I) by minimalizing the objective function\nL1 loss, L :\n2\nAlgorithm 1 Model Training\n1: repeat\n2:\nsample (XLR,XHR\n0\n) ∼p(XLR,XHR)\n3:\nsample t ∼Uniform(1,...,T)\n4:\nsample ε ∼N (0,I)\n5:\nupsample XLR to match XHR size\n6:\ntake gradient descent step on\n7:\n∇θ =∥ε −εθ(XLR,XHR\nt\n,t) ∥,\n8:\nwith XHR\nt\n= √¯αtXHR\n0\n+√1−¯αtε\n9: until converged\nL = EXLR,XHR\nt\n,ε,t ∥ε −εθ(XLR,√¯αtXHR\n0\n+\np\n1−¯αtε,t) ∥\n(3)\nwhere εθ is the denoising model, αt = 1 −βt, and ¯αt =\n∏t\ns=1 αs. Then the trained εθ is used to iteratively denoise\na pure noisy data XHR\nT\n∼N (0,I) to generate the output\nXHR\n0\n, as summarized in Algorithm 2.\nAlgorithm 2 Model Inference\n1: sample XHR\nT\n∼N (0,I)\n2: upsample XLR to match XHR size\n3: for t = T,...,1 do\n4:\nsample z ∼N (0,I) if t > 1 elsez = 0\n5:\nXHR\nt−1 =\n1\n√αt (XHR\nt\n−1−αt\n√1−¯αt εθ(XLR,XHR\nt\n,t) +σtz)\n6: end for\n7: return XHR\n0\nB.\nConfiguring Climate Variables\nTo configure the climate variables in the denoising\nmodel, whether as conditioning input variables (XLR) or\nas target variables (XHR), one can implement it by sim-\nply using all of the variables as both conditioning input\nvariables and target variables, i.e., XLR ∈RC×H\n′×W\n′\nand\nXHR ∈RC×H×W. However, in later experiments, we dis-\ncovered that using all of the variables as conditioning in-\nput and target output is not as effective as focusing on only\none variable as the model output, i.e., XLR ∈RC×H\n′×W\n′\nand\nXHR ∈R1×H×W instead. Following the approach in [3, 10],\nthe conditioning variables XLR are concatenated with the\nXHR\nt\nalong the channel dimension, as illustrated in Figure\n2.\nIII.\nEXPERIMENT SETUP\nA.\nData\nFor our experiments, we use Surface Temperature (TS),\nTotal Precipitation (PRECT), and the gradient of Topogra-\nphy (dPHIS) climate variables from a global climate HR\nsimulation conducted with the fully-coupled, global circu-\nlation climate model CESM version 1.2.2. The HR data\nfrom the climate simulation data (XHR ∈RC×H×W) repre-\nsents daily means over the North America region for 20\nyears (N = 20 × 365 = 7300). We split the data into 5300\ndatapoints for the training, 500 for the validation, and 1500\nfor the test data. The HR data has a resolution of 213×321,\nwith each pixel representing an approximate grid reso-\nlution of 25 kilometers. We perform center cropping to\n192×256 resolution and normalization to zero means. To\ngenerate LR data (XLR ∈RC×H\n′×W\n′\n), we apply bicubic in-\nterpolation with antialiasing enabled, as in [10], to convert\nthe HR data into a coarser resolution (H\n′ ×W\n′), i.e. into\n4x and 8x scale factors. Subsequently, we upsample this\nLR data to match the target output size (H ×W) for the\nmodel’s input. We use TS, PRECT, and dPHIS from the\nLR data as the conditioning input variables of the model\nand set PRECT as the target variable for the mo\n\n---\n\nIndex: 3\nTitle: Towards Answering Climate Questionnaires from Unstructured Climate Reports\nPublished: 2023-07-27\nAuthors: Daniel Spokoyny, Tanmay Laud, Tom Corringham, Taylor Berg-Kirkpatrick\nSource: Arxiv research paper\nContent: Towards Answering Climate Questionnaires\nfrom Unstructured Climate Reports\nDaniel Spokoyny†\nTanmay Laud‡\nThomas W. Corringham‡\nTaylor Berg-Kirkpatrick‡\n†Carnegie Mellon University ‡UC San Diego\nAbstract\nThe topic of Climate Change (CC) has received\nlimited attention in NLP despite its urgency.\nActivists and policymakers need NLP tools to\neffectively process the vast and rapidly grow-\ning unstructured textual climate reports into\nstructured form. To tackle this challenge we\nintroduce two new large-scale climate question-\nnaire datasets and use their existing structure to\ntrain self-supervised models. We conduct ex-\nperiments to show that these models can learn\nto generalize to climate disclosures of differ-\nent organizations types than seen during train-\ning. We then use these models to help align\ntexts from unstructured climate documents to\nthe semi-structured questionnaires in a human\npilot study. Finally, to support further NLP\nresearch in the climate domain we introduce\na benchmark of existing climate text classifi-\ncation datasets to better evaluate and compare\nexisting models.1\n1\nIntroduction\nGlobally, tens of thousands of climate reports have\nbeen generated by different stakeholders such as\ncorporations, cities, states, and national govern-\nments either voluntarily or in response to regula-\ntory pressure. These reports disclose vital infor-\nmation on carbon emissions, impacts, and risks –\nfor example, a firm’s emissions reduction targets\nor a city’s water risk and exposure to drought. In-\ncreasingly, NLP is a critical technology supporting\nlarge scale processing of climate reports to enable\ndownstream applications like detecting corporate\ngreenwashing (Bingler et al., 2021) or identify-\ning misinformation about climate change (Meddeb\net al., 2022). However, for climate researchers to\nmake use of the information contained in these un-\nstructured text documents, their contents must first\nbe collated into semi-structured questionnaires that\nhave consistent fields across reporting bodies and\n1Corresponding Author:dspokoyn@cs.cmu.edu\nreport types. These structured questionnaires, in\nturn, allow climate researchers to compare progress\nacross different stakeholders and identify which\nareas need financing, education, policy changes\nor other resources. Currently, this extraction pro-\ncess requires an immense amount of manual effort\nresulting in whole organizations focused on map-\nping a single type of unstructured reports (Nation-\nally Determined Contribution) to a single type of\nsemi-structured questionnaires (Sustainable Devel-\nopment Goals).23\nIn order to facilitate NLP research for this task,\nwe introduce two new datasets, CLIMA-CDP and\nCLIMA-INS, which are composed of publicly ac-\ncessible semi-structured questionnaires from dif-\nferent stakeholders including cities, states and cor-\nporations. We utilize the structure of the question-\nnaires to train self-supervised classification models\nto align answers to questions (Section 5.3). Further,\nwe show how the setup of our objective allows our\nmodel to generalize to a more challenging scenario\nwhere the set of questions and the stakeholder-type\nare both different at test time (Section 5.4). Fi-\nnally, we show that models trained on CLIMA-CDP\ncan be directly applied to map passages from un-\nstructured documents into questionnaire categories,\nwhich matches the real-world use-case that climate\nresearchers need solved (Section 5.5). In Figure 1\nwe depict all three of these experiments as well as\nexamples of the different reports and stakeholder-\ntypes.\nThere are other existing climate-specific datasets\nfor detecting relevance to climate (Leippold and\nVarini, 2020), identifying stance detection (Vaid\net al., 2022a) and fact-checking (Leippold and\nDiggelmann, 2020) of social media claims. In con-\ntrast, the questionnaires we introduce have an order\nof magnitude more data, are comprehensive in both\nthe breadth of topics covered and the depth of de-\n2World Resources Institute’s: www.climatewatchdata.org\n3For more background info see Appendix B.\narXiv:2301.04253v2  [cs.CL]  27 Jul 2023\nFigure 1: We conduct 3 experi-\nments on CDP-QA. In-Domain\n(5.3) refers to training and eval-\nuating on the same stakeholder-\ntype. Cross-Domain (5.4) refers\nto training and testing on differ-\nent stakeholder-types. Finally,\nUnstructured Questionnaire Fill-\ning (5.5) involves training on\nthe whole CDP-QA corpus and\nthen using the model for map-\nping text from a CAP report to\na CDP. We use solid and dashed\narrows to denote training and in-\nference/evaluation respectively.\ntail provided making our models most suitable for\na wide range of climate applications.\nClimate reports have also been used as a source\nof unlabeled data to continue pretraining large lan-\nguage models to better adapt them for climate\nspecific tasks (Luccioni et al., 2020; Webersinke\net al., 2021). However, it remains an open question\nwhether these domain-specific models can effec-\ntively generalize since evaluation of these models\nhas been limited on the climate domain. To ad-\ndress this gap in comprehensive evaluation, we\ncollate five existing climate datasets, along with\nour two new datasets into a benchmark dataset\n(CLIMABENCH), and find that the domain-specific\nmodels like ClimateBERT underperform compared\nto existing general models (Section 5.2).\nIn summary, our contributions are as follows:\n1. We introduce two new datasets, CLIMA-CDP\nand CLIMA-INS, consisting of difficult clas-\nsification tasks that are analogous to current\nmanual work done by climate researchers, and\nconduct extensive in-domain experiments.\n2. We collate and release CLIMABENCH, an\nevaluation dataset of climate-related text\nclassification tasks and show that, counter-\nintuitively, general-purpose ML models out-\nperform domain-specific models across tasks\nwithin the benchmark.\n3. We conduct a pilot study, evaluated manually\nby a climate researcher, that uses a model\ntrained on CLIMA-CDP to populate a ques-\ntionnaire from real-world unstructured climate\nreports.\nWe believe our contributions are an important\nstep for an emerging domain of building NLP tools\nfor climate researchers. To that end, we release our\nbenchmark4 and open-source our trained models5\nto encourage researchers to extend our existing\ndatasets and contribute new ones.\n2\nRelated Work\nClimate policy evaluation is an active area of re-\nsearch in climate sciences where the goal is to eval-\nuate the effectiveness of current climate policies so\nas to inform future policy decisions (Swarnakar and\nModi, 2021; Cação et al., 2021). It allows for the\ndevelopment, assessment, and improvement of reg-\nulation, increases transparency and public support,\nand encourages public and private sector entities to\nmake pledges or increase their levels of action (Fu-\njiwara et al., 2019; Rolnick et al., 2022). NLP has\nthe potential to derive understandable insights from\npolicy texts for these applications.\nAcademic literature provides a valuable source\nof information for conducting these evaluation stud-\nies. However, a necessary first step is systematic\nevidence mapping or identifying which papers are\nrelevant to a particular policy. Berrang-Ford et al.\n(2021), for instance, build a machine learning sys-\ntem to filter scientific literature relevant to climate\nadaptation.\nAnother area of research involves utilizing un-\nstructured climate documents for topic classifica-\ntion. Corringham et al. (2021) attempt to use doc-\nument headers from unstructured Nationally De-\n4https://github.com/climabench/climabench\n5https://huggingface.co/climabench/miniLM-cdp-all\ntermined Contribution (NDC) reports as coarse-\ngrained labels to train a supervised classifier. Most\nsimilar to our CLIMA-QA work is Luccioni et al.\n(2020) who trained a model to map text passages\nfrom public financial disclosures to the 14 ques-\ntions in Task Force on Climate-related Financial\nDisclosures (TCFD). They recruited experts to\nmanually label the text passages to the TCFD ques-\ntions and only train their models on this labeled\ndata. Our work focuses on using the existing struc-\nture of large-scale public questionnaires to first\ntrain models and then apply them to unstructured\ntexts.\nNLP is also used to analyze social media data to\nunderstand public opinions and discourse around\nclimate change (Kirilenko and Stepchenkova,\n2014). CLIMATEXT (Leippold and Varini, 2020)\nand CLIMATEFEVER (Leippold and Diggelmann,\n2020) extracted and filtered documents from\nWikipedia and other sources to curate a CC corpus\nthat was further annotated by humans. In climate\nfinance, Kölbel et al. (2020) have built NLP classi-\nfiers to distinguish texts describing physical climate\nrisk versus transition risk. While these studies have\nindependently analyzed small annotated datasets,\nwe make use of semi-structured disclosure forms\ncomprising a much larger set of supervised data,\nmade available to the CC and NLP communities\nin a clean and accessible format. Similar work has\nbeen conducted manually in the CC policy evalua-\ntion community (e.g., ClimateWatch) but not over\nthe breadth and scope of documents we consider.\nFinally, benchmarks have been an effective way\nto track progress and highlight the shortcomings of\nNLP models in both general-purpose understanding\n(GLUE (Wang et al., 2018), SuperGLUE (Wang\net al., 2019)) as well as specific domains such as\nlegal NLP (LexGLUE (Chalkidis et al., 2022))\nor biomedical NLP (BLURB (Gu et al., 2022)).\nCLIMABENCH follows on this chain of thought\nto provide a unified way to evaluate models on\nCC-specific problems.\n3\nDatasets\nIn this section we first describe our two new ques-\ntionnaire datasets, CLIMA-CDP and CLIMA-INS,\nand then present all the text classification datasets\nwe collected into CLIMABENCH. We consider a\nquestionnaire, a semi-structured document, filled\nout by a stakeholder for a particular year to have a\nset of questions and answers, (Q, A) where the i-th\nquestion-answer pair {qi, ai} are both free-form\ntext. Table 1 lists a few interesting examples from\nthe newly introduced datasets. The overall statis-\ntics of each dataset are given in Table 2, the token\nlength distribution is given in Appendix Table 9\nand details are explained below.\n3.1\nCLIMA-INS\nThe annual NAIC Climate Risk Disclosure Sur-\nvey6 is a U.S. insurance regulation tool where\ninsurers file non-confidential disclosures of their\nassessments and management of climate-related\nrisks. The purpose of the survey is to enhance trans-\nparency about how insurers manage climate-related\nrisks and opportunities to enable better-informed\ncollaboration on climate-related issues. The dataset\ncontains survey responses for the years 2012-2021,\nwhere each survey consists of eight questions all\nshown in Appendix A and examples in Table 1.\nCompanies have an option to fill the survey individ-\nually or as a group (in case of a conglomerate). In\nthe case of group filing, there may be duplicate an-\nswers repeated across all subsidiaries. We remove\nsuch responses resulting in a total of 17K question-\nanswer pairs. Further, we delete the first sentence\nin each response as it contains obvious markers\n(like \"Yes, we do X.\" or \"No, we do not partici-\npate in Y.\"). The splits for training, validation and\ntesting (80%, 10%, 10%) are created by stratifying\nbased on the company so that similar responses\nfrom the same company are not seen during train\nand test.\n3.2\nCLIMA-CDP\nCarbon Disclosure Project (CDP) is an interna-\ntional organisation that runs a global disclosure\nquestionnaire for various stakeholders to report\ntheir environmental information. In 2021 alone\nover 14,000 organizations filled out the question-\nnaire which contains hundreds of unique questions.\nThe CLIMA-CDP, Dcdp, is composed of parts\n[Dcity, Dcorp, Dstate] where each part is a set of\nquestionnaires filled out by a city, company, or state\nrespectively. From the questionnaires we construct\ntwo tasks: topic classification (CDP-TOPIC) and\nquestion classification (CDP-QA).\nCDP-TOPIC The CD\n\n---\n",
  "news": [
    {
      "title": "Artificial intelligence for modeling and understanding extreme weather and climate events - Nature",
      "description": "Artificial intelligence for modeling and understanding extreme weather and climate events  Nature",
      "published date": "Mon, 24 Feb 2025 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiX0FVX3lxTE5IUnkxQm1ONWNQMzdoZWIzbTZtSUxITnNWZG1yVHVrWFFsWlVMSm5DU3FJTlpuXzVOMDd4QzV2RlZPR2huY1huOXdlaDFiWXY1WGdfMW9YQ0VxX2NtdmE4?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.nature.com",
        "title": "Nature"
      }
    },
    {
      "title": "Artificial intelligence is helping improve climate models - The Economist",
      "description": "Artificial intelligence is helping improve climate models  The Economist",
      "published date": "Wed, 13 Nov 2024 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiuAFBVV95cUxOcDZXMVlaVTdSRWJqNTZ4MF81bDFxUWFYclRIWnhVaXNCWDFQSDNWd3psUl9HWmR2aGlmZWJKSzRDbjRVenJCZnVqbFd1YnlYVkdVbVA5cHM1RXRBOG9rTTlEQUNIRDNPLXo5M2pobXp2MGdRZzNSZHl6dzZNTGlaMnhITVV0Y0laUFdzYXNGN0dIcncwRW5aQlBGSF9BQ2VwWC1CS3gxaTVPM05BOUtFdVVzdGhaRnYw?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.economist.com",
        "title": "The Economist"
      }
    },
    {
      "title": "Accelerating Climate Modeling with Generative AI - UC San Diego Today",
      "description": "Accelerating Climate Modeling with Generative AI  UC San Diego Today",
      "published date": "Mon, 02 Dec 2024 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMigwFBVV95cUxPUURwQTRCeEJjNExNM3I3U3dzdTZCeDlMVGItUWpaVXFIZ0c2RkdjaFhWU3F4VS1QNUhOLVIwQmRqR1RUVTBwNWQ3eTlWOEctczNiSDNmcmYtcm9oZmh1MjdGcXVzRy1zc3RXN0VkV3B0d0hLTkE3WWt6ekhUWkMtV1FaMA?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://today.ucsd.edu",
        "title": "UC San Diego Today"
      }
    },
    {
      "title": "Advancements and challenges of artificial intelligence in climate modeling for sustainable urban planning - Frontiers",
      "description": "Advancements and challenges of artificial intelligence in climate modeling for sustainable urban planning  Frontiers",
      "published date": "Mon, 19 May 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiogFBVV95cUxONXlCQ2w4RGNMVW9fV0FmTFdXa2FrY0VhblM0SEQyODN1eTFsUUl4a2RWdlVMWGRmRVJ0d3lnU2dtYUZQVi1IMkJWeGJqMTRIOFZRR3d2bll6N0RBOWdNbkJQMHczRXcxUk1yT2hJamF5SU1RZU9OaG5hX19ZRlVvQjlVWThCUi1vXzNRcjI1N2Q5cHE1OG5TaUhxZV84OUEzNEE?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.frontiersin.org",
        "title": "Frontiers"
      }
    },
    {
      "title": "Leveraging artificial intelligence for research and action on climate change: opportunities, challenges, and future directions - ScienceDirect.com",
      "description": "Leveraging artificial intelligence for research and action on climate change: opportunities, challenges, and future directions  ScienceDirect.com",
      "published date": "Tue, 01 Jul 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMie0FVX3lxTE5EZUI0RDFaWEtBdzhjY2JQYzAtNVNOUG9ObHB4YThSSlozbDlKUkFDUm1hRkVYWHZ4NnZuY2w3cTg4N2I5SmFjQjVmSGdvNWxfS0lIdlBVNVBBOGZnaFhXMkJ0VUNVY2V1MGUtTExlZllIc1pOeHc5TTE1aw?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.sciencedirect.com",
        "title": "ScienceDirect.com"
      }
    },
    {
      "title": "How AI could shape the future of climate science - American Physical Society",
      "description": "How AI could shape the future of climate science  American Physical Society",
      "published date": "Mon, 16 Jun 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMidEFVX3lxTFBrWGZGUkRtRVJENWlweW5nUnpGcWJnTDBKOE9jMzFsUW9hOG9uU0dZTE5uM3Q1c2M4T0RQVm05ZERlT3FZMjNlbnlMd3NVTXRUam9qTzh0ZlJUSkd2YlczZGFQMUpPeW9WclNlY0VvczlJcHJC?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.aps.org",
        "title": "American Physical Society"
      }
    },
    {
      "title": "At the Intersection of Climate and AI, Machine Learning is Revolutionizing Climate Science - Georgia Institute of Technology",
      "description": "At the Intersection of Climate and AI, Machine Learning is Revolutionizing Climate Science  Georgia Institute of Technology",
      "published date": "Wed, 22 Jan 2025 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMitgFBVV95cUxPT3dCeWdsb2IzSDNNN00wZG5kTFBjSXphYUVDOF93NVhkc1lCNWtfOXpDWjd0MFliQmhsVExLRVNrUVZkNHA2YmlIU1U5WVQ5eTIwQ254YVl5cE5BcEpCLVpuaFNTbDltaS1fY2VxOXNMQ2VkZFJDMWRzX09melp3dnFyQzRQYnU3NEdpdzRRVnViSnNKQXg2ck5kcTdUVEc5ckdsM3pVQmVON1hrTEJjRHFReUk3QQ?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.gatech.edu",
        "title": "Georgia Institute of Technology"
      }
    },
    {
      "title": "Charting the Intersection of Climate Change and AI - The Regulatory Review",
      "description": "Charting the Intersection of Climate Change and AI  The Regulatory Review",
      "published date": "Tue, 24 Dec 2024 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMimgFBVV95cUxOeEo2MW03TmRwSmxMSUkyT2ZjUVp6UThCVEVkMjhpWHZyNHF6TjR5dFFoLUdRZDJOZGx6cTN5T0NuUTdGeW5mRlhnZ0pkd0JUZ2dCSENTTWRlSjRpS253LWIwdXp3SW9CSjBxV1A3Nmcyb1hiYm1hVHBUX0tHTkVEY3JlWXBIMjBKdmtWSVVSVTdXTzdQTC1WYUFR?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.theregreview.org",
        "title": "The Regulatory Review"
      }
    },
    {
      "title": "AI: Good for Climate Models; Bad for Climate - Astrobites",
      "description": "AI: Good for Climate Models; Bad for Climate  Astrobites",
      "published date": "Thu, 12 Jun 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiXkFVX3lxTE5GVDJJVFh1SDM1R0NsS0EyWVk1N1dveThOZ3E3ekx1al84QTMwbFE4b3RrN3BZQTRJZG44RW9ucXFLRi14Yk1vMVhsNDdkcXotbXh1VnB4TkF6a2lMNlE?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://astrobites.org",
        "title": "Astrobites"
      }
    },
    {
      "title": "How AI is Making Climate Modeling Faster, Greener, and More Accurate | NVIDIA Technical Blog - NVIDIA Developer",
      "description": "How AI is Making Climate Modeling Faster, Greener, and More Accurate | NVIDIA Technical Blog  NVIDIA Developer",
      "published date": "Wed, 04 Dec 2024 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiowFBVV95cUxNQUd1UVhiaHlha3JHYTJHbW0wRVJRNW9SSFk3RmN1NkpZZWdXVEZ6UHhjOXJQZjRjTVZEalpTbnZKM3U3TXBKUVlqZ1ZVN3lmdFh0UEhLUjBrQ3pLSElpOFl3VXBHcHMzLWZfbm92YUI1bTFGQWFUTkIxUnpLZE9MNDNzbmM2ajBteFR2MXNPUS0zWFlBdTNscF96Q2FJNDlfcFdF?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://developer.nvidia.com",
        "title": "NVIDIA Developer"
      }
    },
    {
      "title": "Simpler models can outperform deep learning at climate prediction - MIT News",
      "description": "Simpler models can outperform deep learning at climate prediction  MIT News",
      "published date": "Tue, 26 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMimAFBVV95cUxQNVBsMFVzelF5X1AyNHllT2JhclBxcUo5d3g5TWd6VDBXNU14dkVNNjV6YkRfaFU5NTEwWTlpcTlpc3lwckRfeGRDNzdVbmFMNl9XSmdJR3liUkZYQ1dSMHhQMV9GZkhXalhSYWRPOVp5cnQ1RDExc0stR0Nac1NROEE0VDZIQms2blJjUGhQZjhuMXVIR2xPSQ?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://news.mit.edu",
        "title": "MIT News"
      }
    },
    {
      "title": "AI-Based Climate Modelling Market Size | CAGR of 24% - Market.us",
      "description": "AI-Based Climate Modelling Market Size | CAGR of 24%  Market.us",
      "published date": "Tue, 07 Jan 2025 06:17:10 GMT",
      "url": "https://news.google.com/rss/articles/CBMia0FVX3lxTE85RWhJTi1XNG1oUmpmZnlZdlczd2o4dkhwaE9hU0ZRMXFqWlhzS21TeTEtRzJ6ZVZoYVhkLXNxRXFNT3FfdE1YZzkyWUFQLWJkMVFnRXlPOVlrOUJJS2JtUGw5alhfbmducTdn?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://market.us",
        "title": "Market.us"
      }
    },
    {
      "title": "IBM and NASA Release Open-Source AI Model on Hugging Face for Weather and Climate Applications - IBM Newsroom",
      "description": "IBM and NASA Release Open-Source AI Model on Hugging Face for Weather and Climate Applications  IBM Newsroom",
      "published date": "Mon, 23 Sep 2024 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiygFBVV95cUxPc01GNE9oREM4OWNucDRBeG16bmNJS1c0NFliejloVmhJaVUtb1dCdXhGRy05eWdJSkozTkliLXRyLTZTTXQ2VG5tQjFMdDBVcWVydjlzS2hoa0lJZnFvVlRLaHpYeTNLQ3MzSkg4MEVfSnVfWUVUank5dnZERWhuTVNNZzFXWmJpWmh0Z0lidUhiVVZmNXdyQ3Y1WDFzUXFLSG9hb3NPbHBmbFdOZVdmZ0w1M3ZFUHFLMlRjUDRHZkxaRzBIWnMxNFFn?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://newsroom.ibm.com",
        "title": "IBM Newsroom"
      }
    },
    {
      "title": "Zooming in: Efficient regional environmental risk assessment with generative AI - Google Research",
      "description": "Zooming in: Efficient regional environmental risk assessment with generative AI  Google Research",
      "published date": "Thu, 05 Jun 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMirAFBVV95cUxNYTFUMGgxdmlEQm1MNHAxNGx5Y1UxR1VhRFpXQzJpS2laY1dKRnJER2dLQWhRQUQ5bEFmT0R1dUh2UnMtWFY5VElldzR4QkJNTGdRZkRuMmVRUnBwLW04XzY5WGJlWXlPQUhla2Q2aWQ5T3FpSDkxekpYU2xXX1lwM2xTSXFXeENUdllZeDVLdDZ3NHQzOS1TX3ZDQkN1VnpudTdFNzJPaVBDWE9k?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://research.google",
        "title": "Google Research"
      }
    },
    {
      "title": "AI for Climate Change: Opportunities and Challenges - eWeek",
      "description": "AI for Climate Change: Opportunities and Challenges  eWeek",
      "published date": "Tue, 15 Oct 2024 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMickFVX3lxTFBra2dlUzV2UHF6MFpaME9fNHByUk5xVXpHRDVGSTZDMkFoci1kUi1hUmpPbm0ySnRzYmhSR3hTajF3dUJ0RmpOQ1A3RzBINnNETk9RUUZVZ0ExSHc5bUtIMnJDcHlnSjA4QjY1Y3BtSzlPZw?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.eweek.com",
        "title": "eWeek"
      }
    },
    {
      "title": "AI-empowered next-generation multiscale climate modelling for mitigation and adaptation - Nature",
      "description": "AI-empowered next-generation multiscale climate modelling for mitigation and adaptation  Nature",
      "published date": "Wed, 25 Sep 2024 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiX0FVX3lxTE5GbnlNSXpoT2hBMWcxMU5Lb0I4MVR5ejM0ZHFzQzdaVnJFLWJFdjU2cXg4aV9aTlBGT1hmYlpkVjVCT2FNUFdiMFpHWWdYZnlBVU1Ka3ZBaUhLcWhLekxN?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.nature.com",
        "title": "Nature"
      }
    },
    {
      "title": "NOAA Research develops an AI-powered sibling to its flagship weather model - National Oceanic and Atmospheric Administration (.gov)",
      "description": "NOAA Research develops an AI-powered sibling to its flagship weather model  National Oceanic and Atmospheric Administration (.gov)",
      "published date": "Tue, 22 Jul 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiowFBVV95cUxQRkZhc0lmNWpPV01DQS1ob0xnaHhKenV1V3AwMnptR2FaTlVJVFZ0Y0V2cHdyQ01VdURDSERKS1hyblFXZDRTemZ2MHhmVlN3QzFWSFFRMk9GZVdsOEN1aUFxQWtjU2hXcDFQcTZ6N3J1dUZGQkFCWEpqVjJBZ3EwVDZfN0tEN24xM05jQkNWbEx4ZmhwS2p1aWctSUNjQWlqQy1j?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://research.noaa.gov",
        "title": "National Oceanic and Atmospheric Administration (.gov)"
      }
    },
    {
      "title": "New NVIDIA Earth-2 Generative AI Foundation Model Simulates Global Climate at Kilometer-Scale Resolution - NVIDIA Blog",
      "description": "New NVIDIA Earth-2 Generative AI Foundation Model Simulates Global Climate at Kilometer-Scale Resolution  NVIDIA Blog",
      "published date": "Tue, 10 Jun 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMirwFBVV95cUxOcTc2OXhxR2VXVWh6NGpyZC1icDB6YTRnaDN2MUFkU0lLZHRZNHhzVG54Y0RmZ3dtMGMtcGt3T3djUnBBem4tSWlSUi1NUU9wbHVaQUtZUHlySnppMDdRamVFdURGNzJ2SGdfdU90dTd3U1lQdDgzalFVdWptWG85dGh0V3UzWW5iR2tBSGNFN0NHa1hJWDZkV25TYlVYdlVYZXFFV1ZVN25ENVFPNDlv?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://blogs.nvidia.com",
        "title": "NVIDIA Blog"
      }
    },
    {
      "title": "Supercomputers and AI are helping build better climate models - The Economist",
      "description": "Supercomputers and AI are helping build better climate models  The Economist",
      "published date": "Wed, 20 Nov 2024 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMitAFBVV95cUxNSS1yallnRjFTLTZsbF9KWlk1VzNhX2RJT0t3VEZFOEJOV0dJbi1VNWtiaURXN1NfN3N6U19hUldDU3hVQnNpSHBHNEdrR0Jtd3F1bW82dWEtS3p3THhocVdUek5pVVI1TTZtNVBuUUVNTlNhNzZ3SmF6bW9ZaG0ya19iWTBoRDJxcUZvaDlKVk01LWRIby1BMW9XQnRvSDY1Tk91LW83TTdLNldnbUxyMnRaTnE?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.economist.com",
        "title": "The Economist"
      }
    },
    {
      "title": "Enhancing system resilience to climate change through artificial intelligence: a systematic literature review - Frontiers",
      "description": "Enhancing system resilience to climate change through artificial intelligence: a systematic literature review  Frontiers",
      "published date": "Mon, 30 Jun 2025 08:35:04 GMT",
      "url": "https://news.google.com/rss/articles/CBMijgFBVV95cUxPNHU4bmpFYlRjOXg5MVdWbXl5aVlXX0dLdzdjSjJncmRxWGR2Si1aM1hhTHZsb01NUnNTZDdjbWF6dlgtU2tkc25RNGdoU0JwMjlqbUZvZWVFUnhRNDRCMkJ0ZWVncjVWdmtWQ2dNNFdQN0Z2cXA3SnFwRmdtZHJONTBPTG1lWXgyem1NXzRB?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.frontiersin.org",
        "title": "Frontiers"
      }
    }
  ],
  "knowledge": {
    "topic": "Artificial Intelligence in Climate Modeling",
    "sources": [
      {
        "id": 1,
        "title": "Generative artificial intelligence",
        "authors": [
          "Wikipedia contributors"
        ],
        "source": "Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Generative_artificial_intelligence"
      },
      {
        "id": 2,
        "title": "Artificial general intelligence",
        "authors": [
          "Wikipedia contributors"
        ],
        "source": "Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Artificial_general_intelligence"
      },
      {
        "id": 3,
        "title": "Applications of artificial intelligence",
        "authors": [
          "Wikipedia contributors"
        ],
        "source": "Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence"
      },
      {
        "id": 4,
        "title": "ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning",
        "authors": [
          "Julia Kaltenborn",
          "Charlotte E. E. Lange",
          "Venkatesh Ramesh",
          "Philippe Brouillard",
          "Yaniv Gurwicz",
          "Chandni Nagda",
          "Jakob Runge",
          "Peer Nowack",
          "David Rolnick"
        ],
        "source": "arXiv",
        "url": "https://arxiv.org/abs/2311.03721"
      },
      {
        "id": 5,
        "title": "Generating High-Resolution Regional Precipitation Using Conditional Diffusion Model",
        "authors": [
          "Naufal Shidqi",
          "Chaeyoon Jeong",
          "Sungwon Park",
          "Elke Zeller",
          "Arjun Babu Nellikkattil",
          "Karandeep Singh"
        ],
        "source": "arXiv",
        "url": "https://arxiv.org/abs/2312.07112"
      },
      {
        "id": 6,
        "title": "Towards Answering Climate Questionnaires from Unstructured Climate Reports",
        "authors": [
          "Daniel Spokoyny",
          "Tanmay Laud",
          "Tom Corringham",
          "Taylor Berg-Kirkpatrick"
        ],
        "source": "arXiv",
        "url": "https://arxiv.org/abs/2301.04253"
      }
    ],
    "topics": [
      {
        "id": "t1",
        "title": "Large-scale climate datasets and pipelines for ML (ClimateSet)",
        "summary_points": [
          "ClimateSet provides a consistent, ML-ready, multi–climate-model dataset and modular pipeline that retrieves and preprocesses climate model inputs (Input4MIPs) and outputs (CMIP6) to support large-scale ML tasks in climate science.",
          "Core ClimateSet composition: outputs from 36 Earth System Models (ESMs), input emission fields for multiple Shared Socioeconomic Pathway (SSP) scenarios (including historical), and a focus initially on key variables (temperature and precipitation); the core dataset is publicly available and extensible via the provided downloader and preprocessor.",
          "Primary goals: (1) supply sufficient training data to enable large ML climate models (super emulators) that generalize across models and scenarios; (2) capture multi-model projection uncertainty important for policymaking, which single-model datasets cannot provide.",
          "Design choices address common data challenges: harmonization of variable names/units, spatial/temporal alignment across models, and automated regridding to create consistent input/output tensors suitable for ML training and benchmarking.",
          "ClimateSet demonstrates use as a benchmark for climate model emulation (temperature and precipitation), showing that ML models trained across multiple climate models gain insights into performance and generalization not obtainable from single-model datasets.",
          "Limitations noted: remaining inconsistencies across models (e.g., ensemble members, vertical levels), selection of variables and scenarios in the core release, and dependence on CMIP6/Input4MIPs availability and ESGF infrastructure."
        ],
        "subtopics": [
          {
            "id": "t1.1",
            "title": "Dataset composition and scope",
            "summary_points": [
              "Core release aggregates 36 climate models' outputs and associated emission inputs, focusing initially on monthly variables like surface temperature and precipitation across several SSP scenarios and historical runs.",
              "The dataset targets ML readiness: aligned grids, consistent units, and a standardized temporal resolution to enable direct model training without bespoke climate-domain preprocessing for each model."
            ],
            "references": [
              4
            ]
          },
          {
            "id": "t1.2",
            "title": "Pipeline, tools and extensibility",
            "summary_points": [
              "ClimateSet provides a downloader that automates retrieval from ESGF and a preprocessor (including regridding and temporal aggregation) to create harmonized ML tensors; both components are modular so users can add variables, height levels, ensemble members, or additional scenarios.",
              "The pipeline is intended to reduce domain-knowledge barriers for ML researchers and to enable reproducible dataset construction from CMIP6/Input4MIPs."
            ],
            "references": [
              4
            ]
          },
          {
            "id": "t1.3",
            "title": "Use cases and implications for climate ML",
            "summary_points": [
              "Primary ML use cases include climate model emulation (fast surrogates for long simulations), downscaling, scenario projection, extreme-event prediction, and training large multimodel emulators ('super emulators') that can quickly generate new scenario projections.",
              "Multi-model training facilitates quantification of model-projection uncertainty, a critical input for policy decisions and risk assessment, and provides larger training sample sizes aligned with ML best practices."
            ],
            "references": [
              4
            ]
          }
        ],
        "references": [
          4
        ]
      },
      {
        "id": "t2",
        "title": "Generative ML methods for climate downscaling and emulation",
        "summary_points": [
          "Generative models (GANs, VAEs, diffusion models, and conditional transformers) are applied to climate tasks such as downscaling (super-resolution), emulation (surrogate modeling), and stochastic weather/climate realization generation.",
          "Diffusion-based generative models (denoising diffusion probabilistic models, DDPMs) conditioned on low-resolution climate variables have demonstrated superior fidelity for high upscaling factors (4x, 8x) in regional precipitation downscaling compared to regression baselines and are competitive with or advantageous over GANs in stability and preservation of high-frequency details.",
          "Key architectural choices for effective downscaling include U-Net backbones for denoising networks, concatenation of upsampled LR conditioning variables with HR stochastic states, and loss formulations that predict injected noise (epsilon) using L2 objectives as in DDPM frameworks.",
          "Conditional generative approaches allow sampling multiple plausible high-resolution realizations from the same low-resolution conditioning, enabling uncertainty quantification at local scales—a major advantage over deterministic regression downscalers.",
          "Emulation benefits from large, multi-model datasets (e.g., ClimateSet), allowing ML surrogates to learn cross-model response patterns and generalize across forcing scenarios, drastically reducing computational cost compared to full ESM runs."
        ],
        "subtopics": [
          {
            "id": "t2.1",
            "title": "Conditional diffusion model for precipitation downscaling",
            "summary_points": [
              "Method: adapt DDPM to map low-resolution (LR) climate inputs X_LR to high-resolution (HR) precipitation X_HR using a reverse diffusion chain p_theta(X_HR^{t-1} | X_HR^t, X_LR) modeled as Gaussians with learned mean mu_theta and variance sigma_t^2.",
              "Training objective: predict injected Gaussian noise epsilon via a neural denoiser epsilon_theta (U-Net), optimizing L = E[||epsilon - epsilon_theta(X_LR, X_HR^t, t)||^2], with forward process q defined by scheduled beta_t noise variances.",
              "Implementation details: condition on multiple LR variables (e.g., TS, PRECT, dPHIS), upsample LR inputs to HR grid for concatenation, and use iterative sampling (T steps) to generate HR realizations; shown effective on CESM simulation data for North America."
            ],
            "references": [
              5
            ]
          },
          {
            "id": "t2.2",
            "title": "Comparative methods, evaluation and robustness",
            "summary_points": [
              "Comparisons: diffusion models outperform regression-based super-resolution and often yield more stable training than GANs, particularly at high scaling factors where regression tends to oversmooth and GANs can be unstable to train.",
              "Evaluation metrics should include pixel-wise skill (RMSE, MAE), distributional statistics (e.g., precipitation frequency/intensity distributions), spatial structure metrics, and out-of-sample generalization across time slices or forcing scenarios to assess robustness.",
              "Practical considerations: selecting conditioning variables, handling temporal consistency, and computational cost of iterative sampling are trade-offs; ensembles of stochastic samples can quantify aleatoric uncertainty while training across multiple climate models captures epistemic uncertainty."
            ],
            "references": [
              5,
              4,
              1
            ]
          }
        ],
        "references": [
          5,
          4,
          1
        ]
      },
      {
        "id": "t3",
        "title": "Natural language methods for climate information extraction and benchmarking",
        "summary_points": [
          "Large volumes of unstructured climate reports (corporate, city, state, national disclosures) require NLP tools to convert free-form text into structured questionnaires and fields useful for policy analysis, monitoring, and research.",
          "The CLIMA work introduces two large questionnaire-derived datasets (CLIMA-CDP drawn from the Carbon Disclosure Project; CLIMA-INS from insurance disclosures) and CLIMABENCH, a benchmark aggregating multiple climate text classification tasks to evaluate models on climate-specific NLP challenges.",
          "Approach: utilize existing semi-structured questionnaires to self-supervise classifiers that align text passages to questionnaire questions, enabling in-domain training without costly manual annotation; experiments show models can generalize across stakeholder types (cities, corporations, states).",
          "A counterintuitive empirical finding: general-purpose language models often outperform domain-specific models (e.g., ClimateBERT) on compiled benchmark tasks, indicating model choice and pretraining strategy impact domain adaptation.",
          "Applications include automating questionnaire population, accelerating evidence aggregation for policy, detecting greenwashing, and building datasets to fine-tune LLMs for climate policy tasks."
        ],
        "subtopics": [
          {
            "id": "t3.1",
            "title": "Datasets and benchmark (CLIMA-CDP, CLIMA-INS, CLIMABENCH)",
            "summary_points": [
              "CLIMA-CDP: derived from CDP disclosure questionnaires with broad coverage (thousands of organizations, many questions); CLIMA-INS: NAIC insurance climate risk survey responses yielding ~17k question-answer pairs after preprocessing.",
              "CLIMABENCH aggregates multiple climate NLP datasets to provide standardized evaluation across tasks such as topic classification, question-answer alignment, and report-to-question mapping."
            ],
            "references": [
              6
            ]
          },
          {
            "id": "t3.2",
            "title": "Modeling strategy and empirical findings",
            "summary_points": [
              "Self-supervised classification using questionnaire structure enables training without manual annotation; models were tested on in-domain, cross-domain, and real-world mapping tasks (unstructured reports to questionnaires).",
              "Empirical results indicate that domain-tailored pretraining is not always superior; well-tuned general models can outperform specialized domain models on downstream climate document tasks, underscoring the importance of evaluation on comprehensive benchmarks."
            ],
            "references": [
              6
            ]
          }
        ],
        "references": [
          6
        ]
      },
      {
        "id": "t4",
        "title": "Operational, environmental, and ethical considerations of AI for climate modeling",
        "summary_points": [
          "Computational cost and environmental footprint: training and deploying large ML models (including generative models and LLMs) require extensive data center resources, specialized hardware, significant electricity consumption, and water for cooling—raising concerns about the net environmental impact of AI development and use in climate science.",
          "Trade-offs: while ML surrogates and downscalers can reduce the need for computationally expensive ESM runs (thus saving HPC energy), the energy required to train large ML models and run inference at scale must be accounted for in lifecycle assessments.",
          "Governance, reproducibility and IP: issues include dataset provenance and licensing (e.g., CMIP6/Input4MIPs usage policies), reproducibility across heterogeneous climate model outputs, model interpretability for policy decisions, and intellectual property or copyright concerns when using publicly sourced data in generative systems.",
          "Uncertainty management: combining ML approaches with multi-model ensembles (as facilitated by ClimateSet) is important for separating aleatoric/stochastic uncertainty (addressable via generative sampling) and epistemic/model structural uncertainty (addressable by multi-model training and transparent benchmarking).",
          "Longer-term considerations: the rise of powerful LLMs and potential AGI-like capabilities may influence decision-support tools in climate policy, but responsible integration requires transparency, evaluation, and human oversight to avoid over-reliance on opaque models."
        ],
        "subtopics": [
          {
            "id": "t4.1",
            "title": "Environmental footprint and resource considerations",
            "summary_points": [
              "Generative AI and large ML models consume substantial electricity and cooling water during training and inference; data center footprint and chip manufacturing material intensity must be considered in net-benefit analyses of ML-enabled climate science tools.",
              "Practical mitigation strategies include model efficiency (distillation, pruning), transfer learning from pre-trained models, reuse of emulators across scenarios, and reporting energy-of-training and carbon accounting for published models."
            ],
            "references": [
              1,
              3,
              4
            ]
          },
          {
            "id": "t4.2",
            "title": "Ethics, governance and reproducibility",
            "summary_points": [
              "Key governance issues involve transparency of training data and model behavior when informing policy, reproducibility of ML-based climate results across preprocessing choices, and clear communication of uncertainties to stakeholders and policymakers.",
              "Intellectual property and data licensing constraints (for both input climate data and ancillary training corpora) must be managed to ensure legal and ethical reuse."
            ],
            "references": [
              1,
              4,
              6
            ]
          },
          {
            "id": "t4.3",
            "title": "Role and limitations of LLMs/AGI in climate modeling",
            "summary_points": [
              "LLMs and multimodal generative models can assist climate modeling workflows (data extraction from reports, automating preprocessing pipelines, literature synthesis, scenario narrative generation) but are not substitutes for physics-based ESMs; they can complement domain models for speed and accessibility.",
              "Claims about AGI remain contested; while current LLMs provide powerful language capabilities (useful for knowledge extraction and decision support), their limitations in physical reasoning and requirement for grounding in physical models mean they should be used with careful validation in climate contexts."
            ],
            "references": [
              2,
              1,
              3
            ]
          }
        ],
        "references": [
          1,
          2,
          3,
          4
        ]
      }
    ],
    "abstract": "This knowledge base synthesizes recent advances at the intersection of artificial intelligence and climate modeling, focusing on datasets, generative and conditional ML methods, natural language tools for climate information extraction, and operational/ethical considerations. ClimateSet provides a modular pipeline and a core ML-ready dataset aggregating outputs from 36 CMIP6 Earth System Models and associated Input4MIPs emissions to enable multi-model emulation and uncertainty-aware ML training. Generative approaches—particularly conditional diffusion models (DDPMs) with U-Net denoisers—have proven effective for high-factor precipitation downscaling, predicting noise via L2 objectives and producing multiple plausible high-resolution realizations for uncertainty quantification. NLP contributions include large questionnaire-derived datasets (CLIMA-CDP and CLIMA-INS) and CLIMABENCH, showing that self-supervised alignment methods can map unstructured reports to structured policy questionnaires and that general-purpose language models frequently outperform domain-specific variants on benchmarked tasks. Broader considerations include the environmental footprint of training/deploying large models, data provenance and IP issues, and the need to pair ML surrogates with multi-model ensembles to capture epistemic uncertainty. Collectively, these works indicate a promising role for AI to accelerate and scale climate science—provided careful attention to dataset harmonization, model evaluation, uncertainty communication, and resource impacts.",
    "conclusion": "Applying AI to climate modeling advances capabilities in emulation, downscaling, and automated information extraction while posing practical and ethical challenges. Multi-model, ML-ready datasets like ClimateSet reduce barriers for large-scale ML research and enable training of emulators that capture inter-model uncertainty important for policy. Conditional generative models—especially diffusion-based approaches—offer robust tools for high-resolution downscaling and stochastic realization generation, outperforming conventional regression and addressing limitations of GANs in stability and fidelity. NLP tools built from large semi-structured questionnaires can automate extraction and structuring of climate disclosures, facilitating policy analysis and reducing manual effort. However, practitioners must account for the energy and resource costs of training large models, ensure reproducibility and transparency in preprocessing and model design, respect data licensing, and clearly communicate model uncertainty to decision-makers. Combining physics-based models with ML surrogates and ensemble strategies provides a pragmatic path: leverage AI for speed and pattern learning while maintaining physical grounding, uncertainty quantification, and human oversight to inform robust climate policy and research."
  },
  "report_parts": [
    "## Large-scale climate datasets and pipelines for ML (ClimateSet)\n\nClimateSet provides a consistent, machine-learning-ready, multi–climate-model dataset together with a modular pipeline that retrieves and preprocesses climate model inputs (Input4MIPs) and outputs (CMIP6) to support large-scale ML tasks in climate science [4]. The resource aggregates outputs and input emission fields to create harmonized input/output tensors suitable for model training and benchmarking, emphasizing monthly variables initially such as surface temperature and precipitation [4]. By packaging both a downloader and a preprocessor, ClimateSet aims to make reproducible dataset construction from CMIP6 and Input4MIPs straightforward for ML researchers while reducing the need for bespoke climate-domain preprocessing for each model [4].\n\nThe core composition of ClimateSet includes outputs from 36 Earth System Models (ESMs) together with associated emission fields across multiple Shared Socioeconomic Pathway (SSP) scenarios and historical runs, with an initial focus on key variables like temperature and precipitation [4]. These core data are publicly available and the release emphasizes ML readiness by harmonizing variable names and units, aligning spatial and temporal resolutions across models, and providing automated regridding and temporal aggregation to produce consistent tensors [4]. These design choices are intended to address common cross-model challenges such as inconsistent grid definitions, differing temporal resolutions, and unit heterogeneity so that models trained on the dataset can directly consume inputs without per-model adaptation [4].\n\nA primary goal of ClimateSet is to supply sufficient, diverse training data to enable development of large ML climate models or “super emulators” that generalize across models and scenarios, rather than being tied to a single ESM [4]. Training across multiple models also allows ML practitioners to capture multi-model projection uncertainty, which is critical for policymaking and risk assessment and cannot be obtained from single-model datasets alone [4]. ClimateSet demonstrates its utility as a benchmark for climate model emulation on temperature and precipitation tasks, showing that multimodel-trained ML approaches reveal performance and generalization characteristics that single-model datasets cannot provide [4].\n\nClimateSet also acknowledges limitations in the core release: remaining inconsistencies across models persist (for example in ensemble member availability and vertical level definitions), the initial variable and scenario selection is limited, and the pipeline depends on the availability of CMIP6/Input4MIPs data and the ESGF infrastructure for retrieval [4]. The project mitigates some of these constraints by providing modular downloader and preprocessor components so users can extend the dataset to include additional variables, height levels, ensemble members, or scenarios as needed, while recognizing that some heterogeneities are inherent in the source model outputs [4].\n\n### Dataset composition and scope\n\nThe core release of ClimateSet aggregates outputs from 36 climate models and their associated emission inputs, focusing initially on monthly fields such as surface temperature and precipitation across several SSP scenarios as well as historical runs [4]. This aggregation is intended to create a multimodel corpus that supports ML tasks requiring extensive and diverse training data while preserving the link between forcings (Input4MIPs) and ESM responses (CMIP6) [4].\n\nTo enable direct ML training without bespoke preprocessing for each model, the dataset targets ML readiness by providing aligned grids, consistent units, and standardized temporal resolution across all included models [4]. These harmonization steps—unit conversion, temporal aggregation to standardized monthly cadence, and automated spatial regridding—produce uniform tensors that permit straightforward batching and model input pipelines typical in ML workflows [4].\n\n### Pipeline, tools and extensibility\n\nClimateSet includes a downloader that automates retrieval of CMIP6 and Input4MIPs files from the Earth System Grid Federation (ESGF) and a modular preprocessor that performs regridding, unit harmonization, and temporal aggregation to create harmonized ML-ready tensors [4]. Both components are modular by design so that researchers can add variables, additional vertical levels, ensemble members, or extra scenario runs without modifying the core pipeline architecture [4].\n\nThe pipeline is intended to lower domain-knowledge barriers for ML researchers by encapsulating climate-specific preprocessing steps and enabling reproducible dataset construction from the same underlying CMIP6/Input4MIPs sources [4]. By standardizing retrieval and preprocessing, the tools facilitate benchmarking and comparison of ML methods across consistent multimodel datasets while allowing extensibility to expand the dataset’s scope over time [4].\n\n### Use cases and implications for climate ML\n\nPrimary ML use cases for ClimateSet include climate model emulation (developing fast surrogates for long-running simulations), statistical downscaling, scenario projection, extreme-event prediction, and training large multimodel emulators or “super emulators” that can quickly generate projections for new or perturbed scenarios [4]. The dataset’s multimodel construction enables these applications to leverage greater data diversity and sample size, aligning with ML best practices for training large-capacity models [4].\n\nTraining across multiple climate models also facilitates explicit quantification of model-projection uncertainty, which is a critical input for policy decisions and risk assessment and cannot be captured by single-model emulators alone [4]. By providing a standardized benchmark for emulation on variables such as temperature and precipitation, ClimateSet allows researchers to evaluate both predictive skill and the robustness of ML models’ generalization across ESMs and scenarios, informing the development of methods that are useful for decision-relevant climate applications [4].",
    "## Generative ML methods for climate downscaling and emulation\n\nGenerative machine learning models — including generative adversarial networks (GANs), variational autoencoders (VAEs), diffusion models, and conditional transformers — have been applied to climate tasks such as statistical downscaling (super‑resolution), emulation (surrogate modeling of Earth system model components), and the generation of stochastic weather or climate realizations for uncertainty‑aware applications [5,4,1]. Within this spectrum, diffusion‑based generative models, specifically denoising diffusion probabilistic models (DDPMs) conditioned on low‑resolution climate variables, have shown notable promise for high upscaling factors (e.g., 4×, 8×) in regional precipitation downscaling, providing superior fidelity relative to regression baselines and competitive or improved behavior versus GANs in terms of training stability and preservation of high‑frequency spatial details [5].  \n\nKey architectural and algorithmic choices that support effective downscaling with these models include U‑Net style backbones for the denoising networks, concatenation of upsampled low‑resolution conditional inputs with high‑resolution stochastic states, and loss formulations that directly predict the injected noise (epsilon) using an L2 objective as in the DDPM framework [5]. The stochastic nature of conditional generative approaches allows sampling of multiple plausible high‑resolution realizations from the same low‑resolution conditioning, enabling quantification of aleatoric uncertainty at local scales — a capability not available in deterministic regression‑based downscalers [5]. In parallel, emulation benefits from large, multi‑model datasets (for example, ClimateSet), which enable machine‑learned surrogates to learn cross‑model response patterns and generalize across forcing scenarios, thereby drastically reducing computational cost relative to full Earth system model runs while retaining important aspects of model variability [4,1].\n\n### Conditional diffusion model for precipitation downscaling\n\nThe conditional downscaling methodology adapts the DDPM framework to map low‑resolution climate inputs X_LR to high‑resolution precipitation fields X_HR by formulating a reverse diffusion chain p_theta(X_HR^{t-1} | X_HR^t, X_LR). Each reverse step is modeled as a Gaussian with a learned mean mu_theta and variance sigma_t^2, enabling iterative refinement from a noisy initial state toward a conditioned high‑resolution sample [5]. During training, the forward (noising) process q is defined by a schedule of noise variances beta_t that progressively corrupt the high‑resolution field; the neural denoiser epsilon_theta — commonly instantiated with a U‑Net backbone — is trained to predict the injected Gaussian noise at each timestep using an L2 objective L = E[||epsilon - epsilon_theta(X_LR, X_HR^t, t)||^2] [5].\n\nImplementation details that have proven effective include conditioning on multiple low‑resolution variables (e.g., TS, PRECT, dPHIS), upsampling those low‑resolution inputs to the high‑resolution grid for concatenation with the stochastic state at each denoising step, and performing T iterative reverse steps to generate high‑resolution realizations. This conditional DDPM approach has been demonstrated on CESM simulation data over North America, showing its ability to produce plausible high‑resolution precipitation fields conditioned on coarse inputs [5].\n\n### Comparative methods, evaluation and robustness\n\nComparative evaluations indicate that diffusion‑based downscaling models tend to outperform regression‑based super‑resolution approaches, particularly at large upscaling factors where regression methods commonly produce oversmoothed outputs, and they often exhibit more stable training dynamics than GAN‑based alternatives [5,4,1]. Robust model assessment therefore requires a multi‑axis evaluation protocol that combines pixel‑wise skill metrics (e.g., RMSE, MAE), distributional diagnostics (such as precipitation frequency and intensity distributions), spatial‑structure measures, and out‑of‑sample generalization tests across different time slices or forcing scenarios to assess temporal and scenario robustness [5,4,1].  \n\nPractical deployment considerations include the selection of conditioning variables, approaches for maintaining temporal consistency across sequential samples, and the computational cost associated with iterative sampling in diffusion methods. These trade‑offs must be balanced against the benefits of uncertainty quantification: ensembles of stochastic samples permit estimation of aleatoric uncertainty at local scales, while training across multiple climate models or forcing scenarios helps capture epistemic uncertainty and improves generalization [5,4,1].",
    "## Natural language methods for climate information extraction and benchmarking\n\nLarge volumes of unstructured climate reports — including corporate, city, state, and national disclosures — create a pressing need for natural language processing (NLP) tools that can convert free-form text into structured questionnaires and fields useful for policy analysis, monitoring, and research [6]. These unstructured narratives contain policy-relevant information that is difficult to aggregate at scale without automated methods for aligning passages to predefined question schemas and extracting standardized responses [6].  \n\nTo address this need, the CLIMA work introduces two large questionnaire-derived datasets and a broader benchmark suite that together enable systematic development and evaluation of climate-specific NLP methods [6]. The approach leverages existing semi-structured questionnaires to produce training signals and assembles CLIMABENCH, a compilation of climate text classification tasks, to provide standardized evaluation across topic classification, question–answer alignment, and report-to-question mapping tasks [6].  \n\nThe proposed methods and resources are intended for practical applications such as automating questionnaire population, accelerating evidence aggregation for policy decisions, detecting greenwashing, and producing datasets suitable for fine-tuning large language models for climate policy tasks [6]. Empirically, the work also highlights that model choice and pretraining strategy materially affect performance: contrary to expectation, well-tuned general-purpose language models sometimes outperform domain-specific models (for example, ClimateBERT) on the compiled benchmark tasks, underscoring the importance of comprehensive evaluation when adapting models to climate document tasks [6]. \n\n### Datasets and benchmark (CLIMA-CDP, CLIMA-INS, CLIMABENCH)\n\nCLIMA-CDP is derived from Carbon Disclosure Project (CDP) disclosure questionnaires and provides broad coverage spanning thousands of organizations and many questionnaire items, enabling large-scale alignment between corporate disclosures and structured questions [6]. CLIMA-INS is constructed from insurance disclosures, specifically NAIC insurance climate risk survey responses, and after preprocessing yields roughly 17,000 question–answer pairs that can be used to train and evaluate passage-to-question alignment methods [6].  \n\nCLIMABENCH aggregates multiple climate NLP datasets, including the questionnaire-derived collections, to provide a standardized evaluation framework across a range of tasks relevant to climate information extraction. The benchmark supports comparisons on topic classification, question–answer alignment, and mapping unstructured reports to questionnaire fields, facilitating reproducible assessment of model capabilities on climate-specific challenges [6]. \n\n### Modeling strategy and empirical findings\n\nThe modeling strategy centers on self-supervised classification that exploits the structure of existing questionnaires to create supervision signals: text passages are aligned to questionnaire questions, enabling in-domain training without the need for costly manual annotation [6]. Models trained in this manner were evaluated on a variety of tasks, including in-domain classification, cross-domain transfer, and real-world mapping tasks that align unstructured reports to questionnaire fields; experiments demonstrate that this approach supports generalization across stakeholder types such as cities, corporations, and states [6].  \n\nEmpirical results from the CLIMA evaluations reveal an important nuance in domain adaptation: domain-tailored pretraining is not always superior to using well-tuned general-purpose models. In several compiled benchmark tasks, general models outperformed specialized domain models (for example, ClimateBERT), indicating that pretraining strategy and downstream tuning are critical determinants of performance and that comprehensive benchmarks are necessary to surface these effects [6].",
    "## Operational, environmental, and ethical considerations of AI for climate modeling\n\nThe deployment of machine learning (ML) and generative AI in climate science raises multiple operational and environmental concerns because training and running large models demands substantial data center resources, specialized hardware, extensive electricity consumption, and water for cooling, all of which contribute to the net environmental footprint of these tools [1,3,4]. At the same time, ML approaches offer trade-offs: surrogate models, emulators, and statistical downscalers can reduce the number of computationally expensive Earth system model (ESM) runs required, thereby lowering high-performance computing (HPC) energy use, but the energy and materials required to train and operate large ML models must be included in lifecycle assessments to determine net benefits [1,3,4]. Governance and reproducibility present parallel challenges, as the provenance and licensing of datasets (for example, CMIP6/Input4MIPs usage policies) and heterogeneity across climate model outputs complicate legal reuse and the ability to reproduce ML-based results, which is critical when informing policy decisions [1,4].\n\nManaging uncertainty is central to trustworthy ML integration in climate science: combining generative approaches that can capture aleatoric or stochastic variability with multi-model ensembles that address epistemic or structural model uncertainty helps to distinguish sources of error and supports transparent benchmarking and evaluation [1,3]. Finally, the longer-term rise of powerful large language models (LLMs) and potential advanced AI capabilities suggests both opportunities and risks for decision support in climate policy; responsible integration will require transparent documentation, rigorous evaluation, and sustained human oversight to avoid over-reliance on opaque systems [2,1,3].\n\n### Environmental footprint and resource considerations\n\nGenerative AI and large ML architectures incur substantial operational resource demands during both training and inference phases: they require significant electricity for computation, water for data center cooling, and entail material- and energy-intensive chip manufacturing, all of which should be considered in net-benefit analyses of ML-enabled climate tools [1,3,4]. These resource demands can offset the computational savings that ML surrogates provide unless lifecycle accounting is performed and reported consistently [1,3,4].\n\nPractical mitigation strategies focus on improving model efficiency and reuse. Techniques such as model distillation and pruning, transfer learning from pre-trained networks, and the reuse of trained emulators across multiple scenarios can materially reduce energy and resource requirements relative to training models from scratch for each task [1,3,4]. Complementing technical measures, transparent reporting of energy consumed during training and carbon accounting for published models enables more accurate assessments of environmental footprint and supports informed decision-making about when and how to deploy ML solutions in climate science [1,3,4].\n\n### Ethics, governance and reproducibility\n\nKey governance challenges stem from the need for transparency about training data and model behavior when ML outputs are used to inform policy, since opaque data provenance or undisclosed preprocessing choices can undermine trust and lead to irreproducible conclusions [1,4]. Ensuring reproducibility requires standardized documentation of data sources, preprocessing pipelines, model architectures, and evaluation protocols so that results can be replicated across heterogeneous climate model outputs and different research groups [1,4].\n\nIntellectual property and data licensing constraints also require careful management to enable legal and ethical reuse of both input climate datasets and ancillary corpora used for model training; compliance with dataset-specific terms (for example, those associated with multi-model archives) must be part of model development and dissemination workflows to avoid misuse and to preserve open scientific collaboration [1,4]. Clear communication of uncertainties and the limits of ML-derived inferences to stakeholders and policymakers is essential to prevent misinterpretation of model outputs in decision contexts [1,4].\n\n### Role and limitations of LLMs/AGI in climate modeling\n\nLLMs and multimodal generative models can provide practical assistance across climate-modeling workflows, including extracting information from reports, automating preprocessing pipelines, synthesizing literature, and generating scenario narratives that improve accessibility and workflow efficiency; however, these capabilities are complementary to—and not replacements for—physics-based ESMs that embed mechanistic understanding of the climate system [2,1,3]. When used appropriately, language models can accelerate tasks that improve model provision and interpretation, but their outputs must be grounded in domain knowledge and validated against physical models and observations [2,1,3].\n\nClaims about the arrival of artificial general intelligence remain contested; current LLMs exhibit strong language capabilities useful for knowledge extraction and decision support but have limitations in physical reasoning and require explicit grounding in physical models and datasets to be reliable in climate contexts [2,1,3]. Consequently, responsible integration of these models into climate policymaking and scientific workflows demands careful validation, transparency about model limitations, and preservation of human oversight to avoid undue reliance on opaque or insufficiently validated generative systems [2,1,3]."
  ],
  "criticism": {
    "0": "PASS",
    "1": "1) Incorrect/unsupported variable naming example\n- Statement: \"including multiple LR predictors (for example, total soil moisture, precipitation, or geopotential‑related fields) as inputs to guide the reverse process.\"\n- Why problematic: The INPUT JSON examples for conditioning variables in the conditional diffusion downscaling subtopic use the abbreviations \"TS, PRECT, dPHIS\" (t2.1). The writer introduced \"total soil moisture\" as an example, which is not listed in the JSON and likely mislabels \"TS\" (commonly used for surface temperature in climate datasets, not necessarily soil moisture). This risks confusing readers about which variables were used in the cited work.\n- Reference: topic t2, subtopic t2.1 (\"condition on multiple LR variables (e.g., TS, PRECT, dPHIS)\").\n\nSuggested fix: Use the variable names given in the JSON (TS, PRECT, dPHIS) or explicitly note that the examples are illustrative and clarify what each abbreviation stands for if definitions are added.\n\n2) Minor unsupported phrasing about variance being \"prescribed or learned\"\n- Statement: \"each reverse step is modeled as a Gaussian with a learned mean mu_theta and a prescribed or learned variance sigma_t^2\"\n- Why problematic: The INPUT JSON states the reverse steps are modeled as Gaussians with a learned mean mu_theta and variance sigma_t^2 (t2.1) but does not state whether sigma_t^2 is prescribed or learned. Saying \"prescribed or learned\" introduces an implementation detail not supported by the provided summary and may imply design choices not present in the cited source.\n- Reference: topic t2, subtopic t2.1 (\"modeled as Gaussians with learned mean mu_theta and variance sigma_t^2\").\n\nSuggested fix: Align wording with the JSON—either state simply \"with learned mean mu_theta and variance sigma_t^2\" or, if the original paper distinguishes between learned vs. fixed variance, cite that detail explicitly.\n\nOverall assessment: Content is largely accurate and faithful to the INPUT JSON (t2, t2.1, t2.2). The issues above are relatively minor but important for technical precision and consistency with the source summaries.",
    "2": "PASS",
    "3": "PASS"
  },
  "is_criticized": true
}