{
  "topic": "Quantum Computing",
  "source": "both",
  "wikipedia_docs": "Index: 1\nTitle: Quantum computing\nSource: https://en.wikipedia.org/wiki/Quantum_computing\nContent: A quantum computer is a (real or theoretical) computer that uses quantum mechanical phenomena in an essential way: it exploits superposed and entangled states, and the intrinsically non-deterministic outcomes of quantum measurements, as features of its computation. Quantum computers can be viewed as sampling from quantum systems that evolve in ways classically described as operating on an enormous number of possibilities simultaneously, though still subject to strict computational constraints. By contrast, ordinary (\"classical\") computers operate according to deterministic rules. Any classical computer can, in principle, be replicated by a (classical) mechanical device such as a Turing machine, with only polynomial overhead in time. Quantum computers, on the other hand are believed to require exponentially more resources to simulate classically. It is widely believed that a scalable quantum computer could perform some calculations exponentially faster than any classical computer. Theoretically, a large-scale quantum computer could break some widely used public-key cryptographic schemes and aid physicists in performing physical simulations. However, current hardware implementations of quantum computation are largely experimental and only suitable for specialized tasks.\nThe basic unit of information in quantum computing, the qubit (or \"quantum bit\"), serves the same function as the bit in ordinary or \"classical\" computing. However, unlike a classical bit, which can be in one of two states (a binary), a qubit can exist in a linear combination of two states known as a quantum superposition. The result of measuring a qubit is one of the two states given by a probabilistic rule. If a quantum computer manipulates the qubit in a particular way, wave interference effects amplify probability of the desired measurement result. The design of quantum algorithms involves creating procedures that allow a quantum computer to perform this amplification.\nQuantum computers are not yet practical for real-world applications. Physically engineering high-quality qubits has proven to be challenging. If a physical qubit is not sufficiently isolated from its environment, it suffers from quantum decoherence, introducing noise into calculations. National governments have invested heavily in experimental research aimed at developing scalable qubits with longer coherence times and lower error rates. Example implementations include superconductors (which isolate an electrical current by eliminating electrical resistance) and ion traps (which confine a single atomic particle using electromagnetic fields). Researchers have claimed, and are widely believed to be correct, that certain quantum devices can outperform classical computers on narrowly defined tasks, a milestone referred to as quantum advantage or quantum supremacy. These tasks are not necessarily useful for real-world applications.\n\n\n== History ==\n\nFor many years, the fields of quantum mechanics and computer science formed distinct academic communities. Modern quantum theory developed in the 1920s to explain perplexing physical phenomena observed at atomic scales, and digital computers emerged in the following decades to replace human computers for tedious calculations. Both disciplines had practical applications during World War II; computers played a major role in wartime cryptography, and quantum physics was essential for nuclear physics used in the Manhattan Project.\nAs physicists applied quantum mechanical models to computational problems and swapped digital bits for qubits, the fields of quantum mechanics and computer science began to converge. In 1980, Paul Benioff introduced the quantum Turing machine, which uses quantum theory to describe a simplified computer.\nWhen digital computers became faster, physicists faced an exponential increase in overhead when simulating quantum dynamics, prompting Yuri Manin and Richard Feynman to independently suggest that hardware based on quantum phenomena might be more efficient for computer simulation.\nIn a 1984 paper, Charles Bennett and Gilles Brassard applied quantum theory to cryptography protocols and demonstrated that quantum key distribution could enhance information security.\nQuantum algorithms then emerged for solving oracle problems, such as Deutsch's algorithm in 1985, the Bernstein–Vazirani algorithm in 1993, and Simon's algorithm in 1994.\nThese algorithms did not solve practical problems, but demonstrated mathematically that one could gain more information by querying a black box with a quantum state in superposition, sometimes referred to as quantum parallelism.\n\nPeter Shor built on these results with his 1994 algorithm for breaking the widely used RSA and Diffie–Hellman encryption protocols, which drew significant attention to the field of quantum computing. In 1996, Grover's algorithm established a quantum speedup for the widely applicable unstructured search problem. The same year, Seth Lloyd proved that quantum computers could simulate quantum systems without the exponential overhead present in classical simulations, validating Feynman's 1982 conjecture.\nOver the years, experimentalists have constructed small-scale quantum computers using trapped ions and superconductors.\nIn 1998, a two-qubit quantum computer demonstrated the feasibility of the technology, and subsequent experiments have increased the number of qubits and reduced error rates.\nIn 2019, Google AI and NASA announced that they had achieved quantum supremacy with a 54-qubit machine, performing a computation that is impossible for any classical computer.\nThis announcement was met with a rebuttal from Google's direct competitor, IBM. IBM contended that the calculation Google claimed would take 10,000 years could be performed in just 2.5 days on its own Summit supercomputer if its architecture were optimized, sparking a debate over the precise threshold for \"quantum supremacy\".\n\n\n== Quantum information processing ==\nComputer engineers typically describe a modern computer's operation in terms of classical electrodynamics.\nWithin these \"classical\" computers, some components (such as semiconductors and random number generators) may rely on quantum behavior, but these components are not isolated from their environment, so any quantum information quickly decoheres.\nWhile programmers may depend on probability theory when designing a randomized algorithm, quantum mechanical notions like superposition and interference are largely irrelevant for program analysis.\nQuantum programs, in contrast, rely on precise control of coherent quantum systems. Physicists describe these systems mathematically using linear algebra. Complex numbers model probability amplitudes, vectors model quantum states, and matrices model the operations that can be performed on these states. Programming a quantum computer is then a matter of composing operations in such a way that the resulting program computes a useful result in theory and is implementable in practice.\nAs physicist Charlie Bennett describes the relationship between quantum and classical computers,\n\nA classical computer is a quantum computer ... so we shouldn't be asking about \"where do quantum speedups come from?\" We should say, \"well, all computers are quantum. ... Where do classical slowdowns come from?\"\n\n\n=== Quantum information ===\nJust as the bit is the basic concept of classical information theory, the qubit is the fundamental unit of quantum information. The same term qubit is used to refer to an abstract mathematical model and to any physical system that is represented by that model. A classical bit, by definition, exists in either of two physical states, which can be denoted 0 and 1. A qubit is also described by a state, and two states often written \n  \n    \n      \n        \n          |\n        \n        0\n        ⟩\n      \n    \n    {\\displaystyle |0\\rangle }\n  \n and \n  \n    \n      \n        \n          |\n        \n        1\n        ⟩\n      \n    \n    {\\displaystyle |1\\rangle }\n  \n serve as the quantum counterparts of the classical states 0 and 1. However, the quantum states \n  \n    \n      \n        \n          |\n        \n        0\n        ⟩\n      \n    \n    {\\displaystyle |0\\rangle }\n  \n and \n  \n    \n      \n        \n          |\n        \n        1\n        ⟩\n      \n    \n    {\\displaystyle |1\\rangle }\n  \n belong to a vector space, meaning that they can be multiplied by constants and added together, and the result is again a valid quantum state. Such a combination is known as a superposition of \n  \n    \n      \n        \n          |\n        \n        0\n        ⟩\n      \n    \n    {\\displaystyle |0\\rangle }\n  \n and \n  \n    \n      \n        \n          |\n        \n        1\n        ⟩\n      \n    \n    {\\displaystyle |1\\rangle }\n  \n.\nA two-dimensional vector mathematically represents a qubit state. Physicists typically use Dirac notation for quantum mechanical linear algebra, writing \n  \n    \n      \n        \n          |\n        \n        ψ\n        ⟩\n      \n    \n    {\\displaystyle |\\psi \\rangle }\n  \n 'ket psi' for a vector labeled \n  \n    \n      \n        ψ\n      \n    \n    {\\displaystyle \\psi }\n  \n . Because a qubit is a two-state system, any qubit state takes the form \n  \n    \n      \n        α\n        \n          |\n        \n        0\n        ⟩\n        +\n        β\n        \n          |\n        \n        1\n        ⟩\n      \n    \n    {\\displaystyle \\alpha |0\\rangle +\\beta |1\\rangle }\n  \n , where \n  \n    \n      \n        \n          |\n        \n        0\n        ⟩\n      \n    \n    {\\displaystyle |0\\rangle }\n  \n and \n  \n    \n      \n        \n          |\n        \n        1\n        ⟩\n      \n    \n    {\\displaystyle |1\\rangle }\n  \n are the standard basis states, and \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n and \n  \n    \n      \n        β\n      \n    \n    {\\displaystyle \\beta }\n  \n are the probability amplitudes, which are in general complex numbers. If either \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n or \n  \n    \n      \n        β\n      \n    \n    {\\displaystyle \\beta }\n  \n is zero, the qubit is effectively a classical bit; when both are nonzero, the qubit is in superposition. Such a quantum state vector acts similarly to a (classical) probability vector, with one key difference: unlike probabilities, probability amplitudes are not necessarily positive numbers. Negative amplitudes allow for destructive wave interference.\nWhen a qubit is measured in the standard basis, the result is a classical bit. The Born rule describes the norm-squared correspondence between amplitudes and probabilities—when measuring a qubit \n  \n    \n      \n        α\n        \n          |\n        \n        0\n        ⟩\n        +\n        β\n        \n          |\n        \n        1\n        ⟩\n      \n    \n    {\\displaystyle \\alpha |0\\rangle +\\beta |1\\rangle }\n  \n, the state collapses to \n  \n    \n      \n        \n          |\n        \n        0\n        ⟩\n      \n    \n    {\\displaystyle |0\\rangle }\n  \n with probability \n  \n    \n      \n        \n          |\n        \n        α\n        \n          \n            |\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle |\\alpha |^{2}}\n  \n, or to \n  \n    \n      \n        \n          |\n        \n        1\n        ⟩\n      \n    \n    {\\displaystyle |1\\rangle }\n  \n with probability \n  \n    \n      \n        \n          |\n        \n        β\n        \n          \n            |\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle |\\beta |^{2}}\n  \n.\nAny valid qubit state has coefficients \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n and \n  \n    \n      \n        β\n      \n    \n    {\\displaystyle \\beta }\n  \n such that \n  \n    \n      \n        \n          |\n        \n        α\n        \n          \n            |\n          \n          \n            2\n          \n        \n        +\n        \n          |\n        \n        β\n        \n          \n            |\n          \n          \n            2\n          \n        \n        =\n\n---\n\nIndex: 2\nTitle: Timeline of quantum computing and communication\nSource: https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication\nContent: This is a timeline of quantum computing and communication.\n\n\n== 1960s ==\n\n\n=== 1968/69/70 ===\nStephen Wiesner invents conjugate coding.\n\n\n=== 1969 ===\n13 June – James L. Park (Washington State University, Pullman)'s paper is received by Foundations of Physics, in which he describes the non possibility of disturbance in a quantum transition state in the context of a disproof of quantum jumps in the concept of the atom described by Bohr.\n\n\n== 1970s ==\n\n\n=== 1973 ===\nAlexander Holevo's paper is published. The Holevo bound describes a limit of the quantity of classical information which is possible to quanta encode.\nCharles H. Bennett shows that computation can be done reversibly.\n\n\n=== 1975 ===\nR. P. Poplavskii publishes \"Thermodynamical models of information processing\" (in Russian) which shows the computational infeasibility of simulating quantum systems on classical computers, due to the superposition principle.\nRoman Stanisław Ingarden, a Polish mathematical physicist, submits the paper \"Quantum Information Theory\" in Reports on Mathematical Physics, vol. 10, pp. 43–72, published 1976. It is one of the first attempts at creating a quantum information theory, showing that Shannon information theory cannot directly be generalized to the quantum case, but rather that it is possible to construct a quantum information theory, which is a generalization of Shannon's theory, within the formalism of a generalized quantum mechanics of open systems and a generalized concept of observables (the so-called semi-observables).\n\n\n== 1980s ==\n\n\n=== 1980 ===\nPaul Benioff describes the first quantum mechanical model of a computer. In this work, Benioff showed that a computer could operate under the laws of quantum mechanics by describing a Schrödinger equation description of Turing machines, laying a foundation for further work in quantum computing. The paper was submitted in June 1979 and published in April 1980.\nYuri Manin briefly motivates the idea of quantum computing.\nTommaso Toffoli introduces the reversible Toffoli gate, which (together with initialized ancilla bits) is functionally complete for reversible classical computation.\n\n\n=== 1981 ===\nAt the first Conference on the Physics of Computation, held at the Massachusetts Institute of Technology (MIT) in May, Paul Benioff and Richard Feynman give talks on quantum computing. Benioff's talk built on his earlier 1980 work showing that a computer can operate under the laws of quantum mechanics. The talk was titled \"Quantum mechanical Hamiltonian models of discrete processes that erase their own histories: application to Turing machines\". In Feynman's talk, he observed that it appeared to be impossible to efficiently simulate the evolution of a quantum nature system on a classical computer, and he proposed a basic model for a quantum computer. Feynman's conjecture on a quantum simulating computer, published 1982, understood as – the reality of quantum mechanics expressed as an effective quantum system necessitates quantum computers, is conventionally accepted as a beginning of quantum computing.\n\n\n=== 1982 ===\nPaul Benioff further develops his original model of a quantum mechanical Turing machine.\nWilliam Wootters and Wojciech H. Zurek, and independently Dennis Dieks rediscover the no-cloning theorem of James L. Park.\n\n\n=== 1984 ===\nCharles Bennett and Gilles Brassard employ Wiesner's conjugate coding for distribution of cryptographic keys.\n\n\n=== 1985 ===\nDavid Deutsch, at the University of Oxford, England, describes the first universal quantum computer. Just as a Universal Turing machine can simulate any other Turing machine efficiently (Church–Turing thesis), so the universal quantum computer is able to simulate any other quantum computer with at most a polynomial slowdown.\nAsher Peres points out the need for quantum error correction schemes and discusses a repetition code for amplitude errors.\n\n\n=== 1988 ===\nYoshihisa Yamamoto and K. Igeta propose the first physical realization of a quantum computer, including Feynman's CNOT gate. Their approach uses atoms and photons and is the progenitor of modern quantum computing and networking protocols using photons to transmit qubits and atoms to perform two-qubit operations.\n\n\n=== 1989 ===\nGerard J. Milburn proposes a quantum-optical realization of a Fredkin gate.\nBikas Chakrabarti & collaborators from Saha Institute of Nuclear Physics, Kolkata, India, propose that quantum fluctuations could help explore rugged energy landscapes by escaping from local minima of glassy systems having tall but thin barriers by tunneling (instead of climbing over using thermal excitations), suggesting the effectiveness of quantum annealing over classical simulated annealing.\n\n\n== 1990s ==\n\n\n=== 1991 ===\nArtur Ekert at the University of Oxford, proposes entanglement-based secure communication.\n\n\n=== 1992 ===\nDavid Deutsch and Richard Jozsa propose a computational problem that can be solved efficiently with the deterministic Deutsch–Jozsa algorithm on a quantum computer, but for which no deterministic classical algorithm is possible. This was perhaps the earliest result in the computational complexity of quantum computers, proving that they were capable of performing some well-defined computation more efficiently than any classical computer.\nEthan Bernstein and Umesh Vazirani propose the Bernstein–Vazirani algorithm. It is a restricted version of the Deutsch–Jozsa algorithm where instead of distinguishing between two different classes of functions, it tries to learn a string encoded in a function. The Bernstein–Vazirani algorithm was designed to prove an oracle separation between complexity classes BQP and BPP.\nResearch groups at Max Planck Institute of Quantum Optics (Garching) and shortly after at NIST (Boulder) experimentally realize the first crystallized strings of laser-cooled ions. Linear ion crystals constitute the qubit basis for most quantum computing and simulation experiments with trapped ions.\n\n\n=== 1993 ===\nDaniel R. Simon, at Université de Montréal, Quebec, Canada, invent an oracle problem, Simon's problem, for which a quantum computer would be exponentially faster than a conventional computer. This algorithm introduces the main ideas which were then developed in Peter Shor's factorization algorithm.\n\n\n=== 1994 ===\nPeter Shor, at AT&T's Bell Labs in New Jersey, publishes Shor's algorithm. It would allow a quantum computer to factor large integers quickly. It solves both the factoring problem and the discrete log problem. The algorithm can theoretically break many of the cryptosystems in use today. Its invention sparked tremendous interest in quantum computers.\nThe first United States Government workshop on quantum computing is organized by NIST in Gaithersburg, Maryland, in autumn.\nIsaac Chuang and Yoshihisa Yamamoto propose a quantum-optical realization of a quantum computer to implement Deutsch's algorithm. Their work introduced dual-rail encoding for photonic qubits.\nIn December, Ignacio Cirac, at University of Castilla–La Mancha at Ciudad Real, and Peter Zoller at the University of Innsbruck propose an experimental realization of the controlled NOT gate with cold trapped ions.\n\n\n=== 1995 ===\nThe first United States Department of Defense workshop on quantum computing and quantum cryptography is organized by United States Army physicists Charles M. Bowden, Jonathan Dowling, and Henry O. Everitt; it took place in February at the University of Arizona in Tucson.\nPeter Shor proposes the first schemes for quantum error correction.\nChristopher Monroe and David J. Wineland at NIST (Boulder, Colorado) experimentally realize the first quantum logic gate – the controlled NOT gate – with trapped ions, following the Cirac-Zoller proposal.\nIndependently, Subhash Kak and Ronald Chrisley propose the first quantum neural network.\n\n\n=== 1996 ===\nLov Grover, at Bell Labs, invents the quantum database search algorithm. The quadratic speedup is not as dramatic as the speedup for factoring, discrete logs, or physics simulations. However, the algorithm can be applied to a much wider variety of problems. Any problem that can be solved by random, brute-force search, may take advantage of this quadratic speedup in the number of search queries.\nThe United States Government, particularly in a joint partnership of the Army Research Office (now part of the Army Research Laboratory) and the National Security Agency, issues the first public call for research proposals in quantum information processing.\nAndrew Steane designs Steane code for error correction.\nDavid DiVincenzo, of IBM, proposes a list of minimal requirements for creating a quantum computer, now called DiVincenzo's criteria.\nSeth Lloyd proves Feynman's conjecture on quantum simulation.\n\n\n=== 1997 ===\nDavid G. Cory, Amr Fahmy and Timothy Havel, and at the same time Neil Gershenfeld and Isaac Chuang at MIT publish the first papers realizing gates for quantum computers based on bulk nuclear spin resonance, or thermal ensembles. The technology is based on a nuclear magnetic resonance (NMR) machine, which is similar to the medical magnetic resonance imaging machine.\nAlexei Kitaev describes the principles of topological quantum computation as a method for dealing with the problem of decoherence.\nDaniel Loss and David DiVincenzo propose the Loss-DiVincenzo quantum computer, using as qubits the intrinsic spin-1/2 degree of freedom of individual electrons confined to quantum dots.\n\n\n=== 1998 ===\nThe first experimental demonstration of a quantum algorithm is reported. A working 2-qubit NMR quantum computer was used to solve Deutsch's problem by Jonathan A. Jones and Michele Mosca at Oxford University and shortly after by Isaac L. Chuang at IBM's Almaden Research Center, in California, and Mark Kubinec and the University of California, Berkeley together with coworkers at Stanford University in California and MIT in Massachusetts.\nThe first working 3-qubit NMR computer is reported.\nBruce Kane proposes a silicon-based nuclear spin quantum computer, using nuclear spins of individual phosphorus atoms in silicon as the qubits and donor electrons to mediate the coupling between qubits.\nThe first execution of Grover's algorithm on an NMR computer is reported.\nHidetoshi Nishimori & colleagues from Tokyo Institute of Technology show that a quantum annealing algorithm can perform better than classical simulated annealing under certain conditions.\nDaniel Gottesman and Emanuel Knill independently prove that a certain subclass of quantum computations can be efficiently emulated with classical resources (Gottesman–Knill theorem).\n\n\n=== 1999 ===\nSamuel L. Braunstein and collaborators show that none of the bulk NMR experiments performed to date contain any entanglement; the quantum states being too strongly mixed. This is seen as evidence that NMR computers would likely not yield a benefit over classical computers. It remains an open question, however, whether entanglement is necessary for quantum computational speedup.\nGabriel Aeppli, Thomas Rosenbaum and colleagues demonstrate experimentally the basic concepts of quantum annealing in a condensed matter system.\nYasunobu Nakamura and Jaw-Shen Tsai demonstrate that a superconducting circuit can be used as a qubit.\n\n\n== 2000s ==\n\n\n=== 2000 ===\nArun K. Pati and Samuel L. Braunstein prove the quantum no-deleting theorem. This is dual to the no-cloning theorem which shows that one cannot delete a copy of an unknown qubit. Together with the stronger no-cloning theorem, the no-deleting theorem has the implication that quantum information can neither be created nor be destroyed.\nThe first working 5-qubit NMR computer is demonstrated at the Technical University of Munich, Germany.\nThe first execution of order finding (part of Shor's algorithm) at IBM's Almaden Research Center and Stanford University is demonstrated.\nThe first working 7-qubit NMR computer is demonstrated at the Los Alamos National Laboratory in New Mexico.\nThe textbook, Quantum Comp\n\n---\n\nIndex: 3\nTitle: Superconducting quantum computing\nSource: https://en.wikipedia.org/wiki/Superconducting_quantum_computing\nContent: Superconducting quantum computing is a branch of solid state  physics and quantum computing that implements superconducting electronic circuits using superconducting qubits as artificial atoms, or quantum dots. For superconducting qubits, the two logic states are the ground state and the excited state, denoted \n  \n    \n      \n        \n          |\n        \n        g\n        ⟩\n        \n           and \n        \n        \n          |\n        \n        e\n        ⟩\n      \n    \n    {\\displaystyle |g\\rangle {\\text{ and }}|e\\rangle }\n  \n respectively. Research in superconducting quantum computing is conducted by companies such as Google, IBM, IMEC, BBN Technologies, Rigetti, and Intel.  Many recently developed QPUs (quantum processing units, or quantum chips) use superconducting architecture.\nAs of May 2016, up to 9 fully controllable qubits are demonstrated in the 1D array, and up to 16 in 2D architecture. In October 2019, the Martinis group, partnered with Google, published an article demonstrating novel quantum supremacy, using a chip composed of 53 superconducting qubits.\n\n\n== Background ==\nClassical computation models rely on physical implementations consistent with the laws of classical mechanics. Classical descriptions are accurate only for specific systems consisting of a relatively large number of atoms. A more general description of nature is given by quantum mechanics. Quantum computation studies quantum phenomena applications beyond the scope of classical approximation, with the purpose of performing quantum information processing and communication. Various models of quantum computation exist, but the most popular models incorporate concepts of qubits and quantum gates (or gate-based superconducting quantum computing).\nSuperconductors are implemented due to the fact that at low temperatures they have infinite conductivity and zero resistance. Each qubit is built using semiconductor circuits with an LC circuit: a capacitor and an inductor.\nSuperconducting capacitors and inductors are used to produce a resonant circuit that dissipates almost no energy, as heat  can disrupt quantum information. The superconducting resonant circuits are a class of artificial atoms that can be used as qubits. Theoretical and physical implementations of quantum circuits are widely different. Implementing a quantum circuit had its own set of challenges and must abide by DiVincenzo's criteria, conditions proposed by theoretical physicist David P DiVincenzo, which is set of criteria for the physical implementation of superconducting quantum computing, where the initial five criteria ensure that the quantum computer is in line with the postulates of quantum mechanics and the remaining two pertaining to the relaying of this information over a network.\nWe map the ground and excited states of these atoms to the 0 and 1 state as these are discrete and distinct energy values and therefore it is in line with the postulates of quantum mechanics. In such a construction however an electron can jump to multiple other energy states and not be confined to our excited state; therefore, it is imperative that the system be limited to be affected only by photons with energy difference required to jump from the ground state to the excited state. However, this leaves one major issue, we require uneven spacing between our energy levels to prevent photons with the same energy from causing transitions between neighboring pairs of states. Josephson junctions are superconducting elements with a nonlinear inductance, which is critically important for qubit implementation. The use of this nonlinear element in the resonant superconducting circuit produces uneven spacings between the energy levels.\n\n\n=== Qubits ===\nA qubit is a generalization of a bit (a system with two possible states) capable of occupying a quantum superposition of both states. A quantum gate, on the other hand, is a generalization of a logic gate describing the transformation of one or more qubits once a gate is applied given their initial state. Physical implementation of qubits and gates is challenging for the same reason that quantum phenomena are difficult to observe in everyday life given the minute scale on which they occur. One approach to achieving quantum computers is by implementing superconductors whereby quantum effects are macroscopically observable, though at the price of extremely low operation temperatures.\n\n\n=== Superconductors ===\nUnlike typical conductors, superconductors possess a critical temperature at which resistivity plummets to zero and conductivity is drastically increased. In superconductors, the basic charge carriers are pairs of electrons (known as Cooper pairs), rather than single fermions as found in typical conductors.  Cooper pairs are loosely bound and have an energy state lower than that of Fermi energy. Electrons forming Cooper pairs possess equal and opposite momentum and spin so that the total spin of the Cooper pair is an integer spin. Hence, Cooper pairs are bosons. Two such superconductors which have been used in superconducting qubit models are niobium and tantalum, both d-band superconductors.\n\n\n==== Bose–Einstein condensates ====\nOnce cooled to nearly absolute zero, a collection of bosons collapse into their lowest energy quantum state (the ground state) to form a state of matter known as Bose–Einstein condensate. Unlike fermions, bosons may occupy the same quantum energy level (or quantum state) and do not obey the Pauli exclusion principle. Classically, Bose-Einstein Condensate can be conceptualized as multiple particles occupying the same position in space and having equal momentum. Because interactive forces between bosons are minimized, Bose-Einstein Condensates effectively act as a superconductor. Thus, superconductors are implemented in quantum computing because they possess both near infinite conductivity and near zero resistance. The advantages of a superconductor over a typical conductor, then, are twofold in that superconductors can, in theory, transmit signals nearly instantaneously and run infinitely with no energy loss. The prospect of actualizing superconducting quantum computers becomes all the more promising considering NASA's recent development of the Cold Atom Lab in outer space where Bose-Einstein Condensates are more readily achieved and sustained (without rapid dissipation) for longer periods of time without the constraints of gravity.\n\n\n=== Electrical circuits ===\nAt each point of a superconducting electronic circuit (a network of electrical elements), the condensate wave function describing charge flow is well-defined by some complex probability amplitude. In typical conductor electrical circuits, this same description is true for individual charge carriers except that the various wave functions are averaged in macroscopic analysis,  making it impossible to observe quantum effects. The condensate wave function becomes useful in allowing design and measurement of macroscopic quantum effects. Similar to the discrete atomic energy levels in the Bohr model, only discrete numbers of magnetic flux quanta can penetrate a superconducting loop. In both cases, quantization results from complex amplitude continuity. Differing from microscopic implementations of quantum computers (such as atoms or photons), parameters of superconducting circuits are designed by setting (classical) values to the electrical elements composing them such as by adjusting capacitance or inductance.\nTo obtain a quantum mechanical description of an electrical circuit, a few steps are required. Firstly, all electrical elements must be described by the condensate wave function amplitude and phase rather than by closely related macroscopic current and voltage descriptions used for classical circuits. For instance, the square of the wave function amplitude at any arbitrary point in space corresponds to the probability of finding a charge carrier there. Therefore, the squared amplitude corresponds to a classical charge distribution. The second requirement to obtain a quantum mechanical description of an electrical circuit is that generalized Kirchhoff's circuit laws are applied at every node of the circuit network to obtain the system's equations of motion. Finally, these equations of motion must be reformulated to Lagrangian mechanics such that a quantum Hamiltonian is derived describing the total energy of the system.\n\n\n== Technology ==\n\n\n=== Manufacturing ===\nSuperconducting quantum computing devices are typically designed in the radio-frequency spectrum, cooled in dilution refrigerators below 15 mK and addressed with conventional electronic instruments, e.g. frequency synthesizers and spectrum analyzers. Typical dimensions fall on the range of micrometers, with sub-micrometer resolution, allowing for the convenient design of a Hamiltonian system with well-established integrated circuit technology. Manufacturing superconducting qubits follows a process involving lithography, depositing of metal, etching, and controlled oxidation as described in. Manufacturers continue to improve the lifetime of superconducting qubits and have made significant improvements since the early 2000s.\n\n\n=== Josephson junctions ===\n\nOne distinguishable attribute of superconducting quantum circuits is the use of Josephson junctions. Josephson junctions are an electrical element which does not exist in normal conductors. Recall that a junction is a weak connection between two leads of wire (in this case a superconductive wire) on either side of a thin layer of insulator material only a few atoms thick, usually implemented using shadow evaporation technique. The resulting Josephson junction device exhibits the Josephson Effect whereby the junction produces a supercurrent. An image of a single Josephson junction is shown to the right. The condensate wave function on the two sides of the junction are weakly correlated, meaning that they are allowed to have different superconducting phases. This distinction of nonlinearity contrasts continuous superconducting wire for which the wave function across the junction must be continuous. Current flow through the junction occurs by quantum tunneling, seeming to instantaneously \"tunnel\" from one side of the junction to the other. This tunneling phenomenon is unique to quantum systems. Thus, quantum tunneling is used to create nonlinear inductance, essential for qubit design as it allows a design of anharmonic oscillators for which energy levels are discretized (or quantized) with nonuniform spacing between energy levels, denoted \n  \n    \n      \n        Δ\n        E\n      \n    \n    {\\displaystyle \\Delta E}\n  \n. In contrast, the quantum harmonic oscillator cannot be used as a qubit as there is no way to address only two of its states, given that the spacing between every energy level and the next is exactly the same.\n\n\n== Qubit archetypes ==\nThe three primary superconducting qubit archetypes are the phase, charge and flux qubit. Many hybridizations of these archetypes exist including the fluxonium, transmon, Xmon, and quantronium. For any qubit implementation the logical quantum states \n  \n    \n      \n        {\n        \n          |\n        \n        0\n        ⟩\n        ,\n        \n          |\n        \n        1\n        ⟩\n        }\n      \n    \n    {\\displaystyle \\{|0\\rangle ,|1\\rangle \\}}\n  \n are mapped to different states of the physical system (typically to discrete energy levels or their quantum superpositions). Each of the three archetypes possess a distinct range of Josephson energy to charging energy ratio. Josephson energy refers to the energy stored in Josephson junctions when current passes through, and charging energy is the energy required for one Cooper pair to charge the junction's total capacitance. Josephson energy can be written as \n\n  \n    \n      \n        \n          U\n          \n            j\n          \n        \n        =\n        −\n        \n          \n            \n              \n                I\n\n---\n",
  "arxiv_docs": "Index: 1\nTitle: The Rise of Quantum Internet Computing\nPublished: 2022-08-01\nAuthors: Seng W. Loke\nSource: Arxiv research paper\nContent: arXiv:2208.00733v1  [cs.ET]  1 Aug 2022\nIEEE IOT MAGAZINE, VOL. XX, NO. X, X 2022\n1\nThe Rise of Quantum Internet Computing\nSeng W. Loke, Member, IEEE\nAbstract—This article highlights quantum Internet computing as referring to distributed quantum computing over the quantum Internet,\nanalogous to (classical) Internet computing involving (classical) distributed computing over the (classical) Internet. Relevant to\nquantum Internet computing would be areas of study such as quantum protocols for distributed nodes using quantum information for\ncomputations, quantum cloud computing, delegated veriﬁable blind or private computing, non-local gates, and distributed quantum\napplications, over Internet-scale distances.\nIndex Terms—quantum Internet computing, quantum Internet, distributed quantum computing, Internet computing, distributed\nsystems, Internet\n”This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this\nversion may no longer be accessible.”\n✦\n1\nINTRODUCTION\nT\nHERE have been tremendous developments in quantum\ncomputing, quantum cryptography, quantum commu-\nnications and the quantum Internet, and we have seen\nincreased investments and intensive research in quantum\ncomputing in recent years [1], [2]. The quantum Internet will\nnot necessarily replace the (classical) Internet we know and\nuse today, at least not in the near future, but can complement\nthe current Internet. The quantum Internet aims to enable\nrobust quantum teleportation (or transmission) of qubits,1\nand entanglement among qubits,2 over long Internet-scale\ndistances, which are key to many of the quantum protocols\nincluding quantum key distribution, quantum voting, and\nothers, as well as for non-local control of quantum gates.\nThere have been efforts to build quantum computers,\nand it remains to see if any one paradigm becomes the\ndominant or best way of building such quantum comput-\ners. At the same time, even as researchers develop more\npowerful quantum computers (supporting more qubits for\noperations, and at lower error rates), there is an opportunity\nfor connecting multiple quantum computers from differ-\nent sites to achieve much more complex quantum com-\nputations, i.e., inter-linking multiple quantum computers\non different sites to perform distributed computing with\na distributed system of quantum computers (or quantum\nprocessing units (QPUs) at different nodes), arriving at the\nnotion of distributed quantum computing, e.g., [3].\nWhile distributed quantum computing can involve mul-\ntiple QPUs next to each other or at the same site, with the\nquantum Internet, one can envision distributed quantum\n•\nSeng W. Loke is with the School of Information Technology, Deakin\nUniversity, Melbourne, Australia.\nE-mail: see https://www.deakin.edu.au/about-deakin/people/seng-loke.\nManuscript received X XX, 20XX; revised X XX, 20XX.\n1. A qubit is the basic unit of quantum information, and can be\nthought of as a two-state, or two-levelled, quantum-mechanical system,\nsuch as an electron’s spin, where the two levels are spin up and spin\ndown, or a photon’s polarization, where the two states are the vertical\npolarization and the horizontal polarization.\n2. Multiple qubits at different sites can share an entangled state, a\nsuperpositon of “specially correlated” states, to be used in distributed\nalgorithms.\ncomputing over nodes geographically far apart. As noted\nin [4], the idea is the quantum Internet as the “underly-\ning infrastructure of the Distributed Quantum Computing\necosystem.”\nThis article highlights the emerging area of distributed\nquantum computing over the quantum Internet, which we\nrefer to as quantum Internet computing, i.e., the idea of com-\nputing using quantumly connected distributed quantum\ncomputers over Internet-scale distances. Hence, quantum\nInternet computing is not a new concept in itself but a\nproposed “umbrella term” used here for the collection of\ntopics (listed below), from an analogy to (classical) Internet\ncomputing.\nInternet computing, where one does distributed comput-\ning but over Internet-scale distances and distributed sys-\ntems involve nodes connected via the Internet, is at the inter-\nsection of work in (classical) distributed computing and the\n(classical) Internet. Analogous to Internet computing, one\ncould ask the question of what would be at the intersection\nof work in distributed quantum computing and work on the\nquantum Internet, which brings us to the notion of quantum\nInternet computing.\nAlso, while the quantum Internet and distributed quan-\ntum computing are still nascent research areas, there are at\nleast three key topics which can be considered as relevant to\nquantum Internet computing:\n•\ndistributed quantum computing, including quantum\nprotocols from theoretical perspectives involving\ncommunication complexity studies, and distributed\nquantum computing via non-local or distributed\nquantum gates,\n•\nquantum cloud computing with a focus on delegat-\ning quantum computations, blind quantum comput-\ning, and verifying delegated quantum computations,\nand\n•\ncomputations and algorithms for the quantum Inter-\nnet including key ideas such as quantum entangle-\nment distillation, entanglement swapping, quantum\nIEEE IOT MAGAZINE, VOL. XX, NO. X, X 2022\n2\nrepeaters, and quantum Internet standards.3\nWe brieﬂy discuss the above topics in the following sections.\n2\nDISTRIBUTED QUANTUM COMPUTING\nDistributed quantum computing problems and quantum\nprotocols have been well-studied for over two decades,\nfrom a theoretical computer science perspective,4 many of\nwhich have their inspiration from classical distributed com-\nputing research. Quantum versions of classical distributed\ncomputing problems and protocols, and new forms of dis-\ntributed computing using quantum information, have been\nexplored, e.g., the distributed three-party product problem,\nthe distributed Deutsch-Jozsa promise problem and the\ndistributed intersection problem, demonstrating how, for\nsome problems, quantum information can enable fewer\nbits of communication to be used for a solution, and how\ncertain distributed computation problems can be solved\nwith quantum information, but cannot be solved classically.\nMany quantum protocols, including quantum coin ﬂipping,\nquantum leader election, quantum anonymous broadcast-\ning, quantum voting, quantum Byzantine Generals, quan-\ntum secret sharing, and quantum oblivious transfer, can\nbe viewed as “quantum versions” of classical distributed\ncomputing problems, and have been studied extensively.\nAnother area of study, which has also been considered\nas distributed quantum computing, is non-local gates, or\nthe non-local control of quantum gates, including early\nwork nearly over two decades ago.5 Key to performing\nsuch non-local control of quantum gates is the use of en-\ntanglement, which can be viewed as a resource for such\nnon-local computations. More recent work has looked at\nhow to partition the computations of distributed quantum\ncircuits over multiple QPUs, e.g., [3] as we mentioned earlier\n- with considerations including distributing computations\nin such a way as to optimize performance and to reduce the\nrequirements on entanglement, since if the entanglements\nrequired are generated at too low a rate, this will hold up\ncomputations. The key motivation here is to inter-link a\nset of quantum computers to form effectively a much more\npowerful quantum computer.\n3\nQUANTUM CLOUD COMPUTING AND DELEGAT-\nING QUANTUM COMPUTATIONS\nWe have seen big tech companies and startups offering\nquantum computing as a service similar to accessing other\ncloud service offerings, which is a fantastic resource for\nexperimentation and studies.\nMore formally, studies into delegating quantum com-\nputation from a client (which can be either classical, or\nalmost classical, i.e., with minimal capability to perform\n3. For example, see https://www.ietf.org/archive/id/draft-irtf-qirg-principles-10.html\n[last accessed: 1/8/2022]\n4. For example, see Buhrman and R¨ohrig’s paper dating back to\n2003: https://link.springer.com/chapter/10.1007/978-3-540-45138-9 1\n[last accessed: 1/8/2022]\n5. For example, see the work by Yimsiriwattana and Lomonaco\nJr.\nin\nhttps://arxiv.org/pdf/quant-ph/0402148.pdf\nand\na\ndistributed\nversion\nof\nShor’s\nfamous\nfactorization\nalgorithm\nhttps://arxiv.org/abs/2207.05976 [last accessed: 1/8/2022]\ncomputations such as teleporting qubits, applying simple\nPauli quantum operations, and doing basic measurements)\nwhich is much more restricted than the server (assumed\nto be a universal quantum computer) have been studied,\ncalled delegated quantum computing. And when the server\nis prevented from knowing the client’s inputs but still can\nperform delegated computations, by a technique such as\nthe quantum one-time pad (where the client applies Pauli\noperations to add uncertainty from the server’s perspective,\nthereby effectively encrypting the quantum inputs it sends\nto the server, and keeps track of operations it later needs\nto decrypt the outputs from the server), this is called blind\nquantum computing.\nIn order to be sure that the server does indeed perform\nthe required quantum operations delegated to it by the\nclient, the client can embed tests (or test runs) into the\ndelegated computations, so that the server (not being able\nto distinguish between tests and normal computations) can\nbe caught out if it did not perform the required compu-\ntations properly. That is, the client can verify if the server\nperformed the required quantum computations.6 Further\nabstractions for delegating quantum computations with\nsupporting cloud services continues to be investigated.\n4\nTHE QUANTUM INTERNET\nAs we mentioned earlier, work on the quantum Internet\nfocuses on how to efﬁciently enable robust entanglement\nshared among qubits over long geographical distances. If\ntwo nodes in different continents share entangled states,\nthen, this can be a resource to do non-local gates, i.e.,\nto perform distributed quantum computations, and enable\nquantum protocols over Internet-scale distances.\nThere have been the use of satellites to enable long dis-\ntance entanglement, as well as the use of optical ﬁbre cables\nto demonstrate entanglement. Key to the quantum Internet\nare ideas such as entanglement swapping and quantum\nrepeaters, including ideas such quantum distillation, to\nachieve high ﬁdelity distributed entangled states over long\ndistances, and quantum error correction - this continues to\nbe a research endeavour as mentioned earlier [2].\nThere are other interesting distributed quantum appli-\ncations to be considered including quantum cryptography,\nquantum sensing, and quantum positioning systems.\n5\nDISTRIBUTED QUANTUM COMPUTING OVER THE\nQUANTUM INTERNET: QUANTUM INTERNET COM-\nPUTING AND THE QUANTUM IOT?\nApart from the many quantum computers available over\nthe cloud by big tech and startups which work at very\nlow temperatures, room temperature quantum computers\nhave also started to emerge.7 This could pave the way\nfor quantum computers at the fog and at the edge, not\njust in remote clouds, and perhaps even mobile quantum\n6. An\nexcellent\nexample\nis\nthe\nwork\nby\nBroadbent\nat\nhttps://theoryofcomputing.org/articles/v014a011/\n[last\naccessed:\n1/8/2022]\n7. See https://spectrum.ieee.org/nitrogen-vacancy-diamond-quantum-computer-\nand also https://otd.harvard.edu/explore-innovation/technologies/scalable-room-t\n[last accessed: 1/8/2022]\nIEEE IOT MAGAZINE, VOL. XX, NO. X, X 2022\n3\ncomputers, or quantum computers embedded into every-\nday devices and objects, if ever! Will we then have the\nquantum Internet of Things (IoT)? The answer remains to\nbe seen, and “quantum entangled things across the world”\nwill likely complement the classical IoT. Future applications\nand potential of quantum Internet computing remains to\nbe investigated. Meanwhile, others have begun to look at\nthe connection between 6G networking and the quantum\nInternet [5].\nREFERENCES\n[1] W.\nKozlowski\nand\nS.\nWehner,\n“Towards\nlarge-scale\nq\n\n---\n\nIndex: 2\nTitle: Unconventional Quantum Computing Devices\nPublished: 2000-03-31\nAuthors: Seth Lloyd\nSource: Arxiv research paper\nContent: arXiv:quant-ph/0003151v1  31 Mar 2000\nUnconventional Quantum Computing Devices\nSeth Lloyd\nMechanical Engineering\nMIT 3-160\nCambridge, Mass. 02139\nAbstract: This paper investigates a variety of unconventional quantum computation de-\nvices, including fermionic quantum computers and computers that exploit nonlinear quan-\ntum mechanics. It is shown that unconventional quantum computing devices can in prin-\nciple compute some quantities more rapidly than ‘conventional’ quantum computers.\nComputers are physical: what they can and cannot do is determined by the laws\nof physics. When scientiﬁc progress augments or revises those laws, our picture of what\ncomputers can do changes. Currently, quantum mechanics is generally accepted as the\nfundamental dynamical theory of how physical systems behave. Quantum computers can\nin principle exploit quantum coherence to perform computational tasks that classical com-\nputers cannot [1-21]. If someday quantum mechanics should turn out to be incomplete\nor faulty, then our picture of what computers can do will change. In addition, the set\nof known quantum phenomena is constantly increasing: essentially any coherent quantum\nphenomenon involving nonlinear interactions between quantum degrees of freedom can\nin principle be exploited to perform quantum logic. This paper discusses how the revi-\nsion of fundamental laws and the discovery of new quantum phenomena can lead to new\ntechnologies and algorithms for quantum computers.\nSince new quantum eﬀects are discovered seemingly every day, let’s ﬁrst discuss two\nbasic tests that a phenomenon must pass to be able to function as a basis for quantum\ncomputation. These are 1) The phenomenon must be nonlinear, and 2) It must be coherent.\nTo support quantum logic, the phenomenon must involve some form of nonlinearity, e.g.,\na nonlinear interaction between quantum degrees of freedom. Without such a nonlinearity\nquantum devices, like linear classical devices, cannot perform even so simple a nonlinear\noperation as an AND gate.\nQuantum coherence is a prerequisite for performing tasks\nsuch as factoring using Shor’s algorithm [10], quantum simulation a la Feynman [11] and\nLloyd [12], or Grover’s data-base search algorithm [13], all of which require extended\nmanipulations of coherent quantum superpositions.\n1\nThe requirements of nonlinearity and coherence are not only necessary for a phe-\nnomenon to support quantum computation, they are also in principle suﬃcient. As shown\nin [14-15], essentially any nonlinear interaction between quantum degrees of freedom suf-\nﬁces to construct universal quantum logic gates that can be assembled into a quantum\ncomputer. In addition, the work of Preskill et al. [18] on robust quantum computation\nshows that an error rate of no more than 10−4 per quantum logic operation allows one to\nperform arbitrarily long quantum computations in principle.\nIn practice, of course, few if any quantum phenomena are likely to prove suﬃciently\ncontrollable to provide extended quantum computation. Promising devices under current\nexperimental investigation include ion traps [5,7], high ﬁnesse cavities for manipulating\nlight and atoms using quantum electrodynamics [6], and molecular systems that can be\nmade to compute using nuclear magnetic resonance [8-9]. Such devices store quantum\ninformation on the states of quantum systems such as photons, atoms, or nuclei, and\naccomplish quantum logic by manipulating the interactions between the systems via the\napplication of semiclassical potentials such as microwave or laser ﬁelds. We will call such\ndevices ‘conventional’ quantum computers, if only because such devices have actually been\nconstructed.\nThere is another sense in which such computers are conventional: although the de-\nvices described above have already been used to explore new regimes in physics and to\ncreate and investigate the properties of new and exotic quantum states of matter, they\nfunction according to well established and well understood laws of physics. Perhaps the\nmost striking examples of the ‘conventionality’ of current quantum logic devices are NMR\nquantum microprocessors that are operated using techniques that have been reﬁned for\nalmost half a century. Ion-trap and quantum electrodynamic quantum computers, though\ncertainly cutting edge devices, operate in a quantum electrodynamic regime where the\nfundamental physics has been understood for decades (that is not to say that new and\nunexpected physics does not arise frequently in this regime, rather that there is general\nagreement on how to model the dynamics of such devices).\nMake no mistake about it: a conventional quantum logic device is the best kind of\nquantum logic device to have around. It is exactly because the physics of nuclear magnetic\nresonance and quantum electrodynamics are well understood that devices based on this\nphysics can be used systematically to construct and manipulate the exotic quantum states\nthat form the basis for quantum computation.\nWith that recognition, let us turn to\n2\n‘unconventional’ quantum computers.\nPerhaps the most obvious basis for an unconventional quantum computer is the use\nof particles with non-Boltzmann statistics in a reﬁme where these statistics play a key role\nin the dynamics of the device. For example, Lloyd [16] has proposed the use of fermions\nas the fundamental carriers of quantum information, so that a site or state occupied by a\nfermion represents a 1 and an unoccupied site or state represents a 0. It is straightforward\nto design a universal quantum computer using a conditional hopping dynamics on an array\nof sites, in which a fermion hops from one site to another if only if other sites are occupied.\nIf the array is one-dimensional, then such a fermionic quantum computer is equivalent\nto a conventional quantum computer via the well-known technique of bosonization. If the\narray is two or more dimensional, however, a local operation involving fermions on the\nlattice cannot be mocked up by a local operation on a conventional quantum computer,\nwhich must explicitly keep track of the phases induced by Fermi statistics. As a result,\nsuch a fermionic computer can perform certain operations more rapidly than a conventional\nquantum computer. An obvious example of a problem that can be solved more rapidly on\na fermionic quantum computer is the problem of simulating a lattice fermionic system in\ntwo or more dimensions. To get the antisymmetrization right in second quantized form,\na conventional ‘Boltzmann’ quantum computer takes time proportional to Tℓd−1 where T\nis the time over which the simulation is to take place, ℓis the length of the lattice and\nd is the dimension, while a fermionic quantum computer takes time proportional to T.\n(Here we assume that the computations for both conventional and Fermionic quantum\ncomputers can take advantage of the intrinsic parallelizability of such simulations: if the\ncomputations are performed serially an additional factro of ℓd is required for both types\nof computer to update each site sequentially.)\nAs the lattice size ℓand the dimension d grow large, the diﬀerence between the two\ntypes of computer also grows large. Indeed, the problem of simulating fermions hopping\non a hypercube of dimension d as d →∞is evidently exponentially harder on a con-\nventional quantum computer than a Fermionic quantum computer.\nSince a variety of\ndiﬃcult problems such as the travelling-salesman problem and data-base search problem\ncan be mapped to particles hopping on a hypercube, it is interesting to speculate whether\nfermionic computers might provide an exponential speed-up on problems of interest in ad-\ndition to quantum simulation. No such problems are currently known, however. Fermionic\ncomputers could be realized in principle by manipulating the ways in which electrons and\n3\nholes hop from site to site on a semiconductor lattice (though problems of decoherence are\nlikely to be relatively severe for such systems).\nIt might also be possible to construct bosonic computers using photons, phonons, or\natoms in a Bose-Einstein condensate. Such systems can be highly coherent and support\nnonlinear interactions: phonons and photons can interact in a nonlinear fshion via their\ncommon nonlinear interaction with matter, and atoms in a Bose condensate can be made\nto interact bia quantum electrodynamics (by introduction of a cavity) or by collisions. So\nfar, however, the feature of Bose condensates that makes them so interesting from the point\nof view of physics — all particles in the same state — makes them less interesting from the\npoint of view of quantum computation. Many particles in the same state, which can be\nmanipulated coherently by a variety of techniques, explore the same volume of Hilbert space\nas a single particle in that state. As a result, it is unclear how such a bosonic system could\nprovide a speed-up over conventional quantum computation. More promising than Bose\ncondensates from the perspective of quantum computation and quantum communications,\nis the use of cavity quantum electrodynamics to ‘dial up’ or synthesize arbitrary states\nof the cavity ﬁeld. Such a use of bosonic states is important for the ﬁeld of quantum\ncommunications, which requires the ability to create and manipulate entangled states of\nthe electromagnetic ﬁeld.\nA third unconventional design for a quantum computer relies on ‘exotic’ statistics\nthat are neither fermionic nor bosonic. Kitaev has recently proposed a quantum computer\narchitecture based on ‘anyons,’ particles that when exchanged acquuire an arbitrary phase.\nExamples of anyons include two-dimensional topological defects in lattice systems of spins\nwith various symmetries. Kitaev noted that such anyons could perform quantum logic via\nAharonov-Bohm type interactions [19]. Preskill et al. have shown explicitly how anyonic\nsystems could compute in principle [20], and Lloyd et al.\nhave proposed methods of\nrealizing anyons using superconducting circuits (they could also in principle be constructed\nusing NMR quantum computers to mock up the anyonic dynamics in an eﬀectively two-\ndimensional space of spins) [21]. The advantage of using anyons for quantum computation\nis that their nonlocal topological nature can make them intrinsically error-correcting and\nvirtually immune to the eﬀects of noise and interference.\nAs the technologies of the microscale become better developed, more and more po-\ntential designs for quantum computers, both conventional and unconventional, are likely\nto arise. Additional technologies that could prove useful for the construction of quantum\n4\nlogic devices include photonic crystals, optical hole-burning techniques, electron spin res-\nonance, quantum dots, superconducting circuits in the quantum regime, etc. Since every\nquantum degree of freedom can in principle participate in a computation one cannot a\npriori rule out the possibility of using currently hard to control degrees of freedom such as\nquark and gluon in complex nuclei to process information. Needless to say, most if not all\nof the designs inspired by these technologies are likely to fail. There is room for optimism\nthat some such quantum computer designs will prove practicable, however.\nThe preceding unconventional designs for quantum computers were based on existing,\nexperimentally conﬁrmed physical phenomena (except in the case of non-abelian anyons).\nLet us now turn to designs based on speculative, hypothetical, and not yet veriﬁed phenom-\nena. (One of the most interesting of these phenomena is large-scale quantum computation\nitself: can we create and systematically transform entangled states involving hundreds or\nthousands of quantum variables?) A particularly powerful hypothesis from the point of\nview of quantum computation is that of nonlinear quantum mechanics.\nThe conventional picture of quantum mechanics is that it is linear in the sense that the\nsuperposition principle is obeyed exactly. (Of course, quantum systems can still exhibit\nnonlinear interaction\n\n---\n\nIndex: 3\nTitle: Geometrical perspective on quantum states and quantum computation\nPublished: 2013-11-20\nAuthors: Zeqian Chen\nSource: Arxiv research paper\nContent: arXiv:1311.4939v1  [quant-ph]  20 Nov 2013\nGeometrical perspective on quantum states and quantum computation\nZeqian Chen\nState Key Laboratory of Resonances and Atomic and Molecular Physics,\nWuhan Institute of Physics and Mathematics, Chinese Academy of Sciences,\n30 West District, Xiao-Hong-Shan, Wuhan 430071, China\nWe interpret quantum computing as a geometric evolution process by reformulating ﬁnite quantum\nsystems via Connes’ noncommutative geometry. In this formulation, quantum states are represented\nas noncommutative connections, while gauge transformations on the connections play a role of\nunitary quantum operations. Thereby, a geometrical model for quantum computation is presented,\nwhich is equivalent to the quantum circuit model. This result shows a geometric way of realizing\nquantum computing and as such, provides an alternative proposal of building a quantum computer.\nPACS numbers: 03.67.Lx, 03.65.Aa\nQuantum computation has the advantage of solving\neﬃciently some problems that are considered intractable\nby using conventional classical computation [1]. In this\ncontext, there are two remarkable algorithms found:\nShor’s factoring algorithm [2] and Grove’s search algo-\nrithm [3].\nBut it remains a challenge to ﬁnd eﬃcient\nquantum circuits that can perform these complicated\ntasks in practice, due to quantum decoherence. A cru-\ncial step in the theory of quantum computer has been\nthe discovery of error-correcting quantum codes [4] and\nfault-tolerant quantum computation [5, 6], which estab-\nlished a threshold theorem that proves that quantum de-\ncoherence can be corrected as long as the decoherence is\nsuﬃciently weak. To tackle this barrier, a revolutionary\nstrategy, topological quantum computation (see [7] and\nreferences therein), is to make the system immune to the\nusual sources of quantum decoherence, by involving the\nglobally robust topological nature of the computation.\nRecently, substantial progress in this ﬁeld has been made\non both theoretical and experimental fronts [8].\nIn this paper, we provide an alternative approach to\nquantum computation from a geometrical view of point.\nTo this end, we need to reformulate quantum mechanics\nvia Connes’ noncommutative geometry [9]. In this for-\nmulation, quantum states are represented as noncommu-\ntative connections, while gauge transformations on the\nconnections play a role of unitary quantum operations.\nIn this way, we present a geometrical model for quan-\ntum computation, which is equivalent to the quantum\ncircuit model. In this computational model, information\nis encoded in gauge states instead of quantum states and\nimplementing on gauge states is played by gauge transfor-\nmations. Therefore, our scheme shows a geometric way\nof realizing quantum computing and as such, provides an\nalternative proposal of building a quantum computer.\nLet H be a N dimensional Hilbert space associated\nwith a ﬁnite quantum system. Let A be the algebra of\nall (bounded) linear operators on H, and let U(A) = {u ∈\nA : uu∗= u∗u = I} with I being the unit operator on\nH. Given a selfadjoint operator D on H, (A, H, D) is a\nspectral triple in the sense of noncommutative geometry\n[9, 10]. A (noncommutative) connection on (A, H, D) is\ndeﬁned to be a selfadjoint operator V on H of the form\nthat follows\nV =\nX\nj\naj[D, bj]\n(1)\nwhere aj, bj ∈A and [a, b] = ab −ba. A gauge transform\non a connection V under u ∈U(A) is deﬁned as\nV 7−→Gu(V ) = uV u∗+ u[D, u∗].\n(2)\nFor avoiding triviality, we always assume that D ̸= 0 or\nI in what follows.\nFor any (pure) quantum state |ψ⟩⟨ψ| with ψ being a\nunit vector in H, we have\n|ψ⟩⟨ψ| = |ψ⟩⟨ϕ|i[D, b]|ϕ⟩⟨ψ|\nwhere i = √−1 and, b is a selfjoint operator on H such\nthat i[D, b] has eigenvalue 1 at |ϕ⟩. Such a selfjoint oper-\nator b always exists because D ̸= 0 or I. In this case,\n|ψ⟩⟨ψ| = ia∗[D, ba] −ia∗b[D, a]\n(3)\nwith a = |ϕ⟩⟨ψ|. Thus, every quantum state |ψ⟩⟨ψ| can\nbe represented as a connection, denoted by Vψ, i.e.,\nVψ = ia∗[D, ba] −ia∗b[D, a].\n(4)\nLet GD(H) be the set of all connections V which can\nbe written as V = Vψ + uDu∗−D with ψ being a unit\nvector in H and u ∈U(A). An element in GD(H) is said\nto be a gauge state on (A, H, D). Any quantum state is\nnecessarily a gauge state, but a gauge state need not to\nbe a quantum state. However, any gauge state V can be\nobtained from a quantum state by performing a gauge\ntransform. Indeed, if V = Vψ + uDu∗−D then V =\nGu(Vu∗ψ). Moreover, for any gauge state V on (A, H, D)\nwe have (see [11])\n• for any u ∈U(A), Gu(V ) is again a gauge state;\n• Guv(V ) = Gu(Gv(V )) for all u, v ∈U(A).\nTherefore, a gauge transform preserves gauge states.\nLet V be a gauge state which is prepared from a quan-\ntum state |ψ⟩⟨ψ| by operating a gauge transform Gu, i.e.,\n2\nV = Gu(Vψ). For any event E, the probability of E oc-\ncurring on V is\n⟨E⟩V = ⟨ψ|u∗Eu|ψ⟩.\n(5)\nNote that a gauge state may be prepared in several ways.\nHence, the probability of a event E occurring on a gauge\nstate V depends on the quantum state from which V is\nprepared.\nLet H be a selfadjoint operator on H. Assuming ut =\neitH for t ∈R, we have that the gauge transforms Vt =\nGt(V ) on a ﬁxed gauge state V under ut form a group\n(see [11]), that is,\nGt+s(V ) = Gt(Gs(V )).\n(6)\nThis yields a dynamical equation governed by the Hamil-\ntonian H for gauge states on (A, H, D) as follows [12]\nidVt\ndt = [Vt, H] + [D, H]\n(7)\nwith V0 = V. In particular, for a unit vector ψ we have\nVt = Gt(Vψ) = Vutψ + utDu∗\nt −D.\n(8)\nWe now turn to product of two spectral triples. Sup-\npose (Ai, Hi, Di), i = 1, 2, are two spectral triple associ-\nated with ﬁnite quantum systems. Put\nD = D1 ⊗I2 + I1 ⊗D2\n(9)\nwith Ii being the unit operator on Hi (i = 1, 2). Then\nD is a selfjoint operator on H1 ⊗H2. The spectral triple\n(A1⊗A2, H1⊗H2, D) is called the product of two spectral\ntriples (Ai, Hi, Di), i = 1, 2.\nNow we illustrate our scheme by using a qubit. Let\nH = C2 and\nσx =\n\u0014\n0 1\n1 0\n\u0015\n, σy =\n\u0014\n0 −i\ni\n0\n\u0015\n, σz =\n\u0014\n1\n0\n0 −1\n\u0015\n.\n(10)\nThen (M2, C2, D) is a spectral triple with D = σx, where\nM2 is the set of all 2×2 complex matrices. For |0⟩=\n\u0014\n1\n0\n\u0015\n,\nwe have\nV|0⟩=\n\u0014\n1 0\n0 0\n\u0015\n,\nGσx(V|0⟩) =\n\u0014\n0 0\n0 1\n\u0015\n,\nand\nGσy(V|0⟩) =\n\u0014\n0\n−2\n−2\n1\n\u0015\n,\nGσz(V|0⟩) =\n\u0014\n1\n−2\n−2\n0\n\u0015\n.\nFor |1⟩=\n\u0014\n0\n1\n\u0015\n, we have\nV|1⟩=\n\u0014\n0 0\n0 1\n\u0015\nand\nGσy(V|1⟩) =\n\u0014\n1\n−2\n−2\n0\n\u0015\n.\nHence Gσy(V|1⟩) = Gσz(V|0⟩) and so, the gauge state\nV =\n\u0014\n1\n−2\n−2\n0\n\u0015\ncan be prepared in two diﬀerent ways.\nWe are now ready to interpret quantum computation\nfrom a geometrical view of point.\nBut let us take a\nstep backward and discuss the standard quantum circuit\nmodel for computation [13]. Let H = (C2)⊗n, the tensor\nproduct of n copies of C2. A quantum circuit model on\nn qubits consists of\n• a initial state |ψ⟩, represented by a unit vector ψ ∈\nH;\n• a quantum circuit Γ = UNUN−1 · · · U1, where quan-\ntum “gates” Uk 1 ≤k ≤N, are unitary transfor-\nmations on either C2\ni or C2\ni ⊗C2\nj, 1 ≤i, j ≤n, the\nidentity on all remaining factors;\n• reading the output of the circuit Γ|ψ⟩by measuring\nthe ﬁrst qubit; the probability of observing |1⟩is\nP(Γ) = ⟨ψ|Γ∗Π1Γ|ψ⟩, where Π1 = |1⟩⟨1| ⊗I · · · ⊗I\nis the projection to |1⟩in the ﬁrst qubit.\nLet A = M2n. Put\nD =\nn\nX\ni=1\nI ⊗· · · ⊗I\n|\n{z\n}\ni−1\n⊗σx ⊗I · · · ⊗I\nwhere I is the identity on C2. A computational model\nbased on the spectral triple (A, H, D) is as follows:\n• Initialization of a gauge state Vψ in the spectral\ntriple (A, H, D), where ψ is a unit vector in H;\n• Gauge implementation of the computational pro-\ngram\nG(Γ) = GUN GUN−1 · · · GU1\nwhere “gates” GUk, 1 ≤k ≤N, are gauge transfor-\nmations induced by Uk;\n• Application of the projection operator Π1 for read-\ning the output of the computation G(Γ)(Vψ);\nthe probability of observing |1⟩is P(GΓ)\n=\n⟨ψ|Γ∗Π1Γ|ψ⟩because G(Γ)(Vψ) = GΓ(Vψ) (see\n[11]), i.e., G(Γ)(Vψ) = Γ|ψ⟩⟨ψ|Γ∗+ ΓDΓ∗−D.\nThus, we obtain a geometrical model on n qubits for\nquantum computation, which is evidently equivalent to\nthe quantum circuit model as described above. Due to\nthe essential role of gauge transformations played in this\ncomputational model, we call this scheme gauge quantum\ncomputation.\nAs illustration, we give the Deutsch-Jozsa algorithm\n[14] in gauge quantum computation. Let f : {0, 1}n 7→\n{0, 1} be a function that takes an n-bit into a bit. We\ncall f balanced if f(x) = 1 for exactly half of all possible\n3\nx and f(x) = 0 for the other half.\nGiven a function\nf that is either constant or balanced, we want to ﬁnd\nout which it is with certainty. More precisely, we select\none x ∈{0, 1}n and calculate f(x) with the result being\neither 0 or 1. What is the fewest number of queries that\nwe can make to determine whether or not f is constant?\nIn the classical case, at worst we will need to calculate f\n2n−1 + 1 times, because we may ﬁrst obtain 2n−1 zeros\nand will need one more query to decide.\nHowever, in\nthe setting of quantum computation we could achieve the\ngoal in just one query using the Deutsch-Jozsa algorithm.\nIn the sequel, we give a realization of the Deutsch-Jozsa\nalgorithm in gauge quantum computation.\nLet H = (C2)⊗(n+1) and A = M2n+1. Given a selfad-\njoint operator D on H that is not 0 or I, we get the desired\nspectral triple (A, H, D). For a given f, we deﬁne the as-\nsociated operator Uf on H as Uf|x, y⟩= |x, y ⊕f(x)⟩for\nx ∈{0, 1}n and y ∈{0, 1}. Recall that the Hadamard\noperator H on C2 is\nH =\n1\n√\n2\nX\nx,y∈{0,1}\n(−1)x·y|x⟩⟨y|\nwhere x·y signiﬁes ordinary multiplication. The following\nis the Deutsch-Jozsa algorithm in the setting of gauge\nquantum computation:\n• Initialization of a gauge state Vψ with ψ = |0⟩⊗n ⊗\n|1⟩;\n• Gauge implementation of the computational pro-\ngram G(Γ) = GH⊗n⊗IGUf GH⊗(n+1);\n• Application of the projection operator Π|0⟩⊗n for\nreading the output of the computation G(Γ)(Vψ),\nwhere Π|0⟩⊗n is the projection to |0⟩⊗n in the ﬁrst\nn qubits.\nThe ﬁnal gauge state is V = VΓψ + ΓDΓ∗−D with Γ =\n(H⊗n ⊗I)UfH⊗(n+1), where\nΓψ =\nX\nx,y∈{0,1}n\n(−1)x·y+f(x)\n2n\n|y⟩⊗|0⟩−|1⟩\n√\n2\n.\nSince the amplitude for the state |0⟩⊗n in the ﬁrst n\nqubits is P\nx(−1)f(x)/2n, the probability of observing 0\nis 1 if f is constant, or 0 if f is balanced. Thus we have\ntwo possibilities of obtaining the outcome zero or the\noutcome nonzero. In the ﬁrst case, f is certainly constant\nand in the second case f must be balanced. Therefore,\nwe only need to perform three times gauge transforms for\ndetermining whether or not f is constant.\nIn conclusion, we present a geometrical description of\nquantum computation via noncommutative geometry. In\nthis geometrical model, information is encoded in gauge\nstates and computational operation is implemented by\ngauge transforms instead of unitary transforms. In prin-\nciple, gauge transforms are easier to perform than uni-\ntary quantum operation [15]. Therefore, gauge quantum\ncomputation should be more accessible than the usual\nquantum circuit computation and as such, this provides\nan alternative proposal of building a quantum computer.\nThis work was supported in part by the NSFC under\nGrant No. 11171338 and National Basic Research Pro-\ngram of China under Grant No. 2012CB922102.\n[1] M. A. Nielsen, I. L. Chuang, Quantum Computation\nand Quantum Information (Cambridge University Press,\nCambridge, 2000).\n[2] P. Shor, Algorithms for quantum computation, discrete\nlogarithms and factoring, Proc. 35th Annual Symposium\non Foundations of Computer Science (IEEE Computer\nSociety Press, Los Alamitos, CA, 1994, 124-134).\n[3] L. Grover, Quantum mechanics helps in search for a nee-\ndle in a haystack, Phys. Rev. Lett. 79 (1997), 325-328.\n[4] P. Shor, Scheme for reducing decoherence in quantum\ncomputer memory, Phys. Rev. A 52 (1995), 2493-2496.\n[5] J. Preskill, Fault-tolerant quantum computation, arXiv:\nquant-ph/9712048, 1997.\n[6] P. Shor, Fault-tolerant quantum computation, Proc. 37th\nAnnual Symposium on Foundations of Computer Science\n(IEEE Computer Society Press, Los Alamitos, CA, 1996,\n56-65).\n[7] C. Nayak, S. H. Simon, A. Stern, M. Freedman, S. Das\nSarma, Non-Abelian anyons and topological quantum\ncomputation, Rev. Mod. Phys. 80 (2008), 1083-1159.\n[8] A.\nStern,\nN.\nH.\nLindner,\nTopological\n\n---\n",
  "news": [
    {
      "title": "Controversial Quantum-Computing Paper Gets a Hefty Correction - Scientific American",
      "description": "Controversial Quantum-Computing Paper Gets a Hefty Correction  Scientific American",
      "published date": "Thu, 21 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiqAFBVV95cUxPSW96UWVEdWFvaWFsNWl4VUhVYi1NUVlxcXlEdkVjaVl0Q3YydEh0NVBia09KclpwWGMyQi1ld1lXSkFOdEdLWENRSkxNbmtfYWhldFVyUUJuejZuOWZaLWNRQkVrYjlLb2dZMVQyR0daUi1DN05TbDJRZkZBeVFmUHBjVFFpQ0praV92LUVDa2dDWDF0YS1oanFHMk1TY2dVeW5VMFk1eVE?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.scientificamerican.com",
        "title": "Scientific American"
      }
    },
    {
      "title": "Fractional computing - Nature",
      "description": "Fractional computing  Nature",
      "published date": "Mon, 11 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiX0FVX3lxTE41RHEyX1hkZTh0TWhNRXpZS0pkVTAxR01Eci15YVJNNUlwX2ppa1RXN2hyXzN2MTlwQld4aDZBSnVZTjZ0T1Y2azVCLUlCYm1VZTBRUDhfRFhPZzJXNTRj?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.nature.com",
        "title": "Nature"
      }
    },
    {
      "title": "New MIT report captures state of quantum computing - MIT Sloan",
      "description": "New MIT report captures state of quantum computing  MIT Sloan",
      "published date": "Tue, 19 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMimAFBVV95cUxOR2tKUjRyRkUtTklQSlR1ajI2MFRUQUNhNlJ3MURQaEk4bmlkc2IzRWVDWEdpMnd6cm42TU9GSVozMDlQUGlBYktqTkFQdlZpQmRaU1AyeEtWWEQ3SWR2U3JQc2pWeHdWcFNTbFp1ZlBiR1B1N2JlWUtTWFo4ZXNCOTE5ekFnenpYUEhJaGFXeFNicEhwNUZuUg?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://mitsloan.mit.edu",
        "title": "MIT Sloan"
      }
    },
    {
      "title": "Is Your Quantum Computer Faking It? Physicists Unveil a “Quantum Lie Detector” - SciTechDaily",
      "description": "Is Your Quantum Computer Faking It? Physicists Unveil a “Quantum Lie Detector”  SciTechDaily",
      "published date": "Wed, 13 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiowFBVV95cUxONGFlQUk2bVRab2V6TmtyRVVCMERUNGVUSWRydmNoOHRKQUl4TXVRYnlrSnBseXlGVlNDLVgtTldqUUVZWEtJRkFybUVfZTBFbWJlNmZvTXRRbk41OGlmdXZKQWxNMzExZ2FKVnhGNU5SSzJldnRsSm5VLTl3Q1NRZThPS3dpSUp4Wk1PMTNGTHRFbWNBNVFlV2RZOUZSQjdLcDZN?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://scitechdaily.com",
        "title": "SciTechDaily"
      }
    },
    {
      "title": "Researchers Achieve Quantum Computing Milestone, Realizing Certified Randomness - College of Natural Sciences",
      "description": "Researchers Achieve Quantum Computing Milestone, Realizing Certified Randomness  College of Natural Sciences",
      "published date": "Wed, 26 Mar 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMitgFBVV95cUxPMTFfcGx0aUFBRUlTS1Q3MG5RMzJZSGEyd1RSQ1RtY2lJR0MwQ1I0bjJFTEhVQjZEQU5fWmUxalQtOXpqd3g1NXN6Q09wR3NQaE9qUTRmQzFHdHl3QVNwSWpXXy02d1N6QkU5Mm1WNDMydEVLYWdPS2NGbjRPbk1JTVozSVJWNkYwdVZMSGdLR21BZWJzZ041cHNyOFhLaXNTcHY5U1YzLUpSYnNnY1ota1l0clc0dw?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://cns.utexas.edu",
        "title": "College of Natural Sciences"
      }
    },
    {
      "title": "Predicted quasiparticles called ‘neglectons’ hold promise for robust, universal quantum computing - Physics World",
      "description": "Predicted quasiparticles called ‘neglectons’ hold promise for robust, universal quantum computing  Physics World",
      "published date": "Thu, 14 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMivwFBVV95cUxPU2l6YUdMbktqR21oZkthZ2o5MlhKay0yaTlmaEZFcDF2TDNtYnBsNkV1MUY5U1BrbmZWSmlIU1hiTFZseVBvR2FaQnVkVnptXzA0Tk9haEVWTEs5VGJSVlZPdXpBRUpTS1JuQkp2WUZNcXpIcTMwbFdLcWVCQ0FSSER4OWc5OUVmYkZDMjgwU2R4eTJFVjRfSHd2TkRwc2VyTFk3MlFTNkxCSFF6VEcyMUhRaG90SFRxRjM3Y1o3MA?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://physicsworld.com",
        "title": "Physics World"
      }
    },
    {
      "title": "‘Neglected’ particles that could rescue quantum computing - USC Today",
      "description": "‘Neglected’ particles that could rescue quantum computing  USC Today",
      "published date": "Tue, 05 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMingFBVV95cUxOSXVIemE2YWl0dmR4YTQyUXBCZ2NSSU1QQkdaYTZ2cE1ubVp2VEVfdFV0SVlHeU9CQUNoWGE2ZjNuOGdmX2tleXFuZzVQVEh6cE5lQUFDYUFxS3h0T3JrZmIyQ0NNR2lZcFVMcnNaanJzU3pqdlh1NWhHX25MWnQ5R1Z1OGIxQjNfWEZTWkxyOW9WRHhqcjZhTXU1dGNXZw?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://today.usc.edu",
        "title": "USC Today"
      }
    },
    {
      "title": "Quantum Computing Explained: A Must-Read for Executives - Gartner",
      "description": "Quantum Computing Explained: A Must-Read for Executives  Gartner",
      "published date": "Fri, 20 Sep 2024 04:02:19 GMT",
      "url": "https://news.google.com/rss/articles/CBMiY0FVX3lxTE9NVl9iX0w3MTMwaDdhWlczZnpLWUVXMUQ4TXZyZml3Y2ZueWNXMHRuSXphZFJjQ3Zqc1UzLWZJODJYdWhqRndCeTY1elllMkVZN2Z4YmRxRFQtYl9CcHZzbGk5Yw?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.gartner.com",
        "title": "Gartner"
      }
    },
    {
      "title": "The world should prepare for the looming quantum era - Financial Times",
      "description": "The world should prepare for the looming quantum era  Financial Times",
      "published date": "Thu, 21 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMicEFVX3lxTE0xQU1PcUZ5SFNLaExpdm40bHhnQTFfZzdaMkp5TUFaWmZfbEozYWNhUS1XYjE2U1AyNjZ3Q2puOHo4Und4SnlBS3dJMkl3MUh2aEgyZlZIVzdaUERPM0ZYUmlTcUlIMUJDR2NUdFFpNTE?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.ft.com",
        "title": "Financial Times"
      }
    },
    {
      "title": "Universal distributed blind quantum computing with solid-state qubits - Science | AAAS",
      "description": "Universal distributed blind quantum computing with solid-state qubits  Science | AAAS",
      "published date": "Thu, 01 May 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiYEFVX3lxTFBydGhmanRtcFZCWXJhUkNsdTRqYmVwODRpR3I3QlVyejFyclJrZW9oN2lkRXRmeFJ5NlFsd0hXaTNpcDh3T1FBMEFFLS1ieWY3b0U2bEZDd3VQNDFLcnhXMA?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.science.org",
        "title": "Science | AAAS"
      }
    },
    {
      "title": "Topological quantum processor marks breakthrough in computing - UC Santa Barbara",
      "description": "Topological quantum processor marks breakthrough in computing  UC Santa Barbara",
      "published date": "Thu, 20 Feb 2025 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMilwFBVV95cUxQZ1Fad3g2ZGx1ZVpWUUljZzFmUzVtcm9HeWFBNnZtNUxoVTdFTV93WnA0Q0t4QnpiSmQyc1VWUld1dy1YcmhmUVlVX09Da3BaNEpfQ0FoeWdWclZ3ZV9MT05GYU5KbGVsZVl2MVpwR1BPWU1KVDI4clZYaFBGVVFHb2NSYXAxQl9pMXFJRjZaRzhWYWQxVV9V?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://news.ucsb.edu",
        "title": "UC Santa Barbara"
      }
    },
    {
      "title": "The Next Big Cyber Threat Could Come from Quantum Computers… Is the Government Ready? - U.S. Government Accountability Office (GAO) (.gov)",
      "description": "The Next Big Cyber Threat Could Come from Quantum Computers… Is the Government Ready?  U.S. Government Accountability Office (GAO) (.gov)",
      "published date": "Wed, 22 Jan 2025 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMilwFBVV95cUxNY0xQbnpCMktFbVF4QmNoeGQxSGhZXzMzblBwam15VFo1cWdCeWdBRUlzT3dCNmRrSmU0NU1GRmdwY3FqYWZfSUNrNzN3amJCV1Q0Vm5JeVNBbWRGV2NoeTRydFhTQXViT2NTSFljSWxIU3Q0OHdKcGEzQXh1aFVCWmxuV2R4eU1nTldMS0JMLUw5emtPYjA4?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.gao.gov",
        "title": "U.S. Government Accountability Office (GAO) (.gov)"
      }
    },
    {
      "title": "Why Is Sumitomo Corporation Taking on Quantum Computing? Pioneering Real-World Applications at the Forefront of Social Implementation - sumitomocorp.com",
      "description": "Why Is Sumitomo Corporation Taking on Quantum Computing? Pioneering Real-World Applications at the Forefront of Social Implementation  sumitomocorp.com",
      "published date": "Tue, 15 Jul 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiZkFVX3lxTE93VDJhSnhrYmNxdVRpYXlnT3ExbEw3WjB6cnhZTldCbEJHNGVPUy0xYTcwV081V3I2MHVBa1RlSVJUSUNkNUxiVjh2T2pFNVhXTTJadVNsdGtfbDNsalhuclhBVlF1dw?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.sumitomocorp.com",
        "title": "sumitomocorp.com"
      }
    },
    {
      "title": "Quantum computing could be commercial real estate’s next big tailwind - CNBC",
      "description": "Quantum computing could be commercial real estate’s next big tailwind  CNBC",
      "published date": "Tue, 12 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMijwFBVV95cUxPWHV4bE9za2RNVzdfX29fbXNkVmJhX1FkeEtLdDlyLVYwbm11anh6dzBYcnl2X2tfX3hBeWZtZF9Bazl6Y2JJSFZXTG83UURwWUlDOEo4TXc3S1YzckV0SEJkbExFblFtTE41X2k2LXQ4aXdMQmZnUDVSNl9ZQW44UWtsZzFtdnlaU2hfOXA2NNIBlAFBVV95cUxPZFV6R05iOFB3Zm5oVHc4VlY3ZGFtTm9jSmVNU2R0ZWwxcFNnU2JDbVF2akd0ZXd0aWx6ZnVxZnhBSko3VXpTQ3g4S2pkcDVoajZyTjgwZ20xWjZ1V2dBWGp5b0ZfcVNINmcxMUxETnJQLTYwUi1PM3dESjVZUnFUbnR1S08xZXF6bnI0TzVPRWxITzZ2?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.cnbc.com",
        "title": "CNBC"
      }
    },
    {
      "title": "In Initial Stages of Quantum Computing Commercialization, Sales Stats Show IBM Leads in Quantum Deal Value, IQM in Units Sold - The Quantum Insider",
      "description": "In Initial Stages of Quantum Computing Commercialization, Sales Stats Show IBM Leads in Quantum Deal Value, IQM in Units Sold  The Quantum Insider",
      "published date": "Tue, 19 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMi-AFBVV95cUxPT1lBSF8ySkVILS1ZWWxHS0o3U1VrSTFIYlFSV2dfYnBFdkNnYklpczBWMmYzM1QtWnpXQUNsT3dYbC1vS01tM1FwM3V1WUxETFBXT1JuSXVfcmVxQlMtVlNIVC1KMHJocjhFVS1WREQ2UWpzZ3hlSy1TYkd0SlY1b0FudUZlRjVlOXVQS3JOVmpuRS1OSlFCS0w1dkdmTUtpRnVZQWZQb1F1eWt3QmJwQ2lHN0FoZU11YTNIRFZLUnBrY0ZmVEVqU0hoZmxkRDhQdHJ2UVJoUU5XTDBjTGZQSFMxRWs3UHViTHM5RXhlZnlMZjJWajFaRQ?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://thequantuminsider.com",
        "title": "The Quantum Insider"
      }
    },
    {
      "title": "Scientists Unlock Quantum Computing Power by Entangling Vibrations in a Single Atom - SciTechDaily",
      "description": "Scientists Unlock Quantum Computing Power by Entangling Vibrations in a Single Atom  SciTechDaily",
      "published date": "Sun, 24 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMirgFBVV95cUxNMEhLT3lwSEIxUzRDSUhyX3pnYmZsNzZZWkVsaWhQakt6ZERlWHFFQk5pZlNRLU1SNWo1UElSOF9teC00SWF0WHEycGR3Tlpjd1NxWC1LMTBjR25ZaWM1dEJpTllOTWlkZEhyZGZDb3hTSHhQdy1nenFaMUc4NjVJRXI5czAwX2NCbWphdjdQZmwtdTZ3NXNza3E1S2I3Y0diOGs4bzhTQnhiR3QySHc?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://scitechdaily.com",
        "title": "SciTechDaily"
      }
    },
    {
      "title": "Universal logical quantum photonic neural network processor via cavity-assisted interactions - Nature",
      "description": "Universal logical quantum photonic neural network processor via cavity-assisted interactions  Nature",
      "published date": "Wed, 20 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiX0FVX3lxTFBYRzVDSnRvRWlDaHloXzg3YUJGVVJyR3h1bUFkZ0Y3TUw1NFpZVEtRakl6aHBFcFptdkMtSEMzSDM2RmgwcEx2U24xc2tjdW1LQ3B2aVFYaGxKRmhCTVlR?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.nature.com",
        "title": "Nature"
      }
    },
    {
      "title": "Future of Cybersecurity: Leadership Needed to Fully Define Quantum Threat Mitigation Strategy - U.S. Government Accountability Office (GAO) (.gov)",
      "description": "Future of Cybersecurity: Leadership Needed to Fully Define Quantum Threat Mitigation Strategy  U.S. Government Accountability Office (GAO) (.gov)",
      "published date": "Thu, 21 Nov 2024 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiVEFVX3lxTE95cGVaakdNaE1Rc3REWXIyUWZ0NVc5cldlem96Rllsb25tNUJsZG9MUE9RaXJjenJZWDRfd1VMMmM0MElrdjhvdFdfTjdWR056LUpCag?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.gao.gov",
        "title": "U.S. Government Accountability Office (GAO) (.gov)"
      }
    },
    {
      "title": "‘Like the Piano Tuners of Quantum Computers’ - USC Viterbi | School of Engineering - USC Viterbi School of Engineering",
      "description": "‘Like the Piano Tuners of Quantum Computers’ - USC Viterbi | School of Engineering  USC Viterbi School of Engineering",
      "published date": "Tue, 12 Aug 2025 07:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMijwFBVV95cUxOTjc2ZjRmMUJncXFxMHQyUTBwak9GMlhKT1dqY1NjbUw0VEVxTUZoRkZEdXFRUTFqdW1FTldIRGhzeDVoRDdkeWN0U1NabFNBcU5HcHdJeVNZMUpCanNyS1JBeC1QLVFoQW14bWpEQnRLNHJUUHQxZjRGZGFGTkdWemxORzcydGlVMm02dWd0aw?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://viterbischool.usc.edu",
        "title": "USC Viterbi School of Engineering"
      }
    },
    {
      "title": "A manufacturable platform for photonic quantum computing - Nature",
      "description": "A manufacturable platform for photonic quantum computing  Nature",
      "published date": "Wed, 26 Feb 2025 08:00:00 GMT",
      "url": "https://news.google.com/rss/articles/CBMiX0FVX3lxTE9HTE0tZzAzdGMyRE5yYlRkUFJTVVlkUFpUdzVxWWFFVXdwSUxyYUN6eXI3blhTRmVCOHRBajM3eWRleG5xNEctNkNxMTUzSzAydXQybDlzY2Q5YTJIUkw4?oc=5&hl=en-IN&gl=IN&ceid=IN:en",
      "publisher": {
        "href": "https://www.nature.com",
        "title": "Nature"
      }
    }
  ],
  "knowledge": {
    "topic": "Quantum Computing",
    "sources": [
      {
        "id": 1,
        "title": "Quantum computing",
        "authors": [
          "Wikipedia contributors"
        ],
        "source": "Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Quantum_computing"
      },
      {
        "id": 2,
        "title": "Timeline of quantum computing and communication",
        "authors": [
          "Wikipedia contributors"
        ],
        "source": "Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication"
      },
      {
        "id": 3,
        "title": "Superconducting quantum computing",
        "authors": [
          "Wikipedia contributors"
        ],
        "source": "Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Superconducting_quantum_computing"
      },
      {
        "id": 4,
        "title": "The Rise of Quantum Internet Computing",
        "authors": [
          "Seng W. Loke"
        ],
        "source": "arXiv",
        "url": "https://arxiv.org/abs/2208.00733"
      },
      {
        "id": 5,
        "title": "Unconventional Quantum Computing Devices",
        "authors": [
          "Seth Lloyd"
        ],
        "source": "arXiv",
        "url": "https://arxiv.org/abs/quant-ph/0003151"
      },
      {
        "id": 6,
        "title": "Geometrical perspective on quantum states and quantum computation",
        "authors": [
          "Zeqian Chen"
        ],
        "source": "arXiv",
        "url": "https://arxiv.org/abs/1311.4939"
      }
    ],
    "topics": [
      {
        "id": "t1",
        "title": "Foundations of quantum information and computation",
        "summary_points": [
          "Quantum computation uses quantum mechanical phenomena—superposition, entanglement and probabilistic measurement outcomes—to process information in ways not available to classical deterministic machines (Refs: 1).",
          "The fundamental unit is the qubit, mathematically a two-dimensional complex vector |ψ⟩ = α|0⟩ + β|1⟩ with complex amplitudes α, β and Born‑rule probabilities |α|^2, |β|^2 upon measurement (Ref: 1).",
          "Quantum states are manipulated by unitary operations (quantum gates) and composed into circuits; interference of amplitudes is engineered to amplify desired outcomes (Ref: 1).",
          "Formal descriptions use linear algebra: Hilbert spaces for states, matrices for gates, and tensor products for multi-qubit systems; quantum programming composes these operations subject to physical implementability (Ref: 1).",
          "Quantum computation can be viewed as sampling from quantum evolutions over exponentially large configuration spaces, which explains both classical simulation difficulty and potential quantum speedups (Ref: 1)."
        ],
        "subtopics": [
          {
            "id": "t1.1",
            "title": "Qubit formalism and measurement",
            "summary_points": [
              "A qubit's basis states |0⟩ and |1⟩ span a two-dimensional vector space; any normalized linear combination is a valid state and measurement in the computational basis yields classical bits probabilistically via the Born rule (Ref: 1).",
              "Probability amplitudes are complex and can interfere constructively or destructively; negative/phase amplitudes enable algorithmic interference patterns exploited in algorithms (Ref: 1)."
            ],
            "references": [
              1
            ]
          },
          {
            "id": "t1.2",
            "title": "Quantum gates, circuits and models",
            "summary_points": [
              "Quantum gates are unitary transformations acting on single or few qubits; universal gate sets allow construction of arbitrary unitaries and form the basis of the circuit model of quantum computation (Ref: 1).",
              "Alternative but equivalent formulations include the quantum Turing machine and other models; fault-tolerant constructions and error-correcting codes enable scaling in principle (Refs: 1, 6)."
            ],
            "references": [
              1,
              6
            ]
          },
          {
            "id": "t1.3",
            "title": "Algorithms and complexity",
            "summary_points": [
              "Quantum algorithms exploit superposition and interference to reduce query/compute complexity for some tasks: notable examples are Deutsch–Jozsa, Simon's, Shor's factoring (exponential speedup for structured number‑theoretic problems), and Grover's unstructured search (quadratic speedup) (Refs: 1, 2).",
              "Quantum computers can efficiently simulate many quantum systems (Feynman/Lloyd idea), removing exponential classical overhead for those simulations (Refs: 1, 2)."
            ],
            "references": [
              1,
              2
            ]
          }
        ],
        "references": [
          1
        ]
      },
      {
        "id": "t2",
        "title": "Historical milestones and timeline",
        "summary_points": [
          "Quantum computing emerged from intersecting developments in quantum mechanics and computer science across the 20th century; foundational theoretical contributions began in the 1980s (Benioff, Feynman, Manin) establishing the quantum Turing machine and the idea of quantum simulation (Refs: 2, 1).",
          "Key theoretical advances in the 1980s–1990s: quantum cryptography (Bennett–Brassard), Deutsch's universal quantum computer and early algorithms, Simon's oracle separation, Shor's algorithm (1994) which catalyzed large-scale interest, and Grover's algorithm (1996) demonstrating broad potential speedups (Refs: 2, 1).",
          "Experimental milestones include small-scale implementations (NMR, trapped ions, superconducting qubits) in the 1990s and 2000s; the 2019 Google announcement of quantum supremacy (54/53 qubits) exemplifies recent progress and debate about practical thresholds (Refs: 2, 1)."
        ],
        "subtopics": [
          {
            "id": "t2.1",
            "title": "Foundational theoretical developments (1960s–1990s)",
            "summary_points": [
              "Early information-theoretic and theoretical groundwork included conjugate coding and Holevo bound; the no-cloning theorem and reversible computation laid constraints and opportunities for quantum information processing (Ref: 2).",
              "Benioff (1980) formalized quantum mechanical Turing machines; Feynman (1982) and Manin proposed quantum simulation as a central application motivating quantum hardware (Ref: 2)."
            ],
            "references": [
              2
            ]
          },
          {
            "id": "t2.2",
            "title": "Algorithms that changed the field",
            "summary_points": [
              "Deutsch–Jozsa introduced oracle separations and deterministic quantum advantage for specific promise problems; Simon's problem demonstrated exponential oracle separations that seeded Shor's approach; Shor’s algorithm for factoring and discrete logs made cryptographic implications explicit (Refs: 2, 1).",
              "Grover provided a widely applicable quadratic speedup for unstructured search, relevant across many problem domains (Ref: 2)."
            ],
            "references": [
              2,
              1
            ]
          },
          {
            "id": "t2.3",
            "title": "Experimental progress and claims of quantum advantage",
            "summary_points": [
              "Progressive scaling from few-qubit demonstrations (2–7 qubit NMR and trapped-ion experiments in late 1990s) to multi-qubit architectures (superconducting arrays, ion traps) has been accompanied by steady improvements in coherence and gate fidelity (Refs: 2, 3).",
              "Google's 2019 quantum supremacy claim using a 53-qubit superconducting processor sparked discussion on benchmarking and classical simulation capabilities; IBM contested runtime estimates, highlighting benchmarking nuance (Refs: 1, 2, 3)."
            ],
            "references": [
              2,
              1,
              3
            ]
          }
        ],
        "references": [
          2,
          1
        ]
      },
      {
        "id": "t3",
        "title": "Physical implementations and superconducting qubits",
        "summary_points": [
          "Multiple physical platforms exist: superconducting circuits, trapped ions, photonics, NMR, quantum dots, NV centers and more; each trades off coherence times, gate speed, connectivity and manufacturability (Refs: 1, 2, 3).",
          "Superconducting quantum computing uses lithographically fabricated circuits that behave as macroscopic quantum systems at millikelvin temperatures; Josephson junctions provide nonlinear inductance needed to form anharmonic energy spectra to isolate two levels as qubit states (Ref: 3).",
          "Manufacturing leverages integrated-circuit techniques (lithography, deposition, etching, controlled oxidation) and cryogenic operation (dilution refrigerators < 15 mK); industry players (Google, IBM, Rigetti, Intel, etc.) focus on superconducting QPUs (Ref: 3)."
        ],
        "subtopics": [
          {
            "id": "t3.1",
            "title": "Superconducting qubit technologies",
            "summary_points": [
              "Superconducting qubit archetypes include charge, flux and phase qubits and hybrids such as transmon, Xmon and fluxonium; designs tune Josephson energy vs charging energy to optimize coherence and noise sensitivity (Ref: 3).",
              "Josephson junctions create the essential nonlinearity so that energy level spacings are anharmonic, enabling selective two-level addressing; circuits are described quantum mechanically via Hamiltonians derived from Lagrangian formulations of circuit elements (Ref: 3).",
              "Typical superconducting devices operate at microwave frequencies, with qubit frequencies, control/readout electronics, and require careful isolation to mitigate decoherence and crosstalk (Ref: 3)."
            ],
            "references": [
              3
            ]
          },
          {
            "id": "t3.2",
            "title": "Other experimental platforms",
            "summary_points": [
              "Trapped ions offer long coherence and high-fidelity gates using laser-mediated interactions but face scaling/connectivity engineering challenges; photonic approaches are promising for communication and certain computing models (Refs: 1, 2).",
              "NMR and bulk ensemble approaches provided early proof-of-principle demonstrations but suffer from mixed-state limitations and scaling issues; silicon donor qubits, quantum dots and NV centers offer alternative tradeoffs (Refs: 2, 1)."
            ],
            "references": [
              2,
              1
            ]
          }
        ],
        "references": [
          3,
          1
        ]
      },
      {
        "id": "t4",
        "title": "Noise, decoherence, error correction and topological approaches",
        "summary_points": [
          "Decoherence—loss of quantum coherence due to environmental coupling—introduces noise and limits practical computation; engineering long coherence times and low error rates is central to scalable hardware (Refs: 1, 3).",
          "Quantum error correction (Shor, Steane, surface codes, etc.) and fault-tolerant schemes establish thresholds under which arbitrarily long computations become possible in principle, given gate error rates below a threshold (Refs: 1, 2).",
          "Topological quantum computation (Kitaev, anyons) exploits nonlocal, topologically protected degrees of freedom to suppress local noise and provide intrinsic error robustness; experimental realization remains an active research area (Refs: 2, 5, 6)."
        ],
        "subtopics": [
          {
            "id": "t4.1",
            "title": "Quantum error correction and fault tolerance",
            "summary_points": [
              "Error-correcting codes encode logical qubits into entangled multi-qubit states and use syndrome measurements to detect/correct errors without measuring encoded logical information; concatenation and surface codes are leading practical approaches (Refs: 1, 2).",
              "Threshold theorems show that if per-gate error rates are below certain values (dependent on code and architecture), logical error rates can be suppressed arbitrarily by scaling overhead (Refs: 1)."
            ],
            "references": [
              1,
              2
            ]
          },
          {
            "id": "t4.2",
            "title": "Topological protection and anyons",
            "summary_points": [
              "Topological quantum computation encodes information in nonlocal topological degrees of freedom (e.g., non-Abelian anyons) so that local perturbations have limited effect; braiding exchanges implement gates (Refs: 5, 2).",
              "Anyons and related topological systems promise intrinsic error resistance but require specialized platforms (e.g., certain 2D condensed-matter systems) and remain experimentally challenging (Refs: 5)."
            ],
            "references": [
              5,
              2
            ]
          }
        ],
        "references": [
          1,
          3,
          5
        ]
      },
      {
        "id": "t5",
        "title": "Distributed quantum computing and the Quantum Internet",
        "summary_points": [
          "Quantum Internet computing refers to distributed quantum computation across networked QPUs connected by entanglement, enabling non-local gates, distributed algorithms, delegated computing, and other applications that require Internet-scale entanglement distribution (Ref: 4).",
          "Key quantum Internet primitives include entanglement distribution, entanglement swapping, quantum repeaters, distillation and routing; error correction and high-fidelity entanglement generation are central technical challenges (Ref: 4).",
          "Quantum cloud services, delegating quantum computations, blind/verified quantum computing and partitioning circuits across QPUs are active research topics; tradeoffs include entanglement consumption, latency and verification overhead (Ref: 4)."
        ],
        "subtopics": [
          {
            "id": "t5.1",
            "title": "Quantum Internet primitives and infrastructure",
            "summary_points": [
              "The quantum Internet aims to enable robust teleportation and long-distance entanglement via fiber, satellites and repeater protocols; entanglement fidelity and repeater rates determine usability for distributed computing (Ref: 4).",
              "Entanglement swapping and distillation are used to extend entanglement over long distances; research focuses on scaling these techniques and defining standards for interoperability (Ref: 4)."
            ],
            "references": [
              4
            ]
          },
          {
            "id": "t5.2",
            "title": "Distributed, delegated and blind quantum computing",
            "summary_points": [
              "Delegated quantum computing allows clients (classical or near-classical) to outsource quantum computation to remote quantum servers; blind quantum computing hides inputs from the server using techniques such as quantum one-time pads (Ref: 4).",
              "Verification protocols embed tests to ensure server honesty; partitioning circuits across multiple QPUs may reduce hardware demands but increases entanglement/resource requirements (Ref: 4)."
            ],
            "references": [
              4
            ]
          },
          {
            "id": "t5.3",
            "title": "Quantum Internet computing use cases and outlook",
            "summary_points": [
              "Potential applications include distributed cryptographic protocols (QKD, voting), non-local algorithmic primitives, sensing/positioning, and the vision of a quantum Internet of Things (quantum‑enabled edge/fog devices), though practical deployment faces significant technical hurdles (Ref: 4).",
              "Linking many QPUs could in principle create larger effective quantum machines, but entanglement generation rate and fidelity are critical bottlenecks for distributed workloads (Ref: 4)."
            ],
            "references": [
              4
            ]
          }
        ],
        "references": [
          4
        ]
      },
      {
        "id": "t6",
        "title": "Unconventional models and geometric/formal perspectives",
        "summary_points": [
          "Beyond mainstream platforms, unconventional proposals include fermionic quantum computers, bosonic/cavity-based systems, anyon-based topological computers, and speculative models leveraging nonlinear quantum mechanics; each offers different theoretical advantages and practical challenges (Ref: 5).",
          "A geometric/gauge formulation represents quantum states as noncommutative connections and unitary operations as gauge transforms—this viewpoint is mathematically equivalent to the circuit model and suggests alternative implementation and conceptual approaches (Ref: 6).",
          "Unconventional models can, in principle, offer algorithmic or simulation speedups for specific problems (e.g., fermionic simulators for lattice fermion problems) but face realizability and decoherence constraints (Ref: 5)."
        ],
        "subtopics": [
          {
            "id": "t6.1",
            "title": "Fermionic, bosonic and anyonic computing",
            "summary_points": [
              "Fermionic quantum computers encode information in occupation states of fermions; they can be more natural for simulating fermionic many-body systems and may bypass certain classical overheads in mapping antisymmetry (Ref: 5).",
              "Anyonic (topological) models use non-Abelian exchange statistics to implement gates via braiding, providing inherent protection against local noise and a route to fault tolerance (Refs: 5, 2).",
              "Bosonic approaches (photons, phonons, Bose-Einstein condensates) are powerful for communication and specific computational primitives, though naive many-particle bosonic states do not by themselves enlarge accessible Hilbert space relative to single-particle encodings (Ref: 5)."
            ],
            "references": [
              5,
              2
            ]
          },
          {
            "id": "t6.2",
            "title": "Speculative physics and nonlinear quantum mechanics",
            "summary_points": [
              "If fundamental physics allowed nonlinear quantum mechanics or novel quantum phenomena, new computational powers could arise; such ideas remain speculative and unverified but motivate considering broader physical constraints on computability (Ref: 5).",
              "Practical viability of speculative models depends on coherence, controllability and whether the required nonlinearity or exotic statistics exist at usable scales (Ref: 5)."
            ],
            "references": [
              5
            ]
          },
          {
            "id": "t6.3",
            "title": "Geometric (gauge) formulation of quantum computation",
            "summary_points": [
              "Representing quantum states as noncommutative connections and unitary gates as gauge transformations (Connes' noncommutative geometry) yields a computational model equivalent to circuits but with different conceptual primitives; gauge states and transforms can reproduce circuit probabilities and algorithms (Ref: 6).",
              "This geometric viewpoint can recast algorithms (Deutsch–Jozsa illustrated) and suggests alternative ways to think about implementation and possibly operations that may be easier to implement in specific physical contexts (Ref: 6)."
            ],
            "references": [
              6
            ]
          }
        ],
        "references": [
          5,
          6
        ]
      }
    ],
    "abstract": "This structured summary synthesizes foundational theory, historical development, physical implementations, distributed-computing perspectives and unconventional models for quantum computing based on the provided documents (Wikipedia entries and arXiv papers). It outlines the mathematical formalism of qubits, amplitudes, unitary gates, and the circuit model; recounts milestone theoretical advances (Benioff, Feynman, Deutsch, Simon, Shor, Grover) and experimental progress (NMR, trapped ions, superconducting processors, and the 2019 quantum‑supremacy claim). Hardware discussions focus on superconducting qubits—Josephson junctions, anharmonic circuits, fabrication and cryogenic operation—while comparing to other platforms (ions, photonics, NV centers). Central engineering challenges—decoherence, noise, and error correction—are explained alongside fault tolerance and topological approaches (anyons). The report captures the emerging area of quantum Internet computing: entanglement distribution, repeaters, delegated and blind quantum computation, and partitioned distributed quantum workloads. Finally, unconventional proposals (fermionic, bosonic, anyonic, speculative nonlinear quantum mechanics) and a geometric/gauge reformulation of quantum computation are summarized, noting where they promise advantages (e.g., natural fermion simulation or intrinsic topological robustness) and where practical barriers persist. The synthesis highlights both the theoretical promise of quantum speedups for specific problems and the substantial physical, engineering and algorithmic work still required to realize scalable, useful quantum computation.",
    "conclusion": "Quantum computing unites deep theoretical insights with diverse and rapidly evolving experimental platforms. The discipline has produced provable algorithmic advantages for specific problems and practical progress toward scalable hardware, yet faces substantive challenges in coherence, error correction, and system integration. Distributed quantum computing and the quantum Internet extend the landscape, enabling new paradigms such as delegated, blind, and networked quantum computation, but require advances in entanglement generation and routing. Unconventional models and alternative formalisms broaden conceptual tools and may offer targeted advantages, while geometric and topological approaches point to strategies for robustness. Continued progress will depend on coordinated advances in algorithms, architectures, device engineering, and quantum networking to transition from specialized demonstrations to practically useful, scalable quantum systems."
  },
  "report_parts": [
    "## Foundations of quantum information and computation\n\nQuantum computation harnesses characteristic quantum-mechanical phenomena—superposition, entanglement and inherently probabilistic measurement outcomes—to process information in ways that are not available to classical deterministic machines [1]. The field formalizes information carriers and operations within the language of linear algebra: quantum states reside in Hilbert spaces, gates are represented by matrices, and multi-qubit systems are described by tensor products of single-qubit spaces [1]. Computation proceeds by preparing quantum states, applying sequences of unitary transformations, and performing measurements that produce classical outcomes according to probabilistic rules; through these steps the interference of probability amplitudes can be engineered to amplify desired results and suppress undesired ones [1].\n\nThe elementary information unit is the qubit, mathematically described as a normalized vector in a two-dimensional complex vector space, typically written |ψ⟩ = α|0⟩ + β|1⟩ with complex amplitudes α and β and measurement probabilities given by the Born rule as |α|^2 and |β|^2 [1]. Practical and theoretical descriptions of quantum computation often view quantum devices as sampling from quantum evolutions over configuration spaces that grow exponentially with system size, a perspective that both explains the difficulty of classical simulation and highlights the potential for quantum speedups for certain tasks [1]. Quantum programming and the design of circuits therefore must account for both the algebraic composition of operations and the constraints of physical implementability inherent to real quantum hardware [1].\n\n### Qubit formalism and measurement\n\nA qubit's computational-basis states |0⟩ and |1⟩ span a two-dimensional complex vector space, and any normalized linear combination of these basis vectors constitutes a valid pure state for the system [1]. Measurement in the computational basis converts the quantum state into classical information: the outcome is a classical bit sampled probabilistically, with the likelihoods determined by the Born rule as the squared magnitudes of the state's complex amplitudes [1]. These probabilistic measurement outcomes are a fundamental departure from deterministic classical bits, and they underlie both the power and the limitations of quantum information processing [1].\n\nThe complex probability amplitudes that compose a qubit state can interfere when states are combined and transformed; constructive and destructive interference of these amplitudes is a core mechanism by which quantum algorithms manipulate outcome probabilities [1]. In particular, phases and sign relationships among amplitudes—features with no classical analog—enable algorithmic interference patterns that are deliberately engineered to increase the probability of correct or useful outcomes in quantum procedures [1].\n\n### Quantum gates, circuits and models\n\nQuantum gates are physical realizations of unitary transformations acting on single qubits or small collections of qubits, and they form the primitives from which quantum circuits are built [1]. Within the circuit model of quantum computation, sequences of such gates are composed to implement more complex unitary evolutions; universal gate sets exist that, in principle, allow the construction of arbitrary unitaries on a given register of qubits, establishing the circuit model as a general framework for quantum computation [1]. The engineering of circuits therefore focuses on composing these elementary unitaries while accounting for constraints of implementability and error.\n\nAlternative but formally equivalent computational formulations exist alongside the circuit model, such as the quantum Turing machine, which provide complementary perspectives on quantum computation and complexity [1]. Considerations of scale and reliability lead to theories of fault-tolerant constructions and quantum error-correcting codes, which show that, in principle, quantum computation can be made robust against certain classes of noise and errors and thereby scaled to larger devices [1, 6].\n\n### Algorithms and complexity\n\nQuantum algorithms exploit superposition and interference to reduce query and computational complexity for particular classes of problems, with several canonical examples illustrating different types of speedup [1, 2]. Deutsch–Jozsa and Simon's algorithms demonstrate exponential separations in query complexity for specially structured problems, Shor's algorithm provides an exponential-speedup approach to factoring in the presence of number-theoretic structure, and Grover's algorithm yields a quadratic speedup for unstructured search problems [1, 2]. These examples collectively highlight that quantum advantages are problem-dependent and tied to the ability to exploit structure via quantum interference.\n\nA central motivation for quantum computation is the efficient simulation of quantum systems: as originally proposed by Feynman and formalized by subsequent work, quantum computers can simulate the dynamics of many quantum systems without the exponential overhead required by classical simulation methods, thereby providing an avenue to bypass classical computational intractability for such tasks [1, 2]. This capability underpins much of the theoretical interest in quantum information science and informs the development of algorithms and hardware aimed at quantum simulation.",
    "## Historical milestones and timeline\n\nQuantum computing is the product of long-standing intersections between quantum mechanics and theoretical computer science that unfolded across the twentieth century, with foundational theoretical contributions coalescing in the 1980s. Early formalizations of quantum computation and the articulation of quantum simulation as a central application emerged in this period, establishing the conceptual framework for subsequent algorithmic and experimental work [2, 1]. These theoretical advances reframed computational limits by introducing fundamentally quantum resources—superposition, entanglement, and unitary evolution—into models of computation and information processing [2, 1].\n\nThe period from the 1980s through the 1990s saw a sequence of pivotal algorithmic and cryptographic developments that transformed the field from a theoretical curiosity into an area of broad scientific and technological interest. Landmark results included the introduction of quantum cryptographic protocols, early formulations of universal quantum computation and oracle separations, and the discovery of algorithms that either demonstrated exponential separations in query models or posed concrete threats to classical cryptographic assumptions [2, 1]. These theoretical milestones, in turn, motivated experimental efforts to realize quantum systems capable of implementing and testing quantum algorithms.\n\nExperimental progress has paralleled theoretical development, progressing from proof-of-principle demonstrations to architectures with steadily increasing qubit counts and improved coherence and gate fidelity. Small-scale implementations using platforms such as nuclear magnetic resonance (NMR), trapped ions, and superconducting qubits appeared in the late 1990s and 2000s, laying the groundwork for larger multi-qubit devices and intensive engineering efforts [2, 3]. High-profile demonstrations in recent years, notably a 2019 announcement asserting a form of quantum supremacy using a multi-qubit superconducting processor, have provoked detailed discussion regarding benchmarking, practical thresholds for quantum advantage, and the capacity of classical simulators to contest such claims [2, 1].\n\n### Foundational theoretical developments (1960s–1990s)\n\nThe theoretical foundations of quantum information were built on early information-theoretic results that delineated the capabilities and limitations of quantum systems for encoding and transmitting information. Concepts such as conjugate coding and bounds on accessible information provided an information-theoretic context, while the no-cloning theorem and the recognition of reversible computation in quantum mechanics established both constraints and new opportunities for processing quantum information [2]. These foundational results framed what could be achieved with quantum systems and what fundamental barriers would need to be addressed in algorithm and hardware design [2].\n\nFormal models and motivating applications emerged in the 1980s: Benioff provided a formalization of quantum mechanical Turing machines, thereby connecting quantum dynamics directly to models of computation, and Feynman and Manin independently emphasized quantum simulation as a primary motivation for building quantum hardware capable of efficiently emulating quantum systems that resist classical simulation [2]. Together, these contributions supplied both the rigorous computational model and the practical impetus—simulation of quantum phenomena—that guided early research agendas and justified investment in quantum architectures [2].\n\n### Algorithms that changed the field\n\nA sequence of algorithmic discoveries in the 1980s and 1990s established quantum computation as a domain with qualitatively new algorithmic phenomena. The Deutsch–Jozsa algorithm demonstrated deterministic quantum advantage for specific promise problems and introduced methods for leveraging superposition in oracle settings, while Simon’s problem provided an exponential separation in the oracle model that later informed the development of more practically oriented algorithms [2, 1]. These oracle-based separations illustrated the potential for quantum algorithms to outperform classical counterparts in well-defined models and seeded techniques that would be refined in subsequent work [2, 1].\n\nThe introduction of Shor’s algorithm for integer factoring and discrete logarithms made explicit the concrete cryptographic implications of quantum computation by showing that widely used public-key schemes could be broken in polynomial time on a sufficiently capable quantum computer, a result that dramatically broadened interest in the field [2, 1]. Complementing these exponential-separation results, Grover’s algorithm provided a broadly applicable quadratic speedup for unstructured search problems, demonstrating that quantum advantage could extend beyond contrived oracle settings into a wide array of problem domains where square-root improvements are significant [2]. Collectively, these algorithms reshaped research priorities by linking theoretical possibility to practical impact.\n\n### Experimental progress and claims of quantum advantage\n\nExperimental efforts have advanced from early few-qubit demonstrations to multi-qubit systems across several physical platforms, accompanied by continual improvements in coherence times and gate fidelities. Initial demonstrations in the late 1990s employed small ensembles and systems—often in the range of a few qubits using NMR and trapped-ion techniques—while later work scaled to larger superconducting and trapped-ion arrays, reflecting parallel progress in control, fabrication, and error mitigation [2, 3]. These iterative advances in hardware capability have been essential for moving algorithmic concepts toward empirical tests and benchmarks [2, 3].\n\nHigh-profile milestones in the late 2010s precipitated intense scrutiny of what constitutes practical quantum advantage. A 2019 announcement claiming quantum supremacy using a 53-qubit superconducting processor exemplified both the rapid scaling of certain architectures and the ensuing debates over benchmarking methodology and the true boundary between quantum and classical computational capability [1, 2]. In particular, contemporaneous responses from classical-computing proponents challenged some runtime estimates and underscored the subtleties involved in comparing specialized quantum tasks with optimized classical simulation strategies, highlighting the need for careful, application-specific benchmarks and transparent performance claims [1, 2, 3].",
    "## Physical implementations and superconducting qubits\n\nA diversity of physical platforms has been explored for realizing quantum information processors, including superconducting circuits, trapped ions, photonic systems, nuclear magnetic resonance (NMR), quantum dots, silicon donor systems, and nitrogen-vacancy (NV) centers. Each platform presents distinct trade-offs among coherence times, gate speed, native connectivity and practical manufacturability, and these trade-offs influence platform selection for particular algorithmic or application domains [1,2,3]. The variation in these characteristics has shaped research agendas and the comparative evaluation of architectures for scaling and error mitigation [1,2,3].\n\nSuperconducting quantum computing implements qubits as lithographically fabricated electrical circuits that operate as macroscopic quantum systems when cooled to millikelvin temperatures; Josephson junctions supply the nonlinear inductance that produces an anharmonic energy spectrum, allowing two levels to be isolated and used as a qubit degree of freedom [3]. Typical superconducting devices operate in the microwave frequency range, with qubit transition frequencies, control signals and readout electronics designed around microwave engineering considerations [3].\n\nThe fabrication and operation of superconducting devices leverage standard integrated-circuit processing techniques — lithography, thin-film deposition, etching and controlled oxidation — and devices are mounted in dilution refrigerators maintained below roughly 15 mK to suppress thermal excitations [3]. Substantial industrial and academic efforts have concentrated on superconducting quantum processing units (QPUs), with several companies and research groups emphasizing superconducting platforms as a primary route toward scalable, integrated quantum hardware [3].\n\n### Superconducting qubit technologies\n\nSuperconducting qubit designs encompass several archetypes, historically including charge, flux and phase qubits, and more recent optimized variants such as the transmon, Xmon and fluxonium. These variants differ principally in how they balance Josephson energy against charging energy to reduce sensitivity to environmental noise while preserving sufficient anharmonicity for controllable qubit transitions; tuning these energy scales is a central engineering lever for improving coherence and gate performance [3]. The progression from early archetypes to modern designs reflects ongoing trade-offs among coherence time, control simplicity and fabrication tolerance [3].\n\nAt the circuit-theoretical level, Josephson junctions provide the essential nonlinearity that renders the energy spectrum anharmonic and enables selective addressing of the lowest two energy levels as the computational basis. Superconducting circuits are modeled quantum mechanically by deriving Hamiltonians from Lagrangian formulations of the constituent capacitive, inductive and Josephson elements; these models guide device design, control strategies and analysis of decoherence mechanisms. Because superconducting qubits operate at microwave frequencies and are sensitive to stray coupling and thermal noise, careful isolation, packaging and mitigation of crosstalk are required in system layout and control electronics [3].\n\n### Other experimental platforms\n\nTrapped-ion systems realize qubits with long intrinsic coherence and enable high-fidelity quantum gates through laser-mediated interactions, making them attractive for demonstrations of precise operations; however, engineering challenges remain in scaling trap arrays and in designing connectivity suitable for large-scale processors [1,2]. Photonic approaches occupy a complementary role, offering natural advantages for quantum communication and for computing models that exploit flying qubits or linear-optical operations, and they are considered promising in domains where those attributes are primary requirements [1,2].\n\nEarly experimental demonstrations of quantum information processing employed NMR and bulk ensemble techniques to establish key principles, but these approaches are constrained by mixed-state initialization and limited scalability. Solid-state alternatives such as silicon donor qubits, quantum dots and NV centers in diamond present different trade-offs among coherence, control and manufacturability, and they are explored as alternative routes to quantum hardware that may favor different engineering and integration strategies depending on application needs [2,1].",
    "## Noise, decoherence, error correction and topological approaches\n\nDecoherence, the loss of quantum coherence through unavoidable coupling to the environment, is the principal source of noise that limits the fidelity and practical runtimes of quantum computations; accordingly, engineering long coherence times and achieving low physical error rates are central objectives for scalable quantum hardware [1,3]. This physical constraint motivates both the development of error suppression techniques at the device level and the deployment of higher-level error-correction and fault-tolerant protocols that can manage residual noise while preserving encoded quantum information [1,3]. \n\nQuantum error correction and fault-tolerant architectures provide a conceptual route past the limits set by decoherence: by encoding logical qubits into entangled states of many physical qubits and applying designed recovery operations, these schemes can detect and correct errors without directly measuring the logical information, thereby enabling sustained computation despite ongoing noise [1]. The combination of practical coding strategies with rigorous threshold theorems implies that, in principle, arbitrarily long computations are possible provided the underlying gate and memory error rates fall below certain architecture- and code-dependent thresholds; below such thresholds, logical error rates can be suppressed to arbitrarily low values by increasing resource overheads such as qubit counts and operation counts [1].\n\nTopological approaches seek a complementary path by encoding quantum information in nonlocal, topologically protected degrees of freedom so that local perturbations have only limited effect on the encoded state. In such schemes—most prominently those based on non-Abelian anyons—logical operations are implemented by braiding exchanges of topological quasiparticles, and the nonlocal nature of the encoding confers intrinsic robustness against many local error processes [5]. While topological protection offers the prospect of substantially reduced error-correction overhead, realizing the required topological phases and manipulating anyonic excitations remains experimentally challenging and is an active area of research [5].\n\n### Quantum error correction and fault tolerance\n\nQuantum error-correcting codes work by mapping a logical qubit into an entangled multi-qubit subspace and using syndrome measurements to reveal which local errors have occurred without collapsing the logical state; corrective operations inferred from syndrome outcomes restore the code space while preserving the encoded information [1]. Practical approaches discussed in the literature include hierarchical concatenation schemes and two-dimensional surface codes, which differ in resource scaling, locality constraints, and operational primitives but share the same goal of turning many imperfect physical components into a reliably operating logical qubit [1]. \n\nTheoretical threshold results formalize the conditions under which fault-tolerant quantum computation becomes scalable: if the physical error rates per gate, preparation, and measurement lie below a threshold value determined by the chosen code and architecture, then logical error rates can be reduced arbitrarily by increasing encoding size and employing repeated fault-tolerant operations, at the cost of increased overhead in qubits and gates [1]. These theorems guide experimental targets for physical error rates and motivate the development of codes and architectures optimized for realistic noise models and hardware constraints [1].\n\n### Topological protection and anyons\n\nTopological quantum computation encodes information in global, nonlocal features of a quantum system—commonly associated with non-Abelian anyonic excitations—so that local perturbations cannot readily distinguish or corrupt the logical degrees of freedom; logical gates are effected by braiding these anyons, and the operation depends only on the global braid topology rather than microscopic details of the trajectory [5]. This nonlocal encoding and braid-based gate set provide an intrinsic form of error suppression that can, in principle, reduce the dependence on active error-correction cycles.\n\nDespite its theoretical appeal, realizing topological quantum computing requires specialized physical platforms that support the necessary two-dimensional topological phases and allow controlled creation, manipulation, and measurement of anyonic quasiparticles; these requirements make experimental implementation demanding, and the field remains an active area of experimental and theoretical investigation [5].",
    "## Distributed quantum computing and the Quantum Internet\n\nQuantum Internet computing refers to distributed quantum computation performed across networked quantum processing units (QPUs) that are connected by entanglement, enabling non-local gates, distributed algorithms, delegated computing, and other applications that require Internet-scale entanglement distribution [4]. The paradigm treats entanglement as the fundamental resource that links physically separated quantum processors, allowing computation and communication primitives that have no direct classical analog [4]. Realizing these capabilities at scale therefore depends on the ability to generate, maintain, and route high-fidelity entanglement between distant nodes of a network [4].\n\nCore technical primitives for the quantum Internet include entanglement distribution, entanglement swapping, quantum repeaters, entanglement distillation, and routing mechanisms that manage the network-level placement and use of entangled links [4]. Error correction and the generation of high-fidelity entanglement are central technical challenges because they determine whether non-local quantum operations and distributed algorithms can be executed reliably across the network [4]. As a result, research emphasizes both the physical-layer techniques for producing long-lived entanglement and the protocol-layer mechanisms (such as repeaters and distillation) that extend and improve entanglement over long distances [4].\n\nConcurrently, a range of software- and service-level topics are active research areas for quantum Internet computing. Quantum cloud services and delegated quantum computation explore how classical or near-classical clients can outsource quantum tasks to remote servers, while blind and verified quantum computing aim to protect client data and certify correctness when computation is performed off-site [4]. Partitioning quantum circuits across multiple QPUs offers a route to reduce individual hardware demands by leveraging networked resources, but such partitioning introduces tradeoffs in entanglement consumption, added latency, and verification overhead that must be carefully managed in protocol and resource-design choices [4].\n\n### Quantum Internet primitives and infrastructure\n\nThe envisioned quantum Internet infrastructure seeks to enable robust quantum teleportation and long-distance entanglement distribution using combinations of fiber links, satellite channels, and repeater-based protocols, with the choice of medium and protocol affecting achievable distance, rate, and fidelity [4]. Entanglement fidelity and the effective rates provided by repeater chains or alternative link technologies directly determine the practical usability of the network for distributed computation and communication tasks, since both low fidelity and low rate can preclude reliable non-local operations [4].\n\nTo extend entanglement over long distances, networks rely on entanglement swapping and entanglement distillation as fundamental procedures: swapping concatenates shorter entangled links into longer ones, while distillation increases fidelity at the cost of consuming multiple noisy links [4]. Current research focuses on scaling these techniques to network scales and on defining standards and interoperability requirements so that heterogeneous physical links and repeater implementations can interoperate within a larger Internet-like framework [4].\n\n### Distributed, delegated and blind quantum computing\n\nDelegated quantum computing enables clients—potentially classical or only weakly quantum-capable—to outsource quantum computations to remote quantum servers, providing a means to access quantum resources without local full-scale quantum hardware [4]. Blind quantum computing is a class of delegation techniques that conceals client inputs and computation details from the server, for example through the use of quantum one-time pads or related masking methods that prevent the server from learning sensitive information while performing the computation [4].\n\nVerification protocols are developed to detect or deter dishonest behavior by servers by embedding tests or trap computations that reveal deviations from the prescribed computation, thereby providing a degree of assurance to clients about correctness [4]. Partitioning quantum circuits across multiple QPUs is a promising strategy to lower per-node hardware requirements and to exploit distributed resources, but it increases demands on entanglement availability and other network resources, producing tradeoffs between hardware scalability and entanglement/resource consumption that must be evaluated in system designs [4].\n\n### Quantum Internet computing use cases and outlook\n\nPotential applications of the quantum Internet span distributed cryptographic protocols such as quantum key distribution and secure voting, non-local algorithmic primitives that exploit entanglement between distant processors, enhanced sensing and positioning through distributed quantum measurements, and the broader vision of a quantum Internet of Things in which quantum-enabled edge or fog devices participate in networked quantum tasks [4]. While these applications motivate the development of networked quantum systems, practical deployment is constrained by significant technical hurdles in generating, distributing, and maintaining entanglement at Internet scales [4].\n\nIn principle, linking many QPUs via entanglement could create larger effective quantum machines by combining quantum memory and processing capacity across nodes, offering a path to scale beyond isolated devices [4]. In practice, however, the entanglement generation rate and the fidelity of produced entangled links are critical bottlenecks for distributed workloads; insufficient rates or poor fidelity limit the types of algorithms and protocols that can be executed reliably on a distributed quantum platform [4].",
    "## Unconventional models and geometric/formal perspectives\n\nBeyond mainstream quantum computing platforms, several unconventional proposals have been explored, including fermionic quantum computers, bosonic or cavity-based systems, anyon-based topological computers, and speculative models that leverage nonlinear quantum mechanics; each of these proposals offers distinct theoretical advantages as well as practical challenges [5]. These models differ in their native degrees of freedom, symmetry properties, and error sensitivities, and consequently suggest different mappings from problems to physical hardware as well as different engineering obstacles to realize coherent control [5]. A separate but related line of thought recasts the formal structure of quantum computation in geometric and gauge-theoretic language, representing states and operations with noncommutative geometric objects and gauge transformations, an approach that is mathematically equivalent to the circuit model while providing alternative conceptual and implementation perspectives [6]. Collectively, these unconventional and geometric/formal perspectives indicate both opportunities for problem-specific algorithmic or simulation speedups and significant constraints arising from realizability and decoherence in physical systems [5].\n\n### Fermionic, bosonic and anyonic computing\n\nFermionic quantum computers encode information in occupation states of fermionic modes, making the representation of antisymmetric many-body fermion states more natural and potentially reducing classical overheads associated with mapping fermionic antisymmetry into qubit registers for simulation tasks [5]. This native encoding can, in principle, yield more direct algorithms for lattice fermion problems and related many-body simulations, though the practical benefits depend on the ability to prepare, control, and read out fermionic occupations with sufficient fidelity [5].\n\nAnyonic or topological quantum computing models exploit non-Abelian exchange statistics, implementing logical gates through braiding operations that manipulate the topological degrees of freedom; this braiding-based gate construction provides inherent protection against certain classes of local noise and thereby offers a route to fault-tolerant computation rooted in topology [5, 2]. The topologically protected nature of anyonic encodings reduces sensitivity to local errors, but engineering systems that realize non-Abelian anyons and performing the required braids at scale remain substantial experimental challenges [5, 2].\n\nBosonic approaches—using photons, phonons, or collective excitations in Bose–Einstein condensates—are powerful for communication tasks and for implementing specific computational primitives that exploit continuous-variable degrees of freedom or bosonic mode structure [5]. Nevertheless, it is important to note that naive many-particle bosonic states do not, by themselves, enlarge the accessible Hilbert space relative to appropriate single-particle encodings; the computational resourcefulness of bosonic systems therefore depends on how modes and encodings are structured and controlled rather than on particle number alone [5].\n\n### Speculative physics and nonlinear quantum mechanics\n\nIf fundamental physics permitted nonlinear modifications of quantum mechanics or exhibited other exotic phenomena not present in standard quantum theory, then novel computational powers could, in principle, emerge from such physics; these conjectures remain speculative and are not empirically established, but they motivate examining broader physical constraints on computability and the limits of algorithmic speedups [5]. The possibility of new computational capabilities arising from speculative physics serves primarily as a theoretical prompt to investigate which computational tasks are fundamentally limited by the linear, unitary structure of conventional quantum mechanics and which might benefit from radically different dynamics [5].\n\nAny assessment of the practical viability of speculative models depends critically on whether the requisite nonlinearity or exotic statistics are physically realized at scales and with coherence properties suitable for information processing, and on whether such phenomena can be controllably harnessed without introducing prohibitive decoherence or noise [5]. Thus, while speculative models expand the conceptual landscape of computability, their relevance to implementable quantum computation is contingent on strong physical evidence and on overcoming substantial control and coherence requirements [5].\n\n### Geometric (gauge) formulation of quantum computation\n\nA geometric or gauge-theoretic formulation represents quantum states as noncommutative connections and interprets unitary operations as gauge transformations, following ideas from noncommutative geometry; this framework yields a model of computation that is mathematically equivalent to the standard circuit picture while employing different conceptual primitives such as gauge states and transformations [6]. Within this formalism, probabilities and algorithmic transformations of the circuit model can be reproduced using gauge-theoretic constructs, establishing formal equivalence while offering an alternative language for describing quantum processes [6].\n\nThis geometric viewpoint can be used to recast familiar algorithms—Deutsch–Jozsa has been illustrated in this language—and to suggest alternative implementation strategies by identifying operations that may be simpler to realize in particular physical contexts when framed as gauge manipulations rather than as sequences of discrete gates [6]. By shifting the primitives of computation from wires and gates to connections and gauge transforms, the geometric approach may highlight new implementation routes or conceptual simplifications that complement circuit-based engineering and theoretical analysis [6]."
  ],
  "criticism": {
    "0": "PASS",
    "1": "PASS",
    "2": "Issue identified:\n\n- The statement \"and they continue to be explored as potential routes to scalable quantum hardware with distinct advantages in materials integration or room-temperature operation in some cases\" includes an unsupported claim about \"room-temperature operation in some cases.\"\n\nWhy this is problematic:\n\n- The INPUT JSON (topic t3.2: \"Other experimental platforms\") notes that silicon donor qubits, quantum dots and NV centers \"offer alternative tradeoffs among coherence, control, and manufacturability\" but does not state or support a claim about room-temperature operation. As written, the WRITER OUTPUT asserts a specific operational advantage (room-temperature operation) that is not present in the provided sources. Introducing this factual detail without support goes beyond the JSON and risks misrepresenting the source material.\n\nReference to input:\n\n- See t3.2 (\"Other experimental platforms\") in the INPUT JSON, which lists these platforms and their trade-offs but does not mention room-temperature operation.\n\nActionable suggestions:\n\n- Remove the phrase \"or room-temperature operation in some cases\" unless you can cite a supporting source from the given JSON.  \n- If you want to retain a related point consistent with the input, rephrase to focus on supported aspects such as \"materials integration\" or \"different trade-offs among coherence, control, and manufacturability\" (as in t3.2).  \n\nAll other statements in the WRITER OUTPUT are consistent with the INPUT JSON.",
    "3": "PASS",
    "4": "PASS",
    "5": "PASS"
  },
  "is_criticized": true
}