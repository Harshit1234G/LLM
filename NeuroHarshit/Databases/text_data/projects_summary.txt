Projects:
1. Handwritten Digit Recognition:
- Duration of Handwritten Digit Recognition: Nov 2024 - Dec 2024
- Description of Handwritten Digit Recognition: A GUI based software, recognizes Handwritten digits. Built and trained the CNN model from scratch on the MNIST dataset, without relying on pre-trained weights. User can draw digits, add noise, change pensize and import/export the prediction history. Program displays metrics like Probability Distribution, Accuracy, Confidence, Confusion Matrix, and Correct V/S Wrong Predictions. Intuitive buttons, shortcuts, and toggles for seamless user experience.
- Technologies used in Handwritten Digit Recognition: Python, TensorFlow, NumPy, Pandas, Pillow, CustomTkinter, scikit-learn, PyInstaller, Matplotlib, Tkinter, Pickle, and inno setup builder.
- Main Challenge of Handwritten Digit Recognition: Creating the GUI
- Real world use case of Handwritten Digit Recognition: Used in banking for cheque processing, postal services for reading handwritten zip codes/addresses, and digitizing forms/documents for automation.
- Keywords for Handwritten Digit Recognition: Best Project, Custom Model, Computer Vision, Deep Learning, GUI, Model Deployment

2. NeuroHarshit:
- Duration of NeuroHarshit: Aug 2025 – Aug 2025
- Description of NeuroHarshit: An AI-powered personal portfolio assistant built using RAG (Retrieval-Augmented Generation). The system is designed to answer queries about my background, projects, skills, certifications, education, and experience. It has four core components: Rewriter (rewrites the follow-up user queries based on the chat history), Retriever (it retrieves the relevant documents using multi query retrieval), Generator (it generates a response based on the rewritten query and the relevant documents), and last Finalizer (which just finalizes the response). Also built an API using FastAPI and a streamlit app for showcasing the chatbot.
- Technologies used in NeuroHarshit: Python, OpenAI API, LangChain, LangGraph, FAISS, Streamlit, FastAPI.
- Main Challenge of NeuroHarshit: Creating a reliable and robust chatbot, and creating the chat history and follow-up question mechanism.
- Real world use case of NeuroHarshit: Demonstrates how AI-powered assistants can automate recruitment processes by answering candidate-related queries, serve as interactive resumes for professionals, or act as intelligent knowledge assistants for companies.
- Keywords for NeuroHarshit: RAG, AI Agent, Portfolio Website

3. Human Emotion Detection:
- Duration of Human Emotion Detection: Mar 2025 – Mar 2025
- Description of Human Emotion Detection: A computer vision project that detects human facial emotions (Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise) using Convolutional Neural Networks (CNNs). Explored multiple architectures including LeNet-5, AlexNet, VGG-16, and ResNet-34. Achieved ~64% accuracy on the FER2013 dataset with VGG-16 after applying data augmentation and fine-tuning. This project was my first step into deep learning for computer vision and gave me strong practical insights into model architecture design, overfitting, and transfer learning.
- Future Work for Human Emotion Detection: Plan to revisit this project with improved architectures (EfficientNet, MobileNetV2, Xception), improved dataset and better fine-tuning strategies after gaining more experience.  
- Technologies Used in Human Emotion Detection: Python, TensorFlow, OpenCV, NumPy, Matplotlib.
- Main Challenge of Human Emotion Detection: Training the CNN
- Real world use case of Human Emotion Detection: Useful in customer service (detecting customer emotions in real time), healthcare (supporting mental health monitoring), Security & Surveillance (Can identify suspicious behavior based on emotional cues).
- Keywords for Human Emotion Detection: Custom Model, Deep Learning, Real-time Computer Vision Pipeline

4. Agentic AI Research Assistant:
- Duration of Agentic AI Research Assistant: Aug 2025 – Sep 2025
- Description of Agentic AI Research Assistant: An advanced multi-agent research system that automates the entire academic-style research workflow. It consists of multiple agents: SearcherAgent (fetches data from Wikipedia, arXiv, and GNews), ExtractorAgent (structures information into a JSON knowledge base), WriterAgent (expands summaries into detailed markdown reports), CriticAgent (validates accuracy and flags hallucinations), and AssemblerAgent (compiles everything into a polished PDF report with title page, abstract, methodology, main body, appendices, and references). The system ensures factual accuracy, reliability, and cost-efficient research generation.
- Technologies used in Agentic AI Research Assistant: Python, OpenAI API, LangChain, LangGraph, LangSmith, Wikipedia API, arXiv API, GNews API, markdown-pdf.
- Main Challenge of Agentic AI Research Assistant: Designing strict JSON extraction and building critic loops to minimize hallucinations.
- Real world use case of Agentic AI Research Assistant: Can serve as a powerful research automation tool for students, researchers, and professionals by generating structured, citation-backed reports on any topic. It demonstrates how AI agents can collaborate to handle complex multi-step workflows reliably.
- Keywords for Agentic AI Research Assistant: Agentic AI, Research Automation, Multi-Agent System, LLM, Knowledge Extraction, Report Generation

Learning & Practice Repository: 
1. Hands-on-ML:
- Description: Personal repository documenting my chapter-wise implementations, exercises, and notes from the book “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron. The repository includes mini-projects, key concepts, and tutorials on machine learning, deep learning, and model deployment.
- Purpose: Reinforce ML fundamentals and build intuition through practical coding exercises.
- Keywords: Machine Learning, Deep Learning, Scikit-Learn, TensorFlow, Neural Networks, Model Training, ML Exercises

2. Python-for-Data-Analysis:
- Description: Repository of chapter-wise practice, tutorials, and exercises based on “Python for Data Analysis” by Wes McKinney. Covers data wrangling, preprocessing, and analysis techniques with Pandas, NumPy, and Jupyter, along with tips and tricks for efficient data handling.
- Purpose: Strengthen data analysis skills through hands-on coding and structured learning.
- Keywords: Data Analysis, Pandas, NumPy, Jupyter, Data Wrangling, Data Cleaning, Exploratory Data Analysis, Data Visualization